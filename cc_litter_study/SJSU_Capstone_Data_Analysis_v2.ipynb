{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SJSU Capstone Data Analysis\n",
    "*SJSU-MSTM*\n",
    "\n",
    "### README\n",
    "This notebook contains data cleaning, analysis and visualization for the SJSU capstone data; it validates data based on the Caltrans Data Quality Management Plan (DQMP) data quality dimensions listed below.\n",
    "\n",
    "> Note: Similar to software [unit testing][01.00], it is intended to serve as a test suite for the specified dataset.\n",
    "\n",
    "*Change Log*\n",
    "* 10-21-2020: Submit Version 1.0\n",
    "* 10-21-2020: Baseline Version v0.1\n",
    "* 11-26-2024: SJSU Capstone Update\n",
    "\n",
    "*Deliverables*\n",
    "1. Test case are organized into separate modules and prints test results\n",
    "2. Each test will output non-compliant records into CSV files for action\n",
    "3. Data processing module produces transformed data (e.g. table joins)\n",
    "4. Notebook generates data dictionary after running all test cases\n",
    "5. All test cases are repeatable and documented\n",
    "\n",
    "*Data Quality Dimensions (DQMP)*\n",
    "1. Accuracy and Precision: Data is close to true value and exactness\n",
    "2. Validity: Conforms to established formats, data types and ranges\n",
    "3. Completeness: Absence of gaps in data, especially missing values\n",
    "4. Consistency: Data is collected at similar datetime and location\n",
    "5. Timeliness: Data is updated on a regular basis\n",
    "6. Granularity: Data is collected at appropriate level of detail for use\n",
    "7. Uniqueness: Best effort to collect data from authoritative sources\n",
    "8. Accessibility: Data is collected or processed into useable formats\n",
    "9. Reputation: Data is trusted as reliable source\n",
    "\n",
    "### Results (Summary)\n",
    "This section reports data validation findings and process steps.\n",
    "\n",
    "> Note: Data validation is intended to flag non-compliant values for discussion and not correction until confirmed by the team. As a result, the following issues were observed during data validation in addition to non-compliance report.\n",
    "\n",
    "*Datasets Cleaned, Analyzed & Visualized*\n",
    "1. Caltrans and Clean CA Litter Collection Totals\n",
    "2. Clean CA Level of Service (LOS) Scores\n",
    "3. Caltrans Customer Service Requests (CSRs)\n",
    "\n",
    "*Data Processing Steps*\n",
    "1. Import raw data/template files and save as table variables\n",
    "2. Crosswalk raw data/template fields; populate template\n",
    "3. Flag missing columns as \"Column not provided\"\n",
    "4. Convert column data types as needed\n",
    "5. Join project with corresponding table\n",
    "6. Save merged data for validation\n",
    "\n",
    "### Jupyter Introduction\n",
    "This notebook will require some basic understanding of the Python programming language, Jupyter platform and data analysis concepts. It is based on this [tutorial][01.02] and [Github Repo][01.03].\n",
    "\n",
    "Jupyter is a powerful collaborative tool which is open-source and light-weight. It provides all the tools necessary to run data analysis, visualization, statistics and data science [out of the box][01.04]. In addition, it has gain acceptance from industry and academia for collaborating on projects and publishing work.\n",
    "\n",
    "Jupyter is a combination of text and code with the programming run-time built into the platform so there is no need to install additional software. The text is in the markdown file format (similar to HTML), and code in several languages. It is organized by cells which can consist of either text or code; placed together, they can be sent as a single document to share/publish work.\n",
    "\n",
    "### Jupyter Notebook\n",
    "Notebooks are organized by cells, which mainly consist of text (in markdown) and code (Python). It operations like a hybrid between MS Word and Excel file; whereas the entire file is like a document, the cells operate like a spreadsheet. For getting started, feel free to scroll down each cell and navigate around the cells for a quick tour. Here is a breakdown of how to view/edit cells:\n",
    "\n",
    "*Navigation*\n",
    "1. Each cell may be edited by hitting ENTER; toggle between cells using the arrow keys or mouse/scroller\n",
    "2. When editing a cell, be sure to select \"markdown\" for text or \"code\" before writing into it\n",
    "3. Each cell can be run by hitting CTRL + ENTER or the \"run\" button form the menu bar\n",
    "4. Output from each cell will appear below; if an error occurs, please read and try to debug it(!)\n",
    "5. File can be saved by hitting CTRL + \"s\" or file/save from the pulldown menu above\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "*Notes*\n",
    "1. This notebook will require some Python programming\n",
    "2. It is widely used and taught in [high school][01.05] and AP Computer Science [courses][01.06]\n",
    "3. [Jupyter][01.07] supports many other languages, including R, Scala and Julia\n",
    "4. Python is the most popular of them and can be used for other tasks, primarily data science and web applications\n",
    "\n",
    "### Exercises\n",
    "\n",
    "*Jupyter*\n",
    "1. [Intro Guide (DataQuest)][01.08]\n",
    "2. [Intro Guide (DataCamp)][01.09]\n",
    "3. [Notebook Intro (Medium)][01.10]\n",
    "4. [Data Science Tutorial (Jupyter)][01.11]\n",
    "\n",
    "*Python*\n",
    "1. [Quick Start][01.12]\n",
    "2. [Intro Tutorials][01.13]\n",
    "3. [Quick Start (FCC)][01.14]\n",
    "\n",
    "*Markdown*\n",
    "1. [Quick Start (Github)][01.15]\n",
    "2. [Quick Start Guide (Markdown)][01.16]\n",
    "3. [Quick Start Tutorial (Markdown)][01.17]\n",
    "\n",
    "[01.00]: https://en.wikipedia.org/wiki/Unit_testing\n",
    "[01.01]: https://www.anaconda.com/distribution/\n",
    "[01.02]: https://medium.com/python-pandemonium/introduction-to-exploratory-data-analysis-in-python-8b6bcb55c190\n",
    "[01.03]: https://github.com/kadnan/EDA_Python/\n",
    "[01.04]: https://jupyter.org/jupyter-book/01/what-is-data-science.html\n",
    "[01.05]: https://codehs.com/info/curriculum/intropython\n",
    "[01.06]: https://code.org/educate/curriculum/high-school\n",
    "[01.07]: https://jupyter.org/\n",
    "[01.08]: https://www.dataquest.io/blog/jupyter-notebook-tutorial/\n",
    "[01.09]: https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\n",
    "[01.10]: https://towardsdatascience.com/a-beginners-tutorial-to-jupyter-notebooks-1b2f8705888a\n",
    "[01.11]: https://jupyter.org/jupyter-book/01/what-is-data-science.html\n",
    "[01.12]: https://www.python.org/about/gettingstarted/\n",
    "[01.13]: https://realpython.com/learning-paths/python3-introduction/\n",
    "[01.14]: https://guide.freecodecamp.org/python/\n",
    "[01.15]: https://guides.github.com/features/mastering-markdown/\n",
    "[01.16]: https://www.markdownguide.org/getting-started/\n",
    "[01.17]: https://www.markdowntutorial.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01.01 - load python modules into notebook\n",
    "\n",
    "# install pip package in current kernel; run only for initial install:\n",
    "# https://medium.com/@rohanguptha.bompally/python-data-visualization-using-folium-and-geopandas-981857948f02\n",
    "# !pip install descartes\n",
    "\n",
    "# data analysis modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# data visualization modules\n",
    "import seaborn as sns\n",
    "\n",
    "# excel module\n",
    "# !pip install openpyxl\n",
    "# import openpyxl\n",
    "\n",
    "# set numeric output; turn off scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# adjust print settings\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 35\n",
    "\n",
    "# suppress warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.01 - data import functions\n",
    "\n",
    "# function to read csv file and drop div/0 error values\n",
    "def read_data_csv(path):\n",
    "    df = pd.read_csv(path, na_values=['#DIV/0!'])\n",
    "    return(df)\n",
    "\n",
    "# function to write csv file\n",
    "def write_data_csv(df, path):\n",
    "    df.to_csv(path)\n",
    "\n",
    "# function to read excel, return csv/dataframe\n",
    "# https://towardsdatascience.com/loading-ridiculously-large-excel-files-in-python-44ba0a7bea24\n",
    "def excel2csv(path_excel, engine_type, path_csv):\n",
    "    # note: new excel, xlsx files - use openpyxl\n",
    "    # df_publish = pd.read_excel(data_path, index_col=0, engine=\"openpyxl\")\n",
    "    # note: old excel, xls files - use xlrd\n",
    "    # df_publish = pd.read_excel(data_path, index_col=0, engine=\"xlrd\")\n",
    "    df = pd.read_excel(path_excel, index_col=0, engine=engine_type)\n",
    "    # return file/dataframe\n",
    "    write_data_csv(df, path_csv)\n",
    "    return(df)\n",
    "\n",
    "# call function to read excel, return csv/dataframe\n",
    "# df_allv_count = excel2csv(\n",
    "#     \"data/excel/OTM_ALLV_COUNTS_01012018.xlsx\",\n",
    "#     \"openpyxl\",\n",
    "#     \"data/csv/OTM_ALLV_COUNTS_01012018.csv\"\n",
    "# )\n",
    "\n",
    "# function to read csv, output zip\n",
    "# https://stackoverflow.com/questions/37754165/python-pandas-create-zip-file-from-csv\n",
    "def csv2zip(df, path_csv, comp, path_zip):\n",
    "    compression_opts = dict(\n",
    "        method=comp,\n",
    "        archive_name=path_csv\n",
    "    )\n",
    "    df.to_csv(\n",
    "        path_zip,\n",
    "        compression=compression_opts\n",
    "    )\n",
    "\n",
    "# call function to read csv, output zip\n",
    "# csv2zip(\n",
    "#     df_publish,\n",
    "#     \"data/csv/OTM_LATEST_PUBLISHED_YEAR.csv\",\n",
    "#     \"zip\",\n",
    "#     \"data/OTM_LATEST_PUBLISHED_YEAR.zip\"\n",
    "# )\n",
    "\n",
    "# function to show table info\n",
    "def data_profile(df, msg):\n",
    "    # pass in variable into string\n",
    "    # https://stackoverflow.com/questions/2960772/how-do-i-put-a-variable-inside-a-string\n",
    "    print('*** Table Info: %s ***' % msg, '\\n')\n",
    "    print(df.info(), '\\n')\n",
    "    print('*** Table Info: Table Dimensions ***', '\\n')\n",
    "    print(df.shape, '\\n')\n",
    "\n",
    "# function to show unique value for given column\n",
    "def show_unique(df, col):\n",
    "    # pass in variable into string\n",
    "    # https://stackoverflow.com/questions/2960772/how-do-i-put-a-variable-inside-a-string\n",
    "    print('*** Unique Values: %s ***' % col, '\\n')\n",
    "    print(df[col].unique(), '\\n')\n",
    "\n",
    "# define function to create and populate template\n",
    "def data_import_project(df, path):\n",
    "    # convert raw data columns into list type for import\n",
    "    # start project data\n",
    "    list_projid = df['Project ID'].to_list()\n",
    "    list_ppno = df['PPNO'].to_list()\n",
    "    list_projtitle = df['Project Title'].to_list()\n",
    "    list_projdesc = df['Project Description'].to_list()\n",
    "    list_projstatus = df['Project Status'].to_list()\n",
    "    list_sb1funds = df['SB1 Funds'].to_list()\n",
    "    list_totalcost = df['Total Project Cost'].to_list()\n",
    "    list_fy = df['Fiscal Year'].to_list()\n",
    "    list_sb1flag = df['Is SB1?'].to_list()\n",
    "    list_onshs = df['ON SHS?'].to_list()\n",
    "    list_ctdist = df['Caltrans District'].to_list()\n",
    "    list_assembly = df['Assembly Districts'].to_list()\n",
    "    list_senate = df['Senate Districts'].to_list()\n",
    "    list_citycode = df['City Code'].to_list()\n",
    "    list_cityid = df['City Agency ID'].to_list()\n",
    "    list_countycode = df['County Code'].to_list()\n",
    "    list_countyid = df['County Agency ID'].to_list()\n",
    "    list_impagencyid = df['Implementing Agency ID'].to_list()\n",
    "\n",
    "    # import columns as list type into empty dataframe\n",
    "    # start project data\n",
    "    df_import = pd.DataFrame()\n",
    "    df_import = df_import.assign(ProjectID = list_projid)\n",
    "    df_import = df_import.assign(PPNO = list_ppno)\n",
    "    df_import = df_import.assign(ProjectTitle = list_projtitle)\n",
    "    df_import = df_import.assign(ProjectDescription = list_projdesc)\n",
    "    df_import = df_import.assign(ProjectStatus = list_projstatus)\n",
    "    df_import = df_import.assign(SB1Funds = list_sb1funds)\n",
    "    df_import = df_import.assign(TotalProjectCost = list_totalcost)\n",
    "    df_import = df_import.assign(FiscalYear = list_fy)\n",
    "    df_import = df_import.assign(SB1Flag = list_sb1flag)\n",
    "    df_import = df_import.assign(OnSHS = list_onshs)\n",
    "    df_import = df_import.assign(CaltransDistrict = list_ctdist)\n",
    "    df_import = df_import.assign(AssemblyDistricts = list_assembly)\n",
    "    df_import = df_import.assign(SenateDistricts = list_senate)\n",
    "    df_import = df_import.assign(CityCodes = list_citycode)\n",
    "    df_import = df_import.assign(CityAgencyID = list_cityid)\n",
    "    df_import = df_import.assign(CountyCode = list_countycode)\n",
    "    df_import = df_import.assign(CountyAgencyID = list_countyid)\n",
    "    df_import = df_import.assign(ImplementingAgencyID = list_impagencyid)\n",
    "\n",
    "    # write to csv file\n",
    "    df_import.to_csv(path)\n",
    "    return(df_import)\n",
    "\n",
    "# define function to create and populate template\n",
    "def data_import_location(df, path):\n",
    "    # convert raw data columns into list type for import\n",
    "    # start location data\n",
    "    list_projid = df['Project ID'].to_list()\n",
    "    list_route = df['Route'].to_list()\n",
    "    list_co_begin = df['Beg_County'].to_list()\n",
    "    list_pm_begin_prefix = df['Beg_PM_Prefix'].to_list()\n",
    "    list_pm_begin = df['Beg_Postmile'].to_list()\n",
    "    list_pm_begin_suffix = df['Beg_Postmile'].to_list()\n",
    "    list_co_end = df['End_County'].to_list()\n",
    "    list_pm_end_prefix = df['End_PM_Prefix'].to_list()\n",
    "    list_pm_end = df['End_Postmile'].to_list()\n",
    "    list_pm_end_suffix = df['End_PM_Suffix'].to_list()\n",
    "\n",
    "    # import columns as list type into empty dataframe\n",
    "    # start location data\n",
    "    df_import = pd.DataFrame()\n",
    "    df_import = df_import.assign(ProjectID = list_projid)\n",
    "    df_import = df_import.assign(Route = list_route)\n",
    "    df_import = df_import.assign(Beg_County = list_co_begin)\n",
    "    df_import = df_import.assign(Beg_PM_Prefix = list_pm_begin_prefix)\n",
    "    df_import = df_import.assign(Beg_Postmile = list_pm_begin)\n",
    "    df_import = df_import.assign(Beg_PM_Suffix = list_pm_begin_suffix)\n",
    "    df_import = df_import.assign(End_County = list_co_end)\n",
    "    df_import = df_import.assign(End_PM_Prefix = list_pm_end_prefix)\n",
    "    df_import = df_import.assign(End_Postmile = list_pm_end)\n",
    "    df_import = df_import.assign(End_PM_Suffix = list_pm_end_suffix)\n",
    "\n",
    "    # write to csv file\n",
    "    df_import.to_csv(path)\n",
    "    return(df_import)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.02 - data processing functions\n",
    "\n",
    "# function to rename columns\n",
    "# https://www.geeksforgeeks.org/how-to-rename-columns-in-pandas-dataframe/\n",
    "def rename_col(df, old_col, new_col):\n",
    "    df = df.rename(\n",
    "        columns={old_col:new_col},\n",
    "        inplace=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# call function to rename columns\n",
    "# df_project = rename_col(\n",
    "#     df_project,\n",
    "#     'Assembly District\\n-Overlay-',\n",
    "#     'assembly_dist'\n",
    "# )\n",
    "\n",
    "# function to replace col val\n",
    "# https://www.geeksforgeeks.org/python-pandas-dataframe-replace/\n",
    "def replace_col(df, col, old_val, new_val):\n",
    "    df[col] = df[col].replace(\n",
    "        to_replace = old_val,\n",
    "        value = new_val\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# function to flag null values for data subset\n",
    "def null_flag(df, col):\n",
    "    df[col].fillna(' | null | ', inplace = True)\n",
    "    return(df)\n",
    "\n",
    "# function convert col to numeric type\n",
    "# reference: https://stackoverflow.com/questions/47333227/pandas-valueerror-cannot-convert-float-nan-to-integer\n",
    "def convert_num(df, col):\n",
    "    # convert type\n",
    "    df[col] = pd.to_numeric(\n",
    "        df[col],\n",
    "        errors='coerce'\n",
    "    )\n",
    "    return(df)\n",
    "\n",
    "# call function to convert col to numeric type\n",
    "# df_project = convert_num(df_project, 'TotalProjectCost')\n",
    "\n",
    "# function convert col to string type\n",
    "# https://www.geeksforgeeks.org/python-pandas-series-astype-to-convert-data-type-of-series/\n",
    "def convert_str(df, col):\n",
    "    df[col] = df[col].astype(str)\n",
    "    return(df)\n",
    "\n",
    "# convert string to datetime\n",
    "# reference: https://stackoverflow.com/questions/32888124/pandas-out-of-bounds-nanosecond-timestamp-after-offset-rollforward-plus-adding-a\n",
    "def convert_date(df, col):\n",
    "    # convert type\n",
    "    df[col] = pd.to_datetime(\n",
    "        df[col],\n",
    "        infer_datetime_format=True,\n",
    "        errors = 'coerce'\n",
    "    )\n",
    "    return(df)\n",
    "\n",
    "# call function to show table info\n",
    "# data_profile(df_project, 'Project List')\n",
    "\n",
    "# function to replace newline\n",
    "# https://stackoverflow.com/questions/53872063/removing-quote-and-hidden-new-line/53872406#53872406\n",
    "def replace_newline(df, col):\n",
    "    # df[col].str.replace('\\n', '')\n",
    "    df[col] = df[col].str.replace(chr(10), \" \").str.replace(chr(13), \" \").str.replace(chr(34), \" \")\n",
    "    return(df)\n",
    "\n",
    "# create function to print validation test results\n",
    "def print_result(invalid_count, df, total_count, invalid_ratio):\n",
    "    if invalid_count >= 1:\n",
    "        print('* Results: | ')\n",
    "        print('\\tNon-Compliant Rows:', invalid_count, ' | ')\n",
    "        print('\\tTotal Rows:', total_count, ' | ')\n",
    "        print('\\tPercent Non-Compliant:', round(invalid_ratio, 4), '\\n')\n",
    "    elif invalid_count < 1:\n",
    "        print('* Results: 100% Passing (All Rows Compliant)\\n')\n",
    "\n",
    "def output_result(df, filepath):\n",
    "    # output error report to csv file\n",
    "    df.to_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03.00 - data subset and table join functions\n",
    "\n",
    "# subset dataset by row values; for example, project list by funding source\n",
    "# https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "# df_projects_atp = df_projects[df_projects['SOURCE'].str.contains('ATP')]\n",
    "\n",
    "# define table join function; merge new and old tables on given column\n",
    "def join_table(df_left, df_right, col, method, msg):\n",
    "    df_join = pd.merge(\n",
    "        df_left,\n",
    "        df_right,\n",
    "        on=col,\n",
    "        how=method\n",
    "    )\n",
    "    print(msg, '\\n')\n",
    "    print('Before Table Join: ')\n",
    "    print('Left Table: ', df_left.shape)\n",
    "    print('Right Table: ', df_right.shape, '\\n')\n",
    "    print('After Table Join: ')\n",
    "    print('Left + Right Table: ', df_join.shape, '\\n')\n",
    "    return(df_join)\n",
    "\n",
    "# define table join function; merge new and old tables with different keys\n",
    "# https://stackoverflow.com/questions/25888207/pandas-join-dataframes-on-field-with-different-names\n",
    "def join_table_key(df_left, df_right, id_key, fk_key, msg):\n",
    "    df_join = pd.merge(df_left, df_right, how='left', left_on=[id_key], right_on=[fk_key])\n",
    "    print(msg, '\\n')\n",
    "    print('Before Table Join: ')\n",
    "    print('Left Table: ', df_left.shape)\n",
    "    print('Right Table: ', df_right.shape, '\\n')\n",
    "    print('After Table Join: ')\n",
    "    print('Left + Right Table: ', df_join.shape, '\\n')\n",
    "    return(df_join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Added by NS 4/17/2025\n",
    "# Identify the path to the Data\n",
    "gcs_path = \"gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Table Dimensions: Original (IMMS 2021B) *** \n",
      "\n",
      "(26910, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2021B) *** \n",
      "\n",
      "(26910, 32) \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_imms_2021b\u001b[38;5;241m.\u001b[39mshape , \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# remove row if value is greater than given value\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m df_imms_2021b \u001b[38;5;241m=\u001b[39m df_imms_2021b[\u001b[38;5;241m~\u001b[39mdf_imms_2021b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduction Quantity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m]\n\u001b[1;32m     53\u001b[0m df_imms_2021b \u001b[38;5;241m=\u001b[39m df_imms_2021b[\u001b[38;5;241m~\u001b[39mdf_imms_2021b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSecondary Prod\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# check table dim\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# 05.01.01 - data import/cleaning (imms)\n",
    "\n",
    "# Commented out by NS 4/17/2025 & replaced with the script that pulls in the data from GCS\n",
    "# # import imms/litter collection totals as csv datasets\n",
    "# df_imms_2021b = read_data_csv('data/imms_2021b.csv')\n",
    "# df_imms_2022a = read_data_csv('data/imms_2022a.csv')\n",
    "# df_imms_2022b = read_data_csv('data/imms_2022b.csv')\n",
    "# df_imms_2023a = read_data_csv('data/imms_2023a.csv')\n",
    "# df_imms_2023b = read_data_csv('data/imms_2023b.csv')\n",
    "# df_imms_2024a = read_data_csv('data/imms_2024a.csv')\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# import imms/litter collection totals as csv datasets from GCS\n",
    "df_imms_2021b = read_data_csv(f\"{gcs_path}imms_2021b.csv\")\n",
    "df_imms_2022a = read_data_csv(f\"{gcs_path}imms_2022a.csv\")\n",
    "df_imms_2022b = read_data_csv(f\"{gcs_path}imms_2022b.csv\")\n",
    "df_imms_2023a = read_data_csv(f\"{gcs_path}imms_2023a.csv\")\n",
    "df_imms_2023b = read_data_csv(f\"{gcs_path}imms_2023b.csv\")\n",
    "df_imms_2024a = read_data_csv(f\"{gcs_path}imms_2024a.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call function to show data profile\n",
    "# data_profile(df_imms_2021b, 'Data Profile: IMMS - 2021b')\n",
    "# data_profile(df_imms_2022a, 'Data Profile: IMMS - 2022a')\n",
    "# data_profile(df_imms_2022b, 'Data Profile: IMMS - 2022b')\n",
    "# data_profile(df_imms_2023a, 'Data Profile: IMMS - 2023a')\n",
    "# data_profile(df_imms_2023b, 'Data Profile: IMMS - 2023b')\n",
    "# data_profile(df_imms_2024a, 'Data Profile: IMMS - 2024a')\n",
    "\n",
    "# clean data - IMMS 2021B\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (IMMS 2021B) ***', '\\n')\n",
    "print(df_imms_2021b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2021b = df_imms_2021b[~df_imms_2021b['From PM'].isnull()]\n",
    "# df_imms_2021b = df_imms_2021b[~df_imms_2021b['To PM'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null PM (IMMS 2021B) ***', '\\n')\n",
    "# print(df_imms_2021b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b['Production Quantity'].isnull()]\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b['Secondary Prod'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null litter prod (IMMS 2021B) ***', '\\n')\n",
    "print(df_imms_2021b.shape , '\\n')\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b['Production Quantity'].astype(np.int) <= 1000]\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b['Secondary Prod'].astype(np.int) <= 1000]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove litter prod if greater than 1000 CY (IMMS 2021B) ***', '\\n')\n",
    "print(df_imms_2021b.shape , '\\n')\n",
    "\n",
    "# clean data - IMMS 2022A\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (IMMS 2022A) ***', '\\n')\n",
    "print(df_imms_2022a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2022a = df_imms_2022a[~df_imms_2022a['From PM'].isnull()]\n",
    "# df_imms_2022a = df_imms_2022a[~df_imms_2022a['To PM'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null PM (IMMS 2022A) ***', '\\n')\n",
    "print(df_imms_2022a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a['Production Quantity'].isnull()]\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a['Secondary Prod'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null litter prod (IMMS 2022A) ***', '\\n')\n",
    "print(df_imms_2022a.shape , '\\n')\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a['Production Quantity'].astype(np.int) <= 1000]\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a['Secondary Prod'].astype(np.int) <= 1000]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove litter prod if greater than 1000 CY (IMMS 2022A) ***', '\\n')\n",
    "print(df_imms_2022a.shape , '\\n')\n",
    "\n",
    "# clean data - IMMS 2022B\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (IMMS 2022B) ***', '\\n')\n",
    "print(df_imms_2022b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2022b = df_imms_2022b[~df_imms_2022b['From PM'].isnull()]\n",
    "# df_imms_2022b = df_imms_2022b[~df_imms_2022b['To PM'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null PM (IMMS 2022B) ***', '\\n')\n",
    "print(df_imms_2022b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2022b = df_imms_2022b[~df_imms_2022b['Production Quantity'].isnull()]\n",
    "df_imms_2022b = df_imms_2022b[~df_imms_2022b['Secondary Prod'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null litter prod (IMMS 2022B) ***', '\\n')\n",
    "print(df_imms_2022b.shape , '\\n')\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "df_imms_2022b = df_imms_2022b[~df_imms_2022b['Production Quantity'].astype(np.int) <= 1000]\n",
    "df_imms_2022b = df_imms_2022b[~df_imms_2022b['Secondary Prod'].astype(np.int) <= 1000]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove litter prod if greater than 1000 CY (IMMS 2022B) ***', '\\n')\n",
    "print(df_imms_2022b.shape , '\\n')\n",
    "\n",
    "# clean data - IMMS 2023A\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (IMMS 2023A) ***', '\\n')\n",
    "print(df_imms_2023a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2023a = df_imms_2023a[~df_imms_2023a['From PM'].isnull()]\n",
    "# df_imms_2023a = df_imms_2023a[~df_imms_2023a['To PM'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null PM (IMMS 2023A) ***', '\\n')\n",
    "print(df_imms_2023a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a['Production Quantity'].isnull()]\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a['Secondary Prod'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null litter prod (IMMS 2023A) ***', '\\n')\n",
    "print(df_imms_2023a.shape , '\\n')\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a['Production Quantity'].astype(np.int) <= 1000]\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a['Secondary Prod'].astype(np.int) <= 1000]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove litter prod if greater than 1000 CY (IMMS 2023A) ***', '\\n')\n",
    "print(df_imms_2023a.shape , '\\n')\n",
    "\n",
    "# clean data - IMMS 2023B\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (IMMS 2023B) ***', '\\n')\n",
    "print(df_imms_2023b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2023b = df_imms_2023b[~df_imms_2023b['From PM'].isnull()]\n",
    "# df_imms_2023b = df_imms_2023b[~df_imms_2023b['To PM'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null PM (IMMS 2023B) ***', '\\n')\n",
    "print(df_imms_2023b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b['Production Quantity'].isnull()]\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b['Secondary Prod'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null litter prod (IMMS 2023B) ***', '\\n')\n",
    "print(df_imms_2023b.shape , '\\n')\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b['Production Quantity'].astype(np.int) <= 1000]\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b['Secondary Prod'].astype(np.int) <= 1000]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove litter prod if greater than 1000 CY (IMMS 2023B) ***', '\\n')\n",
    "print(df_imms_2023b.shape , '\\n')\n",
    "\n",
    "# export final csv file\n",
    "write_data_csv(\n",
    "    df_imms_2021b,\n",
    "    'data/05.01.01_data_clean_imms_2021b.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_imms_2022a,\n",
    "    'data/05.01.01_data_clean_imms_2022a.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_imms_2022b,\n",
    "    'data/05.01.01_data_clean_imms_2022b.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_imms_2023a,\n",
    "    'data/05.01.01_data_clean_imms_2023a.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_imms_2023b,\n",
    "    'data/05.01.01_data_clean_imms_2023b.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_imms_2024a,\n",
    "    'data/05.01.01_data_clean_imms_2024a.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.01.02 - data import/cleaning (csr)\n",
    "\n",
    "# Commented out by NS on 4/17/2025\n",
    "# # import csr data as csv datasets\n",
    "# df_csr_2021b = read_data_csv('data/csr_litter_aah_2021b.csv')\n",
    "# df_csr_2022a = read_data_csv('data/csr_litter_aah_2022a.csv')\n",
    "# df_csr_2022b = read_data_csv('data/csr_litter_aah_2022b.csv')\n",
    "# df_csr_2023a = read_data_csv('data/csr_litter_aah_2023a.csv')\n",
    "# df_csr_2023b = read_data_csv('data/csr_litter_aah_2023b.csv')\n",
    "# df_csr_2024a = read_data_csv('data/csr_litter_aah_2024a.csv')\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# Import CSR data as CSV datasets\n",
    "df_csr_2021b = read_data_csv(f\"{gcs_path}csr_litter_aah_2021b.csv\")\n",
    "df_csr_2022a = read_data_csv(f\"{gcs_path}csr_litter_aah_2022a.csv\")\n",
    "df_csr_2022b = read_data_csv(f\"{gcs_path}csr_litter_aah_2022b.csv\")\n",
    "df_csr_2023a = read_data_csv(f\"{gcs_path}csr_litter_aah_2023a.csv\")\n",
    "df_csr_2023b = read_data_csv(f\"{gcs_path}csr_litter_aah_2023b.csv\")\n",
    "df_csr_2024a = read_data_csv(f\"{gcs_path}csr_litter_aah_2024a.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# import csr data as csv datasets\n",
    "# data_profile(df_csr_2021b, 'Data Profile: CSR - 2021b')\n",
    "# data_profile(df_csr_2022a, 'Data Profile: CSR - 2022a')\n",
    "# data_profile(df_csr_2022b, 'Data Profile: CSR - 2022b')\n",
    "# data_profile(df_csr_2023a, 'Data Profile: CSR - 2023a')\n",
    "# data_profile(df_csr_2023b, 'Data Profile: CSR - 2023b')\n",
    "# data_profile(df_csr_2024a, 'Data Profile: CSR - 2024a')\n",
    "\n",
    "# clean data - CSR 2021B\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (CSR 2021B) ***', '\\n')\n",
    "print(df_csr_2021b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b['Date Opened'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null date opened (CSR 2021B) ***', '\\n')\n",
    "print(df_csr_2021b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b['Latitude'].isnull()]\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b['Longitude'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null lat/long (CSR 2021B) ***', '\\n')\n",
    "print(df_csr_2021b.shape , '\\n')\n",
    "\n",
    "# clean data - CSR 2022A\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (CSR 2022A) ***', '\\n')\n",
    "print(df_csr_2022a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a['Date Opened'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null date opened (CSR 2022A) ***', '\\n')\n",
    "print(df_csr_2022a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a['Latitude'].isnull()]\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a['Longitude'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null lat/long (CSR 2022A) ***', '\\n')\n",
    "print(df_csr_2022a.shape , '\\n')\n",
    "\n",
    "# clean data - CSR 2022B\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (CSR 2022B) ***', '\\n')\n",
    "print(df_csr_2022b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b['Date Opened'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null date opened (CSR 2022B) ***', '\\n')\n",
    "print(df_csr_2022b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b['Latitude'].isnull()]\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b['Longitude'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null lat/long (CSR 2022B) ***', '\\n')\n",
    "print(df_csr_2022b.shape , '\\n')\n",
    "\n",
    "# clean data - CSR 2023A\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (CSR 2023A) ***', '\\n')\n",
    "print(df_csr_2023a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a['Date Opened'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null date opened (CSR 2023A) ***', '\\n')\n",
    "print(df_csr_2023a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a['Latitude'].isnull()]\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a['Longitude'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null lat/long (CSR 2023A) ***', '\\n')\n",
    "print(df_csr_2023a.shape , '\\n')\n",
    "\n",
    "# clean data - CSR 2023B\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (CSR 2023B) ***', '\\n')\n",
    "print(df_csr_2023b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b['Date Opened'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null date opened (CSR 2023B) ***', '\\n')\n",
    "print(df_csr_2023b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b['Latitude'].isnull()]\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b['Longitude'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null lat/long (CSR 2023B) ***', '\\n')\n",
    "print(df_csr_2023b.shape , '\\n')\n",
    "\n",
    "# clean data - CSR 2024A\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (CSR 2024A) ***', '\\n')\n",
    "print(df_csr_2024a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a['Date Opened'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null date opened (CSR 2024A) ***', '\\n')\n",
    "print(df_csr_2024a.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a['Latitude'].isnull()]\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a['Longitude'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null lat/long (CSR 2024A) ***', '\\n')\n",
    "print(df_csr_2024a.shape , '\\n')\n",
    "\n",
    "# export final csv file\n",
    "write_data_csv(\n",
    "    df_csr_2021b,\n",
    "    'data/05.01.02_data_clean_csr_2021b.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_csr_2022a,\n",
    "    'data/05.01.02_data_clean_csr_2022a.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_csr_2022b,\n",
    "    'data/05.01.02_data_clean_csr_2022b.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_csr_2023a,\n",
    "    'data/05.01.02_data_clean_csr_2023a.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_csr_2023b,\n",
    "    'data/05.01.02_data_clean_csr_2023b.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_csr_2024a,\n",
    "    'data/05.01.02_data_clean_csr_2024a.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.01.03 - data import/cleaning (los)\n",
    "\n",
    "# Commented out by NS 4/17/2025\n",
    "# # import los scores as csv datasets\n",
    "# df_los_2023a_d1 = read_data_csv('data/los_scores_2023a_d1.csv')\n",
    "# df_los_2023a_d2 = read_data_csv('data/los_scores_2023a_d2.csv')\n",
    "# df_los_2023a_d3 = read_data_csv('data/los_scores_2023a_d3.csv')\n",
    "# df_los_2023a_d4 = read_data_csv('data/los_scores_2023a_d4.csv')\n",
    "# df_los_2023a_d5 = read_data_csv('data/los_scores_2023a_d5.csv')\n",
    "# df_los_2023a_d6 = read_data_csv('data/los_scores_2023a_d6.csv')\n",
    "# df_los_2023a_d7 = read_data_csv('data/los_scores_2023a_d7.csv')\n",
    "# df_los_2023a_d8 = read_data_csv('data/los_scores_2023a_d8.csv')\n",
    "# df_los_2023a_d9 = read_data_csv('data/los_scores_2023a_d9.csv')\n",
    "# df_los_2023a_d10 = read_data_csv('data/los_scores_2023a_d10.csv')\n",
    "# df_los_2023a_d11 = read_data_csv('data/los_scores_2023a_d11.csv')\n",
    "# df_los_2023a_d12 = read_data_csv('data/los_scores_2023a_d12.csv')\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# Import LOS scores data as CSV datasets\n",
    "df_los_2023a_d1 = read_data_csv(f\"{gcs_path}los_scores_2023a_d1.csv\")\n",
    "df_los_2023a_d2 = read_data_csv(f\"{gcs_path}los_scores_2023a_d2.csv\")\n",
    "df_los_2023a_d3 = read_data_csv(f\"{gcs_path}los_scores_2023a_d3.csv\")\n",
    "df_los_2023a_d4 = read_data_csv(f\"{gcs_path}los_scores_2023a_d4.csv\")\n",
    "df_los_2023a_d5 = read_data_csv(f\"{gcs_path}los_scores_2023a_d5.csv\")\n",
    "df_los_2023a_d6 = read_data_csv(f\"{gcs_path}los_scores_2023a_d6.csv\")\n",
    "df_los_2023a_d7 = read_data_csv(f\"{gcs_path}los_scores_2023a_d7.csv\")\n",
    "df_los_2023a_d8 = read_data_csv(f\"{gcs_path}los_scores_2023a_d8.csv\")\n",
    "df_los_2023a_d9 = read_data_csv(f\"{gcs_path}los_scores_2023a_d9.csv\")\n",
    "df_los_2023a_d10 = read_data_csv(f\"{gcs_path}los_scores_2023a_d10.csv\")\n",
    "df_los_2023a_d11 = read_data_csv(f\"{gcs_path}los_scores_2023a_d11.csv\")\n",
    "df_los_2023a_d12 = read_data_csv(f\"{gcs_path}los_scores_2023a_d12.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Commented out by NS 4/17/2025\n",
    "# # import los scores as csv datasets\n",
    "# df_los_all_d1 = read_data_csv('data/los_scores_raw_d1.csv')\n",
    "# df_los_all_d2 = read_data_csv('data/los_scores_raw_d2.csv')\n",
    "# df_los_all_d3 = read_data_csv('data/los_scores_raw_d3.csv')\n",
    "# df_los_all_d4 = read_data_csv('data/los_scores_raw_d4.csv')\n",
    "# df_los_all_d5 = read_data_csv('data/los_scores_raw_d5.csv')\n",
    "# df_los_all_d6 = read_data_csv('data/los_scores_raw_d6.csv')\n",
    "# df_los_all_d7 = read_data_csv('data/los_scores_raw_d7.csv')\n",
    "# df_los_all_d8 = read_data_csv('data/los_scores_raw_d8.csv')\n",
    "# df_los_all_d9 = read_data_csv('data/los_scores_raw_d9.csv')\n",
    "# df_los_all_d10 = read_data_csv('data/los_scores_raw_d10.csv')\n",
    "# df_los_all_d11 = read_data_csv('data/los_scores_raw_d11.csv')\n",
    "# df_los_all_d12 = read_data_csv('data/los_scores_raw_d12.csv')\n",
    "\n",
    "# Import LOS scores (raw) as CSV datasets\n",
    "df_los_all_d1 = read_data_csv(f\"{gcs_path}los_scores_raw_d1.csv\")\n",
    "df_los_all_d2 = read_data_csv(f\"{gcs_path}los_scores_raw_d2.csv\")\n",
    "df_los_all_d3 = read_data_csv(f\"{gcs_path}los_scores_raw_d3.csv\")\n",
    "df_los_all_d4 = read_data_csv(f\"{gcs_path}los_scores_raw_d4.csv\")\n",
    "df_los_all_d5 = read_data_csv(f\"{gcs_path}los_scores_raw_d5.csv\")\n",
    "df_los_all_d6 = read_data_csv(f\"{gcs_path}los_scores_raw_d6.csv\")\n",
    "df_los_all_d7 = read_data_csv(f\"{gcs_path}los_scores_raw_d7.csv\")\n",
    "df_los_all_d8 = read_data_csv(f\"{gcs_path}los_scores_raw_d8.csv\")\n",
    "df_los_all_d9 = read_data_csv(f\"{gcs_path}los_scores_raw_d9.csv\")\n",
    "df_los_all_d10 = read_data_csv(f\"{gcs_path}los_scores_raw_d10.csv\")\n",
    "df_los_all_d11 = read_data_csv(f\"{gcs_path}los_scores_raw_d11.csv\")\n",
    "df_los_all_d12 = read_data_csv(f\"{gcs_path}los_scores_raw_d12.csv\")\n",
    "\n",
    "\n",
    "# import los scores as csv datasets\n",
    "data_profile(df_los_all_d1, 'Data Profile: LOS - d1')\n",
    "data_profile(df_los_all_d2, 'Data Profile: LOS - d2')\n",
    "data_profile(df_los_all_d3, 'Data Profile: LOS - d3')\n",
    "data_profile(df_los_all_d4, 'Data Profile: LOS - d4')\n",
    "data_profile(df_los_all_d5, 'Data Profile: LOS - d5')\n",
    "data_profile(df_los_all_d6, 'Data Profile: LOS - d6')\n",
    "data_profile(df_los_all_d7, 'Data Profile: LOS - d7')\n",
    "data_profile(df_los_all_d8, 'Data Profile: LOS - d8')\n",
    "data_profile(df_los_all_d9, 'Data Profile: LOS - d9')\n",
    "data_profile(df_los_all_d10, 'Data Profile: LOS - d10')\n",
    "data_profile(df_los_all_d11, 'Data Profile: LOS - d11')\n",
    "data_profile(df_los_all_d12, 'Data Profile: LOS - d12')\n",
    "\n",
    "# clean data - los_2023a_d1\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d1) ***', '\\n')\n",
    "print(df_los_2023a_d1.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d1 = df_los_2023a_d1[~df_los_2023a_d1['CO'].isnull()]\n",
    "df_los_2023a_d1 = df_los_2023a_d1[~df_los_2023a_d1['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d1) ***', '\\n')\n",
    "# print(df_los_2023a_d1.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d2\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d2) ***', '\\n')\n",
    "print(df_los_2023a_d2.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d2 = df_los_2023a_d2[~df_los_2023a_d2['CO'].isnull()]\n",
    "df_los_2023a_d2 = df_los_2023a_d2[~df_los_2023a_d2['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d2) ***', '\\n')\n",
    "# print(df_los_2023a_d2.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d3\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d3) ***', '\\n')\n",
    "print(df_los_2023a_d3.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d3 = df_los_2023a_d3[~df_los_2023a_d3['CO'].isnull()]\n",
    "df_los_2023a_d3 = df_los_2023a_d3[~df_los_2023a_d3['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d3) ***', '\\n')\n",
    "# print(df_los_2023a_d3.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d4\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d4) ***', '\\n')\n",
    "print(df_los_2023a_d4.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d4 = df_los_2023a_d4[~df_los_2023a_d4['CO'].isnull()]\n",
    "df_los_2023a_d4 = df_los_2023a_d4[~df_los_2023a_d4['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d4) ***', '\\n')\n",
    "# print(df_los_2023a_d4.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d5\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d5) ***', '\\n')\n",
    "print(df_los_2023a_d5.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d5 = df_los_2023a_d5[~df_los_2023a_d5['CO'].isnull()]\n",
    "df_los_2023a_d5 = df_los_2023a_d5[~df_los_2023a_d5['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d5) ***', '\\n')\n",
    "# print(df_los_2023a_d5.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d6\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d6) ***', '\\n')\n",
    "print(df_los_2023a_d6.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d6 = df_los_2023a_d6[~df_los_2023a_d6['CO'].isnull()]\n",
    "df_los_2023a_d6 = df_los_2023a_d6[~df_los_2023a_d6['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d6) ***', '\\n')\n",
    "# print(df_los_2023a_d6.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d7\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d7) ***', '\\n')\n",
    "print(df_los_2023a_d7.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d7 = df_los_2023a_d7[~df_los_2023a_d7['CO'].isnull()]\n",
    "df_los_2023a_d7 = df_los_2023a_d7[~df_los_2023a_d7['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d7) ***', '\\n')\n",
    "# print(df_los_2023a_d7.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d8\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d8) ***', '\\n')\n",
    "print(df_los_2023a_d8.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d8 = df_los_2023a_d8[~df_los_2023a_d8['CO'].isnull()]\n",
    "df_los_2023a_d8 = df_los_2023a_d8[~df_los_2023a_d8['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d8) ***', '\\n')\n",
    "# print(df_los_2023a_d8.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d9\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d9) ***', '\\n')\n",
    "print(df_los_2023a_d9.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d9 = df_los_2023a_d9[~df_los_2023a_d9['CO'].isnull()]\n",
    "df_los_2023a_d9 = df_los_2023a_d9[~df_los_2023a_d9['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d9) ***', '\\n')\n",
    "# print(df_los_2023a_d9.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d10\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d10) ***', '\\n')\n",
    "print(df_los_2023a_d10.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d10 = df_los_2023a_d10[~df_los_2023a_d10['CO'].isnull()]\n",
    "df_los_2023a_d10 = df_los_2023a_d10[~df_los_2023a_d10['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d10) ***', '\\n')\n",
    "# print(df_los_2023a_d10.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d11\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d11) ***', '\\n')\n",
    "print(df_los_2023a_d11.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d11 = df_los_2023a_d11[~df_los_2023a_d11['CO'].isnull()]\n",
    "df_los_2023a_d11 = df_los_2023a_d11[~df_los_2023a_d11['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d11) ***', '\\n')\n",
    "# print(df_los_2023a_d11.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d12\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_2023a_d12) ***', '\\n')\n",
    "print(df_los_2023a_d12.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d12 = df_los_2023a_d12[~df_los_2023a_d12['CO'].isnull()]\n",
    "df_los_2023a_d12 = df_los_2023a_d12[~df_los_2023a_d12['RTE'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d12) ***', '\\n')\n",
    "# print(df_los_2023a_d12.shape , '\\n')\n",
    "\n",
    "# export final csv file\n",
    "write_data_csv(\n",
    "    df_los_2023a_d1,\n",
    "    'data/05.01.03_data_clean_los_2023a_d1.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d2,\n",
    "    'data/05.01.03_data_clean_los_2023a_d2.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d3,\n",
    "    'data/05.01.03_data_clean_los_2023a_d3.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d4,\n",
    "    'data/05.01.03_data_clean_los_2023a_d4.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d5,\n",
    "    'data/05.01.03_data_clean_los_2023a_d5.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d6,\n",
    "    'data/05.01.03_data_clean_los_2023a_d6.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d7,\n",
    "    'data/05.01.03_data_clean_los_2023a_d7.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d8,\n",
    "    'data/05.01.03_data_clean_los_2023a_d8.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d9,\n",
    "    'data/05.01.03_data_clean_los_2023a_d9.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d10,\n",
    "    'data/05.01.03_data_clean_los_2023a_d10.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d11,\n",
    "    'data/05.01.03_data_clean_los_2023a_d11.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_2023a_d12,\n",
    "    'data/05.01.03_data_clean_los_2023a_d12.csv'\n",
    ")\n",
    "\n",
    "# clean data - los_all_d1\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d1) ***', '\\n')\n",
    "print(df_los_all_d1.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d1 = df_los_all_d1[~df_los_all_d1['CO'].isnull()]\n",
    "df_los_all_d1 = df_los_all_d1[~df_los_all_d1['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d1) ***', '\\n')\n",
    "print(df_los_all_d1.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d2\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d2) ***', '\\n')\n",
    "print(df_los_all_d2.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d2 = df_los_all_d2[~df_los_all_d2['CO'].isnull()]\n",
    "df_los_all_d2 = df_los_all_d2[~df_los_all_d2['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d2) ***', '\\n')\n",
    "print(df_los_all_d2.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d3\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d3) ***', '\\n')\n",
    "print(df_los_all_d3.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d3 = df_los_all_d3[~df_los_all_d3['CO'].isnull()]\n",
    "df_los_all_d3 = df_los_all_d3[~df_los_all_d3['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d3) ***', '\\n')\n",
    "print(df_los_all_d3.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d4\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d4) ***', '\\n')\n",
    "print(df_los_all_d4.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d4 = df_los_all_d4[~df_los_all_d4['CO'].isnull()]\n",
    "df_los_all_d4 = df_los_all_d4[~df_los_all_d4['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d4) ***', '\\n')\n",
    "print(df_los_all_d4.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d5\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d5) ***', '\\n')\n",
    "print(df_los_all_d5.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d5 = df_los_all_d5[~df_los_all_d5['CO'].isnull()]\n",
    "df_los_all_d5 = df_los_all_d5[~df_los_all_d5['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d5) ***', '\\n')\n",
    "print(df_los_all_d5.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d6\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d6) ***', '\\n')\n",
    "print(df_los_all_d6.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d6 = df_los_all_d6[~df_los_all_d6['CO'].isnull()]\n",
    "df_los_all_d6 = df_los_all_d6[~df_los_all_d6['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d6) ***', '\\n')\n",
    "print(df_los_all_d6.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d7\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d7) ***', '\\n')\n",
    "print(df_los_all_d7.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d7 = df_los_all_d7[~df_los_all_d7['CO'].isnull()]\n",
    "df_los_all_d7 = df_los_all_d7[~df_los_all_d7['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d7) ***', '\\n')\n",
    "print(df_los_all_d7.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d8\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d8) ***', '\\n')\n",
    "print(df_los_all_d8.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d8 = df_los_all_d8[~df_los_all_d8['CO'].isnull()]\n",
    "df_los_all_d8 = df_los_all_d8[~df_los_all_d8['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d8) ***', '\\n')\n",
    "print(df_los_all_d8.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d9\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d9) ***', '\\n')\n",
    "print(df_los_all_d9.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d9 = df_los_all_d9[~df_los_all_d9['CO'].isnull()]\n",
    "df_los_all_d9 = df_los_all_d9[~df_los_all_d9['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d9) ***', '\\n')\n",
    "print(df_los_all_d9.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d10\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d10) ***', '\\n')\n",
    "print(df_los_all_d10.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d10 = df_los_all_d10[~df_los_all_d10['CO'].isnull()]\n",
    "df_los_all_d10 = df_los_all_d10[~df_los_all_d10['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d10) ***', '\\n')\n",
    "print(df_los_all_d10.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d11\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d11) ***', '\\n')\n",
    "print(df_los_all_d11.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d11 = df_los_all_d11[~df_los_all_d11['CO'].isnull()]\n",
    "df_los_all_d11 = df_los_all_d11[~df_los_all_d11['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d11) ***', '\\n')\n",
    "print(df_los_all_d11.shape , '\\n')\n",
    "\n",
    "# clean data - los_all_d12\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Original (los_all_d12) ***', '\\n')\n",
    "print(df_los_all_d12.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d12 = df_los_all_d12[~df_los_all_d12['CO'].isnull()]\n",
    "df_los_all_d12 = df_los_all_d12[~df_los_all_d12['RTE'].isnull()]\n",
    "# check table dim\n",
    "print('*** Table Dimensions: Remove null dist/co/rte (los_all_d12) ***', '\\n')\n",
    "print(df_los_all_d12.shape , '\\n')\n",
    "\n",
    "# export final csv file\n",
    "write_data_csv(\n",
    "    df_los_all_d1,\n",
    "    'data/05.01.03_data_clean_los_all_d1.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d2,\n",
    "    'data/05.01.03_data_clean_los_all_d2.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d3,\n",
    "    'data/05.01.03_data_clean_los_all_d3.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d4,\n",
    "    'data/05.01.03_data_clean_los_all_d4.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d5,\n",
    "    'data/05.01.03_data_clean_los_all_d5.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d6,\n",
    "    'data/05.01.03_data_clean_los_all_d6.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d7,\n",
    "    'data/05.01.03_data_clean_los_all_d7.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d8,\n",
    "    'data/05.01.03_data_clean_los_all_d8.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d9,\n",
    "    'data/05.01.03_data_clean_los_all_d9.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d10,\n",
    "    'data/05.01.03_data_clean_los_all_d10.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d11,\n",
    "    'data/05.01.03_data_clean_los_all_d11.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_d12,\n",
    "    'data/05.01.03_data_clean_los_all_d12.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.01 - data analysis (imms)\n",
    "\n",
    "# format data for plotting\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Data without emtpy CY values (IMMS 2023A) ***', '\\n')\n",
    "# print(df_imms_2023a.shape , '\\n')\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d1 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d1 = df_imms_2023a_bar_d1[df_imms_2023a_bar_d1['Resp. District'].astype(np.int) == 1]\n",
    "\n",
    "# subset data for additional plots on corridors with high litter totals\n",
    "# df_imms_2023a_bar_01hum101 = df_imms_2023a_bar_d1[df_imms_2023a_bar_d1['IMMS Unit ID'].str.contains('01-HUM-101')]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d2 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d2 = df_imms_2023a_bar_d2[df_imms_2023a_bar_d2['Resp. District'].astype(np.int) == 2]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d3 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d3 = df_imms_2023a_bar_d3[df_imms_2023a_bar_d3['Resp. District'].astype(np.int) == 3]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d4 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d4 = df_imms_2023a_bar_d4[df_imms_2023a_bar_d4['Resp. District'].astype(np.int) == 4]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d5 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d5 = df_imms_2023a_bar_d5[df_imms_2023a_bar_d5['Resp. District'].astype(np.int) == 5]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d6 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d6 = df_imms_2023a_bar_d6[df_imms_2023a_bar_d6['Resp. District'].astype(np.int) == 6]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d7 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d7 = df_imms_2023a_bar_d7[df_imms_2023a_bar_d7['Resp. District'].astype(np.int) == 7]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d8 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d8 = df_imms_2023a_bar_d8[df_imms_2023a_bar_d8['Resp. District'].astype(np.int) == 8]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d9 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d9 = df_imms_2023a_bar_d9[df_imms_2023a_bar_d9['Resp. District'].astype(np.int) == 9]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d10 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d10 = df_imms_2023a_bar_d10[df_imms_2023a_bar_d10['Resp. District'].astype(np.int) == 10]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d11 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d11 = df_imms_2023a_bar_d11[df_imms_2023a_bar_d11['Resp. District'].astype(np.int) == 11]\n",
    "\n",
    "# remove row if value is greater than given value\n",
    "# https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_imms_2023a_bar_d12 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "df_imms_2023a_bar_d12 = df_imms_2023a_bar_d12[df_imms_2023a_bar_d12['Resp. District'].astype(np.int) == 12]\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D1) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D2) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D3) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D4) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D5) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D6) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D7) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D8) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D9) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D10) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D11) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D12) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac005 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '03-SAC-005')\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac005 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '03-SAC-005')\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac005 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '03-SAC-005')\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac005 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '03-SAC-005')\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac005 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '03-SAC-005')\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac005 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '03-SAC-005')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac005, 'Data Profile: IMMS 2021b - 03sac005')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac005, 'Data Profile: IMMS 2022a - 03sac005')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac005, 'Data Profile: IMMS 2022b - 03sac005')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac005, 'Data Profile: IMMS 2023a - 03sac005')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac005, 'Data Profile: IMMS 2023b - 03sac005')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac005, 'Data Profile: IMMS 2024a - 03sac005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac005 = pd.concat([\n",
    "    df_imms_2021b_hotspot_03sac005,\n",
    "    df_imms_2022a_hotspot_03sac005,\n",
    "    df_imms_2022b_hotspot_03sac005,\n",
    "    df_imms_2023a_hotspot_03sac005,\n",
    "    df_imms_2023b_hotspot_03sac005,\n",
    "    df_imms_2024a_hotspot_03sac005\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_03sac005, 'Data Profile: IMMS Litter Hotspot - 03sac005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac050 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '03-SAC-050')\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac050 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '03-SAC-050')\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac050 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '03-SAC-050')\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac050 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '03-SAC-050')\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac050 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '03-SAC-050')\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac050 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '03-SAC-050')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac050, 'Data Profile: IMMS 2021b - 03sac050')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac050, 'Data Profile: IMMS 2022a - 03sac050')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac050, 'Data Profile: IMMS 2022b - 03sac050')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac050, 'Data Profile: IMMS 2023a - 03sac050')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac050, 'Data Profile: IMMS 2023b - 03sac050')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac050, 'Data Profile: IMMS 2024a - 03sac050')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac050 = pd.concat([\n",
    "    df_imms_2021b_hotspot_03sac050,\n",
    "    df_imms_2022a_hotspot_03sac050,\n",
    "    df_imms_2022b_hotspot_03sac050,\n",
    "    df_imms_2023a_hotspot_03sac050,\n",
    "    df_imms_2023b_hotspot_03sac050,\n",
    "    df_imms_2024a_hotspot_03sac050\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_03sac050, 'Data Profile: IMMS Litter Hotspot - 03sac050')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac080 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '03-SAC-080')\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac080 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '03-SAC-080')\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac080 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '03-SAC-080')\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac080 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '03-SAC-080')\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac080 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '03-SAC-080')\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac080 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '03-SAC-080')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac080, 'Data Profile: IMMS 2021b - 03sac080')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac080, 'Data Profile: IMMS 2022a - 03sac080')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac080, 'Data Profile: IMMS 2022b - 03sac080')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac080, 'Data Profile: IMMS 2023a - 03sac080')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac080, 'Data Profile: IMMS 2023b - 03sac080')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac080, 'Data Profile: IMMS 2024a - 03sac080')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac080 = pd.concat([\n",
    "    df_imms_2021b_hotspot_03sac080,\n",
    "    df_imms_2022a_hotspot_03sac080,\n",
    "    df_imms_2022b_hotspot_03sac080,\n",
    "    df_imms_2023a_hotspot_03sac080,\n",
    "    df_imms_2023b_hotspot_03sac080,\n",
    "    df_imms_2024a_hotspot_03sac080\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_03sac080, 'Data Profile: IMMS Litter Hotspot - 03sac080')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala580b = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '04-ALA-580B')\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala580b = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '04-ALA-580B')\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala580b = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '04-ALA-580B')\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala580b = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '04-ALA-580B')\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala580b = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '04-ALA-580B')\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala580b = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '04-ALA-580B')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala580b, 'Data Profile: IMMS 2021b - 04ala580b')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala580b, 'Data Profile: IMMS 2022a - 04ala580b')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala580b, 'Data Profile: IMMS 2022b - 04ala580b')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala580b, 'Data Profile: IMMS 2023a - 04ala580b')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala580b, 'Data Profile: IMMS 2023b - 04ala580b')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala580b, 'Data Profile: IMMS 2024a - 04ala580b')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala580b = pd.concat([\n",
    "    df_imms_2021b_hotspot_04ala580b,\n",
    "    df_imms_2022a_hotspot_04ala580b,\n",
    "    df_imms_2022b_hotspot_04ala580b,\n",
    "    df_imms_2023a_hotspot_04ala580b,\n",
    "    df_imms_2023b_hotspot_04ala580b,\n",
    "    df_imms_2024a_hotspot_04ala580b\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_04ala580b, 'Data Profile: IMMS Litter Hotspot - 04ala580b')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala680 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '04-ALA-680')\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala680 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '04-ALA-680')\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala680 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '04-ALA-680')\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala680 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '04-ALA-680')\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala680 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '04-ALA-680')\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala680 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '04-ALA-680')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala680, 'Data Profile: IMMS 2021b - 04ala680')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala680, 'Data Profile: IMMS 2022a - 04ala680')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala680, 'Data Profile: IMMS 2022b - 04ala680')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala680, 'Data Profile: IMMS 2023a - 04ala680')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala680, 'Data Profile: IMMS 2023b - 04ala680')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala680, 'Data Profile: IMMS 2024a - 04ala680')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala680 = pd.concat([\n",
    "    df_imms_2021b_hotspot_04ala680,\n",
    "    df_imms_2022a_hotspot_04ala680,\n",
    "    df_imms_2022b_hotspot_04ala680,\n",
    "    df_imms_2023a_hotspot_04ala680,\n",
    "    df_imms_2023b_hotspot_04ala680,\n",
    "    df_imms_2024a_hotspot_04ala680\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_04ala680, 'Data Profile: IMMS Litter Hotspot - 04ala680')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala880 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '04-ALA-880')\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala880 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '04-ALA-880')\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala880 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '04-ALA-880')\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala880 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '04-ALA-880')\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala880 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '04-ALA-880')\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala880 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '04-ALA-880')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala880, 'Data Profile: IMMS 2021b - 04ala880')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala880, 'Data Profile: IMMS 2022a - 04ala880')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala880, 'Data Profile: IMMS 2022b - 04ala880')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala880, 'Data Profile: IMMS 2023a - 04ala880')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala880, 'Data Profile: IMMS 2023b - 04ala880')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala880, 'Data Profile: IMMS 2024a - 04ala880')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala880 = pd.concat([\n",
    "    df_imms_2021b_hotspot_04ala880,\n",
    "    df_imms_2022a_hotspot_04ala880,\n",
    "    df_imms_2022b_hotspot_04ala880,\n",
    "    df_imms_2023a_hotspot_04ala880,\n",
    "    df_imms_2023b_hotspot_04ala880,\n",
    "    df_imms_2024a_hotspot_04ala880\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_04ala880, 'Data Profile: IMMS Litter Hotspot - 04ala880')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04cc004a = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '04-CC-004A')\n",
    "]\n",
    "df_imms_2022a_hotspot_04cc004a = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '04-CC-004A')\n",
    "]\n",
    "df_imms_2022b_hotspot_04cc004a = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '04-CC-004A')\n",
    "]\n",
    "df_imms_2023a_hotspot_04cc004a = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '04-CC-004A')\n",
    "]\n",
    "df_imms_2023b_hotspot_04cc004a = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '04-CC-004A')\n",
    "]\n",
    "df_imms_2024a_hotspot_04cc004a = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '04-CC-004A')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04cc004a, 'Data Profile: IMMS 2021b - 04cc004a')\n",
    "# data_profile(df_imms_2022a_hotspot_04cc004a, 'Data Profile: IMMS 2022a - 04cc004a')\n",
    "# data_profile(df_imms_2022b_hotspot_04cc004a, 'Data Profile: IMMS 2022b - 04cc004a')\n",
    "# data_profile(df_imms_2023a_hotspot_04cc004a, 'Data Profile: IMMS 2023a - 04cc004a')\n",
    "# data_profile(df_imms_2023b_hotspot_04cc004a, 'Data Profile: IMMS 2023b - 04cc004a')\n",
    "# data_profile(df_imms_2024a_hotspot_04cc004a, 'Data Profile: IMMS 2024a - 04cc004a')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04cc004a = pd.concat([\n",
    "    df_imms_2021b_hotspot_04cc004a,\n",
    "    df_imms_2022a_hotspot_04cc004a,\n",
    "    df_imms_2022b_hotspot_04cc004a,\n",
    "    df_imms_2023a_hotspot_04cc004a,\n",
    "    df_imms_2023b_hotspot_04cc004a,\n",
    "    df_imms_2024a_hotspot_04cc004a\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_04cc004a, 'Data Profile: IMMS Litter Hotspot - 04cc004a')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04cc680 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '04-CC-680')\n",
    "]\n",
    "df_imms_2022a_hotspot_04cc680 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '04-CC-680')\n",
    "]\n",
    "df_imms_2022b_hotspot_04cc680 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '04-CC-680')\n",
    "]\n",
    "df_imms_2023a_hotspot_04cc680 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '04-CC-680')\n",
    "]\n",
    "df_imms_2023b_hotspot_04cc680 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '04-CC-680')\n",
    "]\n",
    "df_imms_2024a_hotspot_04cc680 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '04-CC-680')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04cc680, 'Data Profile: IMMS 2021b - 04cc680')\n",
    "# data_profile(df_imms_2022a_hotspot_04cc680, 'Data Profile: IMMS 2022a - 04cc680')\n",
    "# data_profile(df_imms_2022b_hotspot_04cc680, 'Data Profile: IMMS 2022b - 04cc680')\n",
    "# data_profile(df_imms_2023a_hotspot_04cc680, 'Data Profile: IMMS 2023a - 04cc680')\n",
    "# data_profile(df_imms_2023b_hotspot_04cc680, 'Data Profile: IMMS 2023b - 04cc680')\n",
    "# data_profile(df_imms_2024a_hotspot_04cc680, 'Data Profile: IMMS 2024a - 04cc680')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04cc680 = pd.concat([\n",
    "    df_imms_2021b_hotspot_04cc680,\n",
    "    df_imms_2022a_hotspot_04cc680,\n",
    "    df_imms_2022b_hotspot_04cc680,\n",
    "    df_imms_2023a_hotspot_04cc680,\n",
    "    df_imms_2023b_hotspot_04cc680,\n",
    "    df_imms_2024a_hotspot_04cc680\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_04cc680, 'Data Profile: IMMS Litter Hotspot - 04cc680')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_06fre099 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '06-FRE-099')\n",
    "]\n",
    "df_imms_2022a_hotspot_06fre099 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '06-FRE-099')\n",
    "]\n",
    "df_imms_2022b_hotspot_06fre099 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '06-FRE-099')\n",
    "]\n",
    "df_imms_2023a_hotspot_06fre099 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '06-FRE-099')\n",
    "]\n",
    "df_imms_2023b_hotspot_06fre099 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '06-FRE-099')\n",
    "]\n",
    "df_imms_2024a_hotspot_06fre099 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '06-FRE-099')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_06fre099, 'Data Profile: IMMS 2021b - 06fre099')\n",
    "# data_profile(df_imms_2022a_hotspot_06fre099, 'Data Profile: IMMS 2022a - 06fre099')\n",
    "# data_profile(df_imms_2022b_hotspot_06fre099, 'Data Profile: IMMS 2022b - 06fre099')\n",
    "# data_profile(df_imms_2023a_hotspot_06fre099, 'Data Profile: IMMS 2023a - 06fre099')\n",
    "# data_profile(df_imms_2023b_hotspot_06fre099, 'Data Profile: IMMS 2023b - 06fre099')\n",
    "# data_profile(df_imms_2024a_hotspot_06fre099, 'Data Profile: IMMS 2024a - 06fre099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_06fre099 = pd.concat([\n",
    "    df_imms_2021b_hotspot_06fre099,\n",
    "    df_imms_2022a_hotspot_06fre099,\n",
    "    df_imms_2022b_hotspot_06fre099,\n",
    "    df_imms_2023a_hotspot_06fre099,\n",
    "    df_imms_2023b_hotspot_06fre099,\n",
    "    df_imms_2024a_hotspot_06fre099\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_06fre099, 'Data Profile: IMMS Litter Hotspot - 06fre099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_06ker099 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '06-KER-099')\n",
    "]\n",
    "df_imms_2022a_hotspot_06ker099 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '06-KER-099')\n",
    "]\n",
    "df_imms_2022b_hotspot_06ker099 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '06-KER-099')\n",
    "]\n",
    "df_imms_2023a_hotspot_06ker099 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '06-KER-099')\n",
    "]\n",
    "df_imms_2023b_hotspot_06ker099 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '06-KER-099')\n",
    "]\n",
    "df_imms_2024a_hotspot_06ker099 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '06-KER-099')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_06ker099, 'Data Profile: IMMS 2021b - 06ker099')\n",
    "# data_profile(df_imms_2022a_hotspot_06ker099, 'Data Profile: IMMS 2022a - 06ker099')\n",
    "# data_profile(df_imms_2022b_hotspot_06ker099, 'Data Profile: IMMS 2022b - 06ker099')\n",
    "# data_profile(df_imms_2023a_hotspot_06ker099, 'Data Profile: IMMS 2023a - 06ker099')\n",
    "# data_profile(df_imms_2023b_hotspot_06ker099, 'Data Profile: IMMS 2023b - 06ker099')\n",
    "# data_profile(df_imms_2024a_hotspot_06ker099, 'Data Profile: IMMS 2024a - 06ker099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_06ker099 = pd.concat([\n",
    "    df_imms_2021b_hotspot_06ker099,\n",
    "    df_imms_2022a_hotspot_06ker099,\n",
    "    df_imms_2022b_hotspot_06ker099,\n",
    "    df_imms_2023a_hotspot_06ker099,\n",
    "    df_imms_2023b_hotspot_06ker099,\n",
    "    df_imms_2024a_hotspot_06ker099\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_06ker099, 'Data Profile: IMMS Litter Hotspot - 06ker099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la005a = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '07-LA-005A')\n",
    "]\n",
    "df_imms_2022a_hotspot_07la005a = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '07-LA-005A')\n",
    "]\n",
    "df_imms_2022b_hotspot_07la005a = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '07-LA-005A')\n",
    "]\n",
    "df_imms_2023a_hotspot_07la005a = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '07-LA-005A')\n",
    "]\n",
    "df_imms_2023b_hotspot_07la005a = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '07-LA-005A')\n",
    "]\n",
    "df_imms_2024a_hotspot_07la005a = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '07-LA-005A')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la005a, 'Data Profile: IMMS 2021b - 07la005a')\n",
    "# data_profile(df_imms_2022a_hotspot_07la005a, 'Data Profile: IMMS 2022a - 07la005a')\n",
    "# data_profile(df_imms_2022b_hotspot_07la005a, 'Data Profile: IMMS 2022b - 07la005a')\n",
    "# data_profile(df_imms_2023a_hotspot_07la005a, 'Data Profile: IMMS 2023a - 07la005a')\n",
    "# data_profile(df_imms_2023b_hotspot_07la005a, 'Data Profile: IMMS 2023b - 07la005a')\n",
    "# data_profile(df_imms_2024a_hotspot_07la005a, 'Data Profile: IMMS 2024a - 07la005a')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la005a = pd.concat([\n",
    "    df_imms_2021b_hotspot_07la005a,\n",
    "    df_imms_2022a_hotspot_07la005a,\n",
    "    df_imms_2022b_hotspot_07la005a,\n",
    "    df_imms_2023a_hotspot_07la005a,\n",
    "    df_imms_2023b_hotspot_07la005a,\n",
    "    df_imms_2024a_hotspot_07la005a\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_07la005a, 'Data Profile: IMMS Litter Hotspot - 07la005a')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la010 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '07-LA-010')\n",
    "]\n",
    "df_imms_2022a_hotspot_07la010 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '07-LA-010')\n",
    "]\n",
    "df_imms_2022b_hotspot_07la010 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '07-LA-010')\n",
    "]\n",
    "df_imms_2023a_hotspot_07la010 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '07-LA-010')\n",
    "]\n",
    "df_imms_2023b_hotspot_07la010 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '07-LA-010')\n",
    "]\n",
    "df_imms_2024a_hotspot_07la010 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '07-LA-010')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la010, 'Data Profile: IMMS 2021b - 07la010')\n",
    "# data_profile(df_imms_2022a_hotspot_07la010, 'Data Profile: IMMS 2022a - 07la010')\n",
    "# data_profile(df_imms_2022b_hotspot_07la010, 'Data Profile: IMMS 2022b - 07la010')\n",
    "# data_profile(df_imms_2023a_hotspot_07la010, 'Data Profile: IMMS 2023a - 07la010')\n",
    "# data_profile(df_imms_2023b_hotspot_07la010, 'Data Profile: IMMS 2023b - 07la010')\n",
    "# data_profile(df_imms_2024a_hotspot_07la010, 'Data Profile: IMMS 2024a - 07la010')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la010 = pd.concat([\n",
    "    df_imms_2021b_hotspot_07la010,\n",
    "    df_imms_2022a_hotspot_07la010,\n",
    "    df_imms_2022b_hotspot_07la010,\n",
    "    df_imms_2023a_hotspot_07la010,\n",
    "    df_imms_2023b_hotspot_07la010,\n",
    "    df_imms_2024a_hotspot_07la010\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_07la010, 'Data Profile: IMMS Litter Hotspot - 07la010')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la101 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '07-LA-101')\n",
    "]\n",
    "df_imms_2022a_hotspot_07la101 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '07-LA-101')\n",
    "]\n",
    "df_imms_2022b_hotspot_07la101 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '07-LA-101')\n",
    "]\n",
    "df_imms_2023a_hotspot_07la101 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '07-LA-101')\n",
    "]\n",
    "df_imms_2023b_hotspot_07la101 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '07-LA-101')\n",
    "]\n",
    "df_imms_2024a_hotspot_07la101 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '07-LA-101')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la101, 'Data Profile: IMMS 2021b - 07la101')\n",
    "# data_profile(df_imms_2022a_hotspot_07la101, 'Data Profile: IMMS 2022a - 07la101')\n",
    "# data_profile(df_imms_2022b_hotspot_07la101, 'Data Profile: IMMS 2022b - 07la101')\n",
    "# data_profile(df_imms_2023a_hotspot_07la101, 'Data Profile: IMMS 2023a - 07la101')\n",
    "# data_profile(df_imms_2023b_hotspot_07la101, 'Data Profile: IMMS 2023b - 07la101')\n",
    "# data_profile(df_imms_2024a_hotspot_07la101, 'Data Profile: IMMS 2024a - 07la101')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la101 = pd.concat([\n",
    "    df_imms_2021b_hotspot_07la101,\n",
    "    df_imms_2022a_hotspot_07la101,\n",
    "    df_imms_2022b_hotspot_07la101,\n",
    "    df_imms_2023a_hotspot_07la101,\n",
    "    df_imms_2023b_hotspot_07la101,\n",
    "    df_imms_2024a_hotspot_07la101\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_07la101, 'Data Profile: IMMS Litter Hotspot - 07la101')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la110 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '07-LA-110')\n",
    "]\n",
    "df_imms_2022a_hotspot_07la110 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '07-LA-110')\n",
    "]\n",
    "df_imms_2022b_hotspot_07la110 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '07-LA-110')\n",
    "]\n",
    "df_imms_2023a_hotspot_07la110 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '07-LA-110')\n",
    "]\n",
    "df_imms_2023b_hotspot_07la110 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '07-LA-110')\n",
    "]\n",
    "df_imms_2024a_hotspot_07la110 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '07-LA-110')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la110, 'Data Profile: IMMS 2021b - 07la110')\n",
    "# data_profile(df_imms_2022a_hotspot_07la110, 'Data Profile: IMMS 2022a - 07la110')\n",
    "# data_profile(df_imms_2022b_hotspot_07la110, 'Data Profile: IMMS 2022b - 07la110')\n",
    "# data_profile(df_imms_2023a_hotspot_07la110, 'Data Profile: IMMS 2023a - 07la110')\n",
    "# data_profile(df_imms_2023b_hotspot_07la110, 'Data Profile: IMMS 2023b - 07la110')\n",
    "# data_profile(df_imms_2024a_hotspot_07la110, 'Data Profile: IMMS 2024a - 07la110')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la110 = pd.concat([\n",
    "    df_imms_2021b_hotspot_07la110,\n",
    "    df_imms_2022a_hotspot_07la110,\n",
    "    df_imms_2022b_hotspot_07la110,\n",
    "    df_imms_2023a_hotspot_07la110,\n",
    "    df_imms_2023b_hotspot_07la110,\n",
    "    df_imms_2024a_hotspot_07la110\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_07la110, 'Data Profile: IMMS Litter Hotspot - 07la110')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la405 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '07-LA-405')\n",
    "]\n",
    "df_imms_2022a_hotspot_07la405 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '07-LA-405')\n",
    "]\n",
    "df_imms_2022b_hotspot_07la405 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '07-LA-405')\n",
    "]\n",
    "df_imms_2023a_hotspot_07la405 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '07-LA-405')\n",
    "]\n",
    "df_imms_2023b_hotspot_07la405 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '07-LA-405')\n",
    "]\n",
    "df_imms_2024a_hotspot_07la405 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '07-LA-405')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la405, 'Data Profile: IMMS 2021b - 07la405')\n",
    "# data_profile(df_imms_2022a_hotspot_07la405, 'Data Profile: IMMS 2022a - 07la405')\n",
    "# data_profile(df_imms_2022b_hotspot_07la405, 'Data Profile: IMMS 2022b - 07la405')\n",
    "# data_profile(df_imms_2023a_hotspot_07la405, 'Data Profile: IMMS 2023a - 07la405')\n",
    "# data_profile(df_imms_2023b_hotspot_07la405, 'Data Profile: IMMS 2023b - 07la405')\n",
    "# data_profile(df_imms_2024a_hotspot_07la405, 'Data Profile: IMMS 2024a - 07la405')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la405 = pd.concat([\n",
    "    df_imms_2021b_hotspot_07la405,\n",
    "    df_imms_2022a_hotspot_07la405,\n",
    "    df_imms_2022b_hotspot_07la405,\n",
    "    df_imms_2023a_hotspot_07la405,\n",
    "    df_imms_2023b_hotspot_07la405,\n",
    "    df_imms_2024a_hotspot_07la405\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_07la405, 'Data Profile: IMMS Litter Hotspot - 07la405')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_08riv010 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '08-RIV-010')\n",
    "]\n",
    "df_imms_2022a_hotspot_08riv010 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '08-RIV-010')\n",
    "]\n",
    "df_imms_2022b_hotspot_08riv010 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '08-RIV-010')\n",
    "]\n",
    "df_imms_2023a_hotspot_08riv010 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '08-RIV-010')\n",
    "]\n",
    "df_imms_2023b_hotspot_08riv010 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '08-RIV-010')\n",
    "]\n",
    "df_imms_2024a_hotspot_08riv010 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '08-RIV-010')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_08riv010, 'Data Profile: IMMS 2021b - 08riv010')\n",
    "# data_profile(df_imms_2022a_hotspot_08riv010, 'Data Profile: IMMS 2022a - 08riv010')\n",
    "# data_profile(df_imms_2022b_hotspot_08riv010, 'Data Profile: IMMS 2022b - 08riv010')\n",
    "# data_profile(df_imms_2023a_hotspot_08riv010, 'Data Profile: IMMS 2023a - 08riv010')\n",
    "# data_profile(df_imms_2023b_hotspot_08riv010, 'Data Profile: IMMS 2023b - 08riv010')\n",
    "# data_profile(df_imms_2024a_hotspot_08riv010, 'Data Profile: IMMS 2024a - 08riv010')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_08riv010 = pd.concat([\n",
    "    df_imms_2021b_hotspot_08riv010,\n",
    "    df_imms_2022a_hotspot_08riv010,\n",
    "    df_imms_2022b_hotspot_08riv010,\n",
    "    df_imms_2023a_hotspot_08riv010,\n",
    "    df_imms_2023b_hotspot_08riv010,\n",
    "    df_imms_2024a_hotspot_08riv010\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_08riv010, 'Data Profile: IMMS Litter Hotspot - 08riv010')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_08riv060 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '08-RIV-060')\n",
    "]\n",
    "df_imms_2022a_hotspot_08riv060 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '08-RIV-060')\n",
    "]\n",
    "df_imms_2022b_hotspot_08riv060 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '08-RIV-060')\n",
    "]\n",
    "df_imms_2023a_hotspot_08riv060 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '08-RIV-060')\n",
    "]\n",
    "df_imms_2023b_hotspot_08riv060 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '08-RIV-060')\n",
    "]\n",
    "df_imms_2024a_hotspot_08riv060 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '08-RIV-060')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_08riv060, 'Data Profile: IMMS 2021b - 08riv060')\n",
    "# data_profile(df_imms_2022a_hotspot_08riv060, 'Data Profile: IMMS 2022a - 08riv060')\n",
    "# data_profile(df_imms_2022b_hotspot_08riv060, 'Data Profile: IMMS 2022b - 08riv060')\n",
    "# data_profile(df_imms_2023a_hotspot_08riv060, 'Data Profile: IMMS 2023a - 08riv060')\n",
    "# data_profile(df_imms_2023b_hotspot_08riv060, 'Data Profile: IMMS 2023b - 08riv060')\n",
    "# data_profile(df_imms_2024a_hotspot_08riv060, 'Data Profile: IMMS 2024a - 08riv060')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_08riv060 = pd.concat([\n",
    "    df_imms_2021b_hotspot_08riv060,\n",
    "    df_imms_2022a_hotspot_08riv060,\n",
    "    df_imms_2022b_hotspot_08riv060,\n",
    "    df_imms_2023a_hotspot_08riv060,\n",
    "    df_imms_2023b_hotspot_08riv060,\n",
    "    df_imms_2024a_hotspot_08riv060\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_08riv060, 'Data Profile: IMMS Litter Hotspot - 08riv060')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_10sj005 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '10-SJ-005')\n",
    "]\n",
    "df_imms_2022a_hotspot_10sj005 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '10-SJ-005')\n",
    "]\n",
    "df_imms_2022b_hotspot_10sj005 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '10-SJ-005')\n",
    "]\n",
    "df_imms_2023a_hotspot_10sj005 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '10-SJ-005')\n",
    "]\n",
    "df_imms_2023b_hotspot_10sj005 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '10-SJ-005')\n",
    "]\n",
    "df_imms_2024a_hotspot_10sj005 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '10-SJ-005')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_10sj005, 'Data Profile: IMMS 2021b - 10sj005')\n",
    "# data_profile(df_imms_2022a_hotspot_10sj005, 'Data Profile: IMMS 2022a - 10sj005')\n",
    "# data_profile(df_imms_2022b_hotspot_10sj005, 'Data Profile: IMMS 2022b - 10sj005')\n",
    "# data_profile(df_imms_2023a_hotspot_10sj005, 'Data Profile: IMMS 2023a - 10sj005')\n",
    "# data_profile(df_imms_2023b_hotspot_10sj005, 'Data Profile: IMMS 2023b - 10sj005')\n",
    "# data_profile(df_imms_2024a_hotspot_10sj005, 'Data Profile: IMMS 2024a - 10sj005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_10sj005 = pd.concat([\n",
    "    df_imms_2021b_hotspot_10sj005,\n",
    "    df_imms_2022a_hotspot_10sj005,\n",
    "    df_imms_2022b_hotspot_10sj005,\n",
    "    df_imms_2023a_hotspot_10sj005,\n",
    "    df_imms_2023b_hotspot_10sj005,\n",
    "    df_imms_2024a_hotspot_10sj005\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_10sj005, 'Data Profile: IMMS Litter Hotspot - 10sj005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_10sj099 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '10-SJ-099')\n",
    "]\n",
    "df_imms_2022a_hotspot_10sj099 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '10-SJ-099')\n",
    "]\n",
    "df_imms_2022b_hotspot_10sj099 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '10-SJ-099')\n",
    "]\n",
    "df_imms_2023a_hotspot_10sj099 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '10-SJ-099')\n",
    "]\n",
    "df_imms_2023b_hotspot_10sj099 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '10-SJ-099')\n",
    "]\n",
    "df_imms_2024a_hotspot_10sj099 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '10-SJ-099')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_10sj099, 'Data Profile: IMMS 2021b - 10sj099')\n",
    "# data_profile(df_imms_2022a_hotspot_10sj099, 'Data Profile: IMMS 2022a - 10sj099')\n",
    "# data_profile(df_imms_2022b_hotspot_10sj099, 'Data Profile: IMMS 2022b - 10sj099')\n",
    "# data_profile(df_imms_2023a_hotspot_10sj099, 'Data Profile: IMMS 2023a - 10sj099')\n",
    "# data_profile(df_imms_2023b_hotspot_10sj099, 'Data Profile: IMMS 2023b - 10sj099')\n",
    "# data_profile(df_imms_2024a_hotspot_10sj099, 'Data Profile: IMMS 2024a - 10sj099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_10sj099 = pd.concat([\n",
    "    df_imms_2021b_hotspot_10sj099,\n",
    "    df_imms_2022a_hotspot_10sj099,\n",
    "    df_imms_2022b_hotspot_10sj099,\n",
    "    df_imms_2023a_hotspot_10sj099,\n",
    "    df_imms_2023b_hotspot_10sj099,\n",
    "    df_imms_2024a_hotspot_10sj099\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_10sj099, 'Data Profile: IMMS Litter Hotspot - 10sj099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_11sd005 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '11-SD-005')\n",
    "]\n",
    "df_imms_2022a_hotspot_11sd005 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '11-SD-005')\n",
    "]\n",
    "df_imms_2022b_hotspot_11sd005 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '11-SD-005')\n",
    "]\n",
    "df_imms_2023a_hotspot_11sd005 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '11-SD-005')\n",
    "]\n",
    "df_imms_2023b_hotspot_11sd005 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '11-SD-005')\n",
    "]\n",
    "df_imms_2024a_hotspot_11sd005 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '11-SD-005')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_11sd005, 'Data Profile: IMMS 2021b - 11sd005')\n",
    "# data_profile(df_imms_2022a_hotspot_11sd005, 'Data Profile: IMMS 2022a - 11sd005')\n",
    "# data_profile(df_imms_2022b_hotspot_11sd005, 'Data Profile: IMMS 2022b - 11sd005')\n",
    "# data_profile(df_imms_2023a_hotspot_11sd005, 'Data Profile: IMMS 2023a - 11sd005')\n",
    "# data_profile(df_imms_2023b_hotspot_11sd005, 'Data Profile: IMMS 2023b - 11sd005')\n",
    "# data_profile(df_imms_2024a_hotspot_11sd005, 'Data Profile: IMMS 2024a - 11sd005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_11sd005 = pd.concat([\n",
    "    df_imms_2021b_hotspot_11sd005,\n",
    "    df_imms_2022a_hotspot_11sd005,\n",
    "    df_imms_2022b_hotspot_11sd005,\n",
    "    df_imms_2023a_hotspot_11sd005,\n",
    "    df_imms_2023b_hotspot_11sd005,\n",
    "    df_imms_2024a_hotspot_11sd005\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_11sd005, 'Data Profile: IMMS Litter Hotspot - 11sd005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_11sd805 = df_imms_2021b[\n",
    "    (df_imms_2021b['IMMS Unit ID'] == '11-SD-805')\n",
    "]\n",
    "df_imms_2022a_hotspot_11sd805 = df_imms_2022a[\n",
    "    (df_imms_2022a['IMMS Unit ID'] == '11-SD-805')\n",
    "]\n",
    "df_imms_2022b_hotspot_11sd805 = df_imms_2022b[\n",
    "    (df_imms_2022b['IMMS Unit ID'] == '11-SD-805')\n",
    "]\n",
    "df_imms_2023a_hotspot_11sd805 = df_imms_2023a[\n",
    "    (df_imms_2023a['IMMS Unit ID'] == '11-SD-805')\n",
    "]\n",
    "df_imms_2023b_hotspot_11sd805 = df_imms_2023b[\n",
    "    (df_imms_2023b['IMMS Unit ID'] == '11-SD-805')\n",
    "]\n",
    "df_imms_2024a_hotspot_11sd805 = df_imms_2024a[\n",
    "    (df_imms_2024a['IMMS Unit ID'] == '11-SD-805')\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_11sd805, 'Data Profile: IMMS 2021b - 11sd805')\n",
    "# data_profile(df_imms_2022a_hotspot_11sd805, 'Data Profile: IMMS 2022a - 11sd805')\n",
    "# data_profile(df_imms_2022b_hotspot_11sd805, 'Data Profile: IMMS 2022b - 11sd805')\n",
    "# data_profile(df_imms_2023a_hotspot_11sd805, 'Data Profile: IMMS 2023a - 11sd805')\n",
    "# data_profile(df_imms_2023b_hotspot_11sd805, 'Data Profile: IMMS 2023b - 11sd805')\n",
    "# data_profile(df_imms_2024a_hotspot_11sd805, 'Data Profile: IMMS 2024a - 11sd805')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_11sd805 = pd.concat([\n",
    "    df_imms_2021b_hotspot_11sd805,\n",
    "    df_imms_2022a_hotspot_11sd805,\n",
    "    df_imms_2022b_hotspot_11sd805,\n",
    "    df_imms_2023a_hotspot_11sd805,\n",
    "    df_imms_2023b_hotspot_11sd805,\n",
    "    df_imms_2024a_hotspot_11sd805\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_11sd805, 'Data Profile: IMMS Litter Hotspot - 11sd805')\n",
    "\n",
    "# create dataframe with all hotspots for analysis\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_all = pd.concat([\n",
    "    df_imms_hotspot_03sac005,\n",
    "    df_imms_hotspot_03sac050,\n",
    "    df_imms_hotspot_03sac080,\n",
    "    df_imms_hotspot_04ala580b,\n",
    "    df_imms_hotspot_04ala680,\n",
    "    df_imms_hotspot_04ala880,\n",
    "    df_imms_hotspot_04cc004a,\n",
    "    df_imms_hotspot_04cc680,\n",
    "    df_imms_hotspot_06fre099,\n",
    "    df_imms_hotspot_06ker099,\n",
    "    df_imms_hotspot_07la005a,\n",
    "    df_imms_hotspot_07la010,\n",
    "    df_imms_hotspot_07la101,\n",
    "    df_imms_hotspot_07la110,\n",
    "    df_imms_hotspot_07la405,\n",
    "    df_imms_hotspot_08riv010,\n",
    "    df_imms_hotspot_08riv060,\n",
    "    df_imms_hotspot_11sd005,\n",
    "    df_imms_hotspot_11sd805\n",
    "], axis=0)\n",
    "# data_profile(df_imms_hotspot_all, 'Data Profile: IMMS Litter Hotspot - Total')\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_count = df_imms_hotspot_all.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_count,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Activity Count'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_sum = df_imms_hotspot_all[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_sum = df_imms_hotspot_all_activity_sum.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_sum,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Activity Sum'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_cost = df_imms_hotspot_all[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_cost = df_imms_hotspot_all_activity_cost.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_cost,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Total Cost'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (total labor)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_labor = df_imms_hotspot_all[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'P.Y.s'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_labor = df_imms_hotspot_all_activity_labor.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_labor,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Total Labor'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.02 - data analysis for stacked charts (imms)\n",
    "\n",
    "# concatenate all time periods to analyze frequency/CY by district\n",
    "df_imms_all_periods = pd.concat([\n",
    "    df_imms_2021b,\n",
    "    df_imms_2022a,\n",
    "    df_imms_2022b,\n",
    "    df_imms_2023a,\n",
    "    df_imms_2023b,\n",
    "    df_imms_2024a\n",
    "], axis=0)\n",
    "# data_profile(\n",
    "#     df_imms_all_periods,\n",
    "#     'Data Profile: IMMS Litter Collection - All Periods'\n",
    "# )\n",
    "# subset dataframe by district\n",
    "df_imms_all_periods_d1 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 1)\n",
    "]\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - All Periods (D1)'\n",
    "# )\n",
    "df_imms_all_periods_d2 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 2)\n",
    "]\n",
    "df_imms_all_periods_d3 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 3)\n",
    "]\n",
    "df_imms_all_periods_d4 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 4)\n",
    "]\n",
    "df_imms_all_periods_d5 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 5)\n",
    "]\n",
    "df_imms_all_periods_d6 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 6)\n",
    "]\n",
    "df_imms_all_periods_d7 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 7)\n",
    "]\n",
    "df_imms_all_periods_d8 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 8)\n",
    "]\n",
    "df_imms_all_periods_d9 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 9)\n",
    "]\n",
    "df_imms_all_periods_d10 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 10)\n",
    "]\n",
    "df_imms_all_periods_d11 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 11)\n",
    "]\n",
    "df_imms_all_periods_d12 = df_imms_all_periods[\n",
    "    (df_imms_all_periods['Resp. District'] == 12)\n",
    "]\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d1 = df_imms_all_periods_d1.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d2 = df_imms_all_periods_d2.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d3 = df_imms_all_periods_d3.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d4 = df_imms_all_periods_d4.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d5 = df_imms_all_periods_d5.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d6 = df_imms_all_periods_d6.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d7 = df_imms_all_periods_d7.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d8 = df_imms_all_periods_d8.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d9 = df_imms_all_periods_d9.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d10 = df_imms_all_periods_d10.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d11 = df_imms_all_periods_d11.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d12 = df_imms_all_periods_d12.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).size().unstack('Activity Description')\n",
    "\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D1)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d2,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D2)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d3,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D3)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d4,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D4)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d5,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D5)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d6,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D6)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d7,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D7)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d8,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D8)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d9,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D9)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d10,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D10)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d11,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D11)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d12,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D12)'\n",
    "# )\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d1 = df_imms_all_periods_d1[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d1 = df_imms_all_periods_activity_sum_d1.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d2 = df_imms_all_periods_d2[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d2 = df_imms_all_periods_activity_sum_d2.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d3 = df_imms_all_periods_d3[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d3 = df_imms_all_periods_activity_sum_d3.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d4 = df_imms_all_periods_d4[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d4 = df_imms_all_periods_activity_sum_d4.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d5 = df_imms_all_periods_d5[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d5 = df_imms_all_periods_activity_sum_d5.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d6 = df_imms_all_periods_d6[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d6 = df_imms_all_periods_activity_sum_d6.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d7 = df_imms_all_periods_d7[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d7 = df_imms_all_periods_activity_sum_d7.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d8 = df_imms_all_periods_d8[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d8 = df_imms_all_periods_activity_sum_d8.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d9 = df_imms_all_periods_d9[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d9 = df_imms_all_periods_activity_sum_d9.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d10 = df_imms_all_periods_d10[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d10 = df_imms_all_periods_activity_sum_d10.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d11 = df_imms_all_periods_d11[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d11 = df_imms_all_periods_activity_sum_d11.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d12 = df_imms_all_periods_d12[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Production Quantity'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d12 = df_imms_all_periods_activity_sum_d12.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D1)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d2,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D2)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d3,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D3)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d4,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D4)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d5,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D5)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d6,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D6)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d7,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D7)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d8,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D8)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d9,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D9)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d10,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D10)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d11,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D11)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d12,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D12)'\n",
    "# )\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d1 = df_imms_all_periods_d1[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d1 = df_imms_all_periods_activity_cost_d1.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d2 = df_imms_all_periods_d2[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d2 = df_imms_all_periods_activity_cost_d2.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d3 = df_imms_all_periods_d3[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d3 = df_imms_all_periods_activity_cost_d3.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d4 = df_imms_all_periods_d4[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d4 = df_imms_all_periods_activity_cost_d4.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d5 = df_imms_all_periods_d5[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d5 = df_imms_all_periods_activity_cost_d5.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d6 = df_imms_all_periods_d6[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d6 = df_imms_all_periods_activity_cost_d6.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d7 = df_imms_all_periods_d7[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d7 = df_imms_all_periods_activity_cost_d7.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d8 = df_imms_all_periods_d8[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d8 = df_imms_all_periods_activity_cost_d8.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d9 = df_imms_all_periods_d9[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d9 = df_imms_all_periods_activity_cost_d9.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d10 = df_imms_all_periods_d10[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d10 = df_imms_all_periods_activity_cost_d10.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d11 = df_imms_all_periods_d11[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d11 = df_imms_all_periods_activity_cost_d11.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d12 = df_imms_all_periods_d12[[\n",
    "    'IMMS Unit ID', 'Activity Description', 'Total Cost'\n",
    "]]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d12 = df_imms_all_periods_activity_cost_d12.groupby([\n",
    "    'IMMS Unit ID', 'Activity Description'\n",
    "]).sum().unstack('Activity Description')\n",
    "\n",
    "# preview results\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d1,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D1)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d2,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D2)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d3,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D3)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d4,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D4)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d5,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D5)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d6,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D6)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d7,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D7)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d8,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D8)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d9,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D9)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d10,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D10)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d11,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D11)'\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d12,\n",
    "    'Data Profile: IMMS Litter Collection - Activity Sum (D12)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.03 - data analysis (csr)\n",
    "\n",
    "# format data for plotting\n",
    "\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "df_csr_2023a_bar_d1 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 1]\n",
    "df_csr_2023a_bar_d2 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 2]\n",
    "df_csr_2023a_bar_d3 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 3]\n",
    "df_csr_2023a_bar_d4 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 4]\n",
    "df_csr_2023a_bar_d5 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 5]\n",
    "df_csr_2023a_bar_d6 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 6]\n",
    "df_csr_2023a_bar_d7 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 7]\n",
    "df_csr_2023a_bar_d8 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 8]\n",
    "df_csr_2023a_bar_d9 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 9]\n",
    "df_csr_2023a_bar_d10 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 10]\n",
    "df_csr_2023a_bar_d11 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 11]\n",
    "df_csr_2023a_bar_d12 = df_csr_2023a[df_csr_2023a[\n",
    "    'Responsible District'\n",
    "].astype(np.int) == 12]\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null date/loc values (D1) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D2) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D3) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D4) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D5) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D6) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D7) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D8) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D9) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D10) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D11) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D12) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# concatenate all time periods for analysis\n",
    "df_csr_all_periods = pd.concat([\n",
    "    df_csr_2021b,\n",
    "    df_csr_2022a,\n",
    "    df_csr_2022b,\n",
    "    df_csr_2023a,\n",
    "    df_csr_2023b,\n",
    "    df_csr_2024a\n",
    "], axis=0)\n",
    "data_profile(\n",
    "    df_csr_all_periods,\n",
    "    'Data Profile: CSR - All Periods'\n",
    ")\n",
    "\n",
    "# subset all periods by district\n",
    "df_csr_all_periods_d1 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 1)\n",
    "]\n",
    "df_csr_all_periods_d2 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 2)\n",
    "]\n",
    "df_csr_all_periods_d3 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 3)\n",
    "]\n",
    "df_csr_all_periods_d4 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 4)\n",
    "]\n",
    "df_csr_all_periods_d5 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 5)\n",
    "]\n",
    "df_csr_all_periods_d6 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 6)\n",
    "]\n",
    "df_csr_all_periods_d7 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 7)\n",
    "]\n",
    "df_csr_all_periods_d8 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 8)\n",
    "]\n",
    "df_csr_all_periods_d9 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 9)\n",
    "]\n",
    "df_csr_all_periods_d10 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 10)\n",
    "]\n",
    "df_csr_all_periods_d11 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 11)\n",
    "]\n",
    "df_csr_all_periods_d12 = df_csr_all_periods[\n",
    "    (df_csr_all_periods['Responsible District'] == 12)\n",
    "]\n",
    "\n",
    "# aggregate total count based on dist/county/route\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_csr_all_periods_route_count_d1 = df_csr_all_periods_d1.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d2 = df_csr_all_periods_d2.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d3 = df_csr_all_periods_d3.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d4 = df_csr_all_periods_d4.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d5 = df_csr_all_periods_d5.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d6 = df_csr_all_periods_d6.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d7 = df_csr_all_periods_d7.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d8 = df_csr_all_periods_d8.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d9 = df_csr_all_periods_d9.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d10 = df_csr_all_periods_d10.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d11 = df_csr_all_periods_d11.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "df_csr_all_periods_route_count_d12 = df_csr_all_periods_d12.groupby([\n",
    "    'County', 'Route'\n",
    "]).size().unstack('Route')\n",
    "\n",
    "# preview results\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d1,\n",
    "    'Data Profile: CSR - Count by Route (D1)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d2,\n",
    "    'Data Profile: CSR - Count by Route (D2)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d3,\n",
    "    'Data Profile: CSR - Count by Route (D3)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d4,\n",
    "    'Data Profile: CSR - Count by Route (D4)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d5,\n",
    "    'Data Profile: CSR - Count by Route (D5)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d6,\n",
    "    'Data Profile: CSR - Count by Route (D6)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d7,\n",
    "    'Data Profile: CSR - Count by Route (D7)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d8,\n",
    "    'Data Profile: CSR - Count by Route (D8)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d9,\n",
    "    'Data Profile: CSR - Count by Route (D9)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d10,\n",
    "    'Data Profile: CSR - Count by Route (D10)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d11,\n",
    "    'Data Profile: CSR - Count by Route (D11)'\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d12,\n",
    "    'Data Profile: CSR - Count by Route (D12)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.04 - data analysis (los)\n",
    "\n",
    "# format data for plotting\n",
    "\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_los_2023a_bar_d1 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 1]\n",
    "# df_los_2023a_bar_d2 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 2]\n",
    "# df_los_2023a_bar_d3 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 3]\n",
    "# df_los_2023a_bar_d4 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 4]\n",
    "# df_los_2023a_bar_d5 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 5]\n",
    "# df_los_2023a_bar_d6 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 6]\n",
    "# df_los_2023a_bar_d7 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 7]\n",
    "# df_los_2023a_bar_d8 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 8]\n",
    "# df_los_2023a_bar_d9 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 9]\n",
    "# df_los_2023a_bar_d10 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 10]\n",
    "# df_los_2023a_bar_d11 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 11]\n",
    "# df_los_2023a_bar_d12 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 12]\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null date/loc values (D1) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D2) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D3) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D4) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D5) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D6) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D7) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D8) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D9) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D10) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D11) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D12) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d1['Average LOS score']= df_los_2023a_d1[df_los_2023a_d1['Average LOS score'] != '#DIV/0!']\n",
    "# group los records for plot\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d1 = df_los_2023a_d1.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d1, 'Data Profile: los_avg_2023a_d1')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d2['Average LOS score']= df_los_2023a_d2[df_los_2023a_d2['Average LOS score'] != '#DIV/0!']\n",
    "# group los records for plot\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d2 = df_los_2023a_d2.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d2, 'Data Profile: los_avg_2023a_d2')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d3['Average LOS score']= df_los_2023a_d3[df_los_2023a_d3['Average LOS score'] != '#DIV/0!']\n",
    "# group los records for plot\n",
    "df_los_2023a_d3['Average LOS score']= df_los_2023a_d3['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d3 = df_los_2023a_d3.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d3, 'Data Profile: los_avg_2023a_d3')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d4, 'Data Profile: los_avg_2023a_d4')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d4['Average LOS score']= df_los_2023a_d4[df_los_2023a_d4['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_2023a_d4['Average LOS score']= df_los_2023a_d4['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d4 = df_los_2023a_d4.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d5, 'Data Profile: los_avg_2023a_d5')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d5['Average LOS score']= df_los_2023a_d5[df_los_2023a_d5['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d5['Average LOS score']= df_los_2023a_d5['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d5 = df_los_2023a_d5.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d6, 'Data Profile: los_avg_2023a_d6')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d6['Average LOS score']= df_los_2023a_d6[df_los_2023a_d6['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d6['Average LOS score']= df_los_2023a_d6['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d6 = df_los_2023a_d6.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d7, 'Data Profile: los_avg_2023a_d7')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d7['Average LOS score']= df_los_2023a_d7[df_los_2023a_d7['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d7['Average LOS score']= df_los_2023a_d7['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d7 = df_los_2023a_d7.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d8, 'Data Profile: los_avg_2023a_d8')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d8['Average LOS score']= df_los_2023a_d8[df_los_2023a_d8['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d8['Average LOS score']= df_los_2023a_d8['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d8 = df_los_2023a_d8.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d9, 'Data Profile: los_avg_2023a_d9')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d9['Average LOS score']= df_los_2023a_d9[df_los_2023a_d9['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d9['Average LOS score']= df_los_2023a_d9['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d9 = df_los_2023a_d9.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d10, 'Data Profile: los_avg_2023a_d10')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d10['Average LOS score']= df_los_2023a_d10[df_los_2023a_d10['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d10['Average LOS score']= df_los_2023a_d10['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d10 = df_los_2023a_d10.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d11, 'Data Profile: los_avg_2023a_d11')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d11['Average LOS score']= df_los_2023a_d11[df_los_2023a_d11['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d11['Average LOS score']= df_los_2023a_d11['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d11 = df_los_2023a_d11.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d12, 'Data Profile: los_avg_2023a_d12')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d12['Average LOS score']= df_los_2023a_d12[df_los_2023a_d12['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d12['Average LOS score']= df_los_2023a_d12['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d12 = df_los_2023a_d12.groupby(['CO', 'RTE'])['Average LOS score'].mean().reset_index(name='Average LOS score')\n",
    "\n",
    "# convert county to string for county/route column\n",
    "convert_str(df_los_all_d1, 'RTE')\n",
    "convert_str(df_los_all_d2, 'RTE')\n",
    "convert_str(df_los_all_d3, 'RTE')\n",
    "convert_str(df_los_all_d4, 'RTE')\n",
    "convert_str(df_los_all_d5, 'RTE')\n",
    "convert_str(df_los_all_d6, 'RTE')\n",
    "convert_str(df_los_all_d7, 'RTE')\n",
    "convert_str(df_los_all_d8, 'RTE')\n",
    "convert_str(df_los_all_d9, 'RTE')\n",
    "convert_str(df_los_all_d10, 'RTE')\n",
    "convert_str(df_los_all_d11, 'RTE')\n",
    "convert_str(df_los_all_d12, 'RTE')\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d1 = df_los_all_d1[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d1['co_rte'] = df_los_all_d1['CO'] + '-' + df_los_all_d1['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d2 = df_los_all_d2[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d2['co_rte'] = df_los_all_d2['CO'] + '-' + df_los_all_d2['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d3 = df_los_all_d3[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d3['co_rte'] = df_los_all_d3['CO'] + '-' + df_los_all_d3['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d4 = df_los_all_d4[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d4['co_rte'] = df_los_all_d4['CO'] + '-' + df_los_all_d4['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d5 = df_los_all_d5[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d5['co_rte'] = df_los_all_d5['CO'] + '-' + df_los_all_d5['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d6 = df_los_all_d6[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d6['co_rte'] = df_los_all_d6['CO'] + '-' + df_los_all_d6['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d7 = df_los_all_d7[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d7['co_rte'] = df_los_all_d7['CO'] + '-' + df_los_all_d7['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d8 = df_los_all_d8[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d8['co_rte'] = df_los_all_d8['CO'] + '-' + df_los_all_d8['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d9 = df_los_all_d9[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d9['co_rte'] = df_los_all_d9['CO'] + '-' + df_los_all_d9['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d10 = df_los_all_d10[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d10['co_rte'] = df_los_all_d10['CO'] + '-' + df_los_all_d10['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d11 = df_los_all_d11[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d11['co_rte'] = df_los_all_d11['CO'] + '-' + df_los_all_d11['RTE']\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d12 = df_los_all_d12[[\n",
    "    'CO',\n",
    "    'RTE',\n",
    "    'los_2022_q1',\n",
    "    'los_2022_q2',\n",
    "    'los_2022_q3',\n",
    "    'los_2022_q4',\n",
    "    'los_2023_q1',\n",
    "    'los_2023_q2',\n",
    "    'los_2023_q3',\n",
    "    'los_2023_q4',\n",
    "    'los_2024_q1',\n",
    "    'los_2024_q2',\n",
    "    'los_2024_q3',\n",
    "    'los_2024_q4'\n",
    "]]\n",
    "# add county/route column\n",
    "df_los_all_d12['co_rte'] = df_los_all_d12['CO'] + '-' + df_los_all_d12['RTE']\n",
    "\n",
    "# remove rows with nan as los score\n",
    "# https://stackoverflow.com/questions/13413590/how-to-drop-rows-of-pandas-dataframe-whose-value-in-a-certain-column-is-nan\n",
    "df_los_all_d1.dropna(inplace=True)\n",
    "df_los_all_d2.dropna(inplace=True)\n",
    "df_los_all_d3.dropna(inplace=True)\n",
    "df_los_all_d4.dropna(inplace=True)\n",
    "df_los_all_d5.dropna(inplace=True)\n",
    "df_los_all_d6.dropna(inplace=True)\n",
    "df_los_all_d7.dropna(inplace=True)\n",
    "df_los_all_d8.dropna(inplace=True)\n",
    "df_los_all_d9.dropna(inplace=True)\n",
    "df_los_all_d10.dropna(inplace=True)\n",
    "df_los_all_d11.dropna(inplace=True)\n",
    "df_los_all_d12.dropna(inplace=True)\n",
    "# preview data\n",
    "# print(df_los_all_d1)\n",
    "\n",
    "# group route segments by count to create stacked bar chart\n",
    "df_los_all_count_d1 = df_los_all_d1.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d2 = df_los_all_d2.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d3 = df_los_all_d3.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d4 = df_los_all_d4.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d5 = df_los_all_d5.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d6 = df_los_all_d6.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d7 = df_los_all_d7.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d8 = df_los_all_d8.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d9 = df_los_all_d9.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d10 = df_los_all_d10.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d11 = df_los_all_d11.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "df_los_all_count_d12 = df_los_all_d12.groupby([\n",
    "    'CO', 'RTE'\n",
    "]).size().unstack('RTE')\n",
    "\n",
    "# convert quarterly columns into row values\n",
    "# https://pandas.pydata.org/pandas-docs/version/1.0.0/reference/api/pandas.DataFrame.melt.html\n",
    "# df_los_all_d1.melt(id_vars=[\n",
    "#     'CO',\n",
    "#     'RTE'\n",
    "# ], value_vars=[\n",
    "#     'los_2022_q1',\n",
    "#     'los_2022_q2',\n",
    "#     'los_2022_q3',\n",
    "#     'los_2022_q4',\n",
    "#     'los_2023_q1',\n",
    "#     'los_2023_q2',\n",
    "#     'los_2023_q3',\n",
    "#     'los_2023_q4',\n",
    "#     'los_2024_q1',\n",
    "#     'los_2024_q2',\n",
    "#     'los_2024_q3',\n",
    "#     'los_2024_q4'\n",
    "# ])\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_d1, 'Data Profile: los_all_d1')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d1['Average LOS score']= df_los_all_d1[df_los_all_d1['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d1['los_2022_q1']= df_los_all_d1['los_2022_q1'].astype(int)\n",
    "# df_los_all_d1['los_2022_q2']= df_los_all_d1['los_2022_q2'].astype(int)\n",
    "# df_los_all_d1['los_2022_q3']= df_los_all_d1['los_2022_q3'].astype(int)\n",
    "# df_los_all_d1['los_2022_q4']= df_los_all_d1['los_2022_q4'].astype(int)\n",
    "# df_los_all_d1['los_2023_q1']= df_los_all_d1['los_2023_q1'].astype(int)\n",
    "# df_los_all_d1['los_2023_q2']= df_los_all_d1['los_2023_q2'].astype(int)\n",
    "# df_los_all_d1['los_2023_q3']= df_los_all_d1['los_2023_q3'].astype(int)\n",
    "# df_los_all_d1['los_2023_q4']= df_los_all_d1['los_2023_q4'].astype(int)\n",
    "# df_los_all_d1['los_2024_q1']= df_los_all_d1['los_2024_q1'].astype(int)\n",
    "# df_los_all_d1['los_2024_q2']= df_los_all_d1['los_2024_q2'].astype(int)\n",
    "# df_los_all_d1['los_2024_q3']= df_los_all_d1['los_2024_q3'].astype(int)\n",
    "# df_los_all_d1['los_2024_q4']= df_los_all_d1['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d1['los_2022_q1']= pd.to_numeric(df_los_all_d1['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d1['los_2022_q2']= pd.to_numeric(df_los_all_d1['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d1['los_2022_q3']= pd.to_numeric(df_los_all_d1['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d1['los_2022_q4']= pd.to_numeric(df_los_all_d1['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d1['los_2023_q1']= pd.to_numeric(df_los_all_d1['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d1['los_2023_q2']= pd.to_numeric(df_los_all_d1['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d1['los_2023_q3']= pd.to_numeric(df_los_all_d1['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d1['los_2023_q4']= pd.to_numeric(df_los_all_d1['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d1['los_2024_q1']= pd.to_numeric(df_los_all_d1['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d1['los_2024_q2']= pd.to_numeric(df_los_all_d1['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d1['los_2024_q3']= pd.to_numeric(df_los_all_d1['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d1['los_2024_q4']= pd.to_numeric(df_los_all_d1['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d1 = df_los_all_d1.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d1, 'Data Profile: los_avg_all_d1')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d2['Average LOS score']= df_los_all_d2[df_los_all_d2['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d2['los_2022_q1']= df_los_all_d2['los_2022_q1'].astype(int)\n",
    "# df_los_all_d2['los_2022_q2']= df_los_all_d2['los_2022_q2'].astype(int)\n",
    "# df_los_all_d2['los_2022_q3']= df_los_all_d2['los_2022_q3'].astype(int)\n",
    "# df_los_all_d2['los_2022_q4']= df_los_all_d2['los_2022_q4'].astype(int)\n",
    "# df_los_all_d2['los_2023_q1']= df_los_all_d2['los_2023_q1'].astype(int)\n",
    "# df_los_all_d2['los_2023_q2']= df_los_all_d2['los_2023_q2'].astype(int)\n",
    "# df_los_all_d2['los_2023_q3']= df_los_all_d2['los_2023_q3'].astype(int)\n",
    "# df_los_all_d2['los_2023_q4']= df_los_all_d2['los_2023_q4'].astype(int)\n",
    "# df_los_all_d2['los_2024_q1']= df_los_all_d2['los_2024_q1'].astype(int)\n",
    "# df_los_all_d2['los_2024_q2']= df_los_all_d2['los_2024_q2'].astype(int)\n",
    "# df_los_all_d2['los_2024_q3']= df_los_all_d2['los_2024_q3'].astype(int)\n",
    "# df_los_all_d2['los_2024_q4']= df_los_all_d2['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d2['los_2022_q1']= pd.to_numeric(df_los_all_d2['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d2['los_2022_q2']= pd.to_numeric(df_los_all_d2['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d2['los_2022_q3']= pd.to_numeric(df_los_all_d2['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d2['los_2022_q4']= pd.to_numeric(df_los_all_d2['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d2['los_2023_q1']= pd.to_numeric(df_los_all_d2['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d2['los_2023_q2']= pd.to_numeric(df_los_all_d2['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d2['los_2023_q3']= pd.to_numeric(df_los_all_d2['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d2['los_2023_q4']= pd.to_numeric(df_los_all_d2['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d2['los_2024_q1']= pd.to_numeric(df_los_all_d2['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d2['los_2024_q2']= pd.to_numeric(df_los_all_d2['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d2['los_2024_q3']= pd.to_numeric(df_los_all_d2['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d2['los_2024_q4']= pd.to_numeric(df_los_all_d2['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d2 = df_los_all_d2.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d2, 'Data Profile: los_avg_all_d2')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d3['Average LOS score']= df_los_all_d3[df_los_all_d3['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d3['los_2022_q1']= df_los_all_d3['los_2022_q1'].astype(int)\n",
    "# df_los_all_d3['los_2022_q2']= df_los_all_d3['los_2022_q2'].astype(int)\n",
    "# df_los_all_d3['los_2022_q3']= df_los_all_d3['los_2022_q3'].astype(int)\n",
    "# df_los_all_d3['los_2022_q4']= df_los_all_d3['los_2022_q4'].astype(int)\n",
    "# df_los_all_d3['los_2023_q1']= df_los_all_d3['los_2023_q1'].astype(int)\n",
    "# df_los_all_d3['los_2023_q2']= df_los_all_d3['los_2023_q2'].astype(int)\n",
    "# df_los_all_d3['los_2023_q3']= df_los_all_d3['los_2023_q3'].astype(int)\n",
    "# df_los_all_d3['los_2023_q4']= df_los_all_d3['los_2023_q4'].astype(int)\n",
    "# df_los_all_d3['los_2024_q1']= df_los_all_d3['los_2024_q1'].astype(int)\n",
    "# df_los_all_d3['los_2024_q2']= df_los_all_d3['los_2024_q2'].astype(int)\n",
    "# df_los_all_d3['los_2024_q3']= df_los_all_d3['los_2024_q3'].astype(int)\n",
    "# df_los_all_d3['los_2024_q4']= df_los_all_d3['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d3['los_2022_q1']= pd.to_numeric(df_los_all_d3['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d3['los_2022_q2']= pd.to_numeric(df_los_all_d3['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d3['los_2022_q3']= pd.to_numeric(df_los_all_d3['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d3['los_2022_q4']= pd.to_numeric(df_los_all_d3['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d3['los_2023_q1']= pd.to_numeric(df_los_all_d3['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d3['los_2023_q2']= pd.to_numeric(df_los_all_d3['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d3['los_2023_q3']= pd.to_numeric(df_los_all_d3['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d3['los_2023_q4']= pd.to_numeric(df_los_all_d3['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d3['los_2024_q1']= pd.to_numeric(df_los_all_d3['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d3['los_2024_q2']= pd.to_numeric(df_los_all_d3['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d3['los_2024_q3']= pd.to_numeric(df_los_all_d3['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d3['los_2024_q4']= pd.to_numeric(df_los_all_d3['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d3 = df_los_all_d3.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d3, 'Data Profile: los_avg_all_d3')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d4['Average LOS score']= df_los_all_d4[df_los_all_d4['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d4['los_2022_q1']= df_los_all_d4['los_2022_q1'].astype(int)\n",
    "# df_los_all_d4['los_2022_q2']= df_los_all_d4['los_2022_q2'].astype(int)\n",
    "# df_los_all_d4['los_2022_q3']= df_los_all_d4['los_2022_q3'].astype(int)\n",
    "# df_los_all_d4['los_2022_q4']= df_los_all_d4['los_2022_q4'].astype(int)\n",
    "# df_los_all_d4['los_2023_q1']= df_los_all_d4['los_2023_q1'].astype(int)\n",
    "# df_los_all_d4['los_2023_q2']= df_los_all_d4['los_2023_q2'].astype(int)\n",
    "# df_los_all_d4['los_2023_q3']= df_los_all_d4['los_2023_q3'].astype(int)\n",
    "# df_los_all_d4['los_2023_q4']= df_los_all_d4['los_2023_q4'].astype(int)\n",
    "# df_los_all_d4['los_2024_q1']= df_los_all_d4['los_2024_q1'].astype(int)\n",
    "# df_los_all_d4['los_2024_q2']= df_los_all_d4['los_2024_q2'].astype(int)\n",
    "# df_los_all_d4['los_2024_q3']= df_los_all_d4['los_2024_q3'].astype(int)\n",
    "# df_los_all_d4['los_2024_q4']= df_los_all_d4['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d4['los_2022_q1']= pd.to_numeric(df_los_all_d4['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d4['los_2022_q2']= pd.to_numeric(df_los_all_d4['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d4['los_2022_q3']= pd.to_numeric(df_los_all_d4['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d4['los_2022_q4']= pd.to_numeric(df_los_all_d4['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d4['los_2023_q1']= pd.to_numeric(df_los_all_d4['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d4['los_2023_q2']= pd.to_numeric(df_los_all_d4['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d4['los_2023_q3']= pd.to_numeric(df_los_all_d4['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d4['los_2023_q4']= pd.to_numeric(df_los_all_d4['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d4['los_2024_q1']= pd.to_numeric(df_los_all_d4['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d4['los_2024_q2']= pd.to_numeric(df_los_all_d4['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d4['los_2024_q3']= pd.to_numeric(df_los_all_d4['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d4['los_2024_q4']= pd.to_numeric(df_los_all_d4['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d4 = df_los_all_d4.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d4, 'Data Profile: los_avg_all_d4')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d5['Average LOS score']= df_los_all_d5[df_los_all_d5['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d5['los_2022_q1']= df_los_all_d5['los_2022_q1'].astype(int)\n",
    "# df_los_all_d5['los_2022_q2']= df_los_all_d5['los_2022_q2'].astype(int)\n",
    "# df_los_all_d5['los_2022_q3']= df_los_all_d5['los_2022_q3'].astype(int)\n",
    "# df_los_all_d5['los_2022_q4']= df_los_all_d5['los_2022_q4'].astype(int)\n",
    "# df_los_all_d5['los_2023_q1']= df_los_all_d5['los_2023_q1'].astype(int)\n",
    "# df_los_all_d5['los_2023_q2']= df_los_all_d5['los_2023_q2'].astype(int)\n",
    "# df_los_all_d5['los_2023_q3']= df_los_all_d5['los_2023_q3'].astype(int)\n",
    "# df_los_all_d5['los_2023_q4']= df_los_all_d5['los_2023_q4'].astype(int)\n",
    "# df_los_all_d5['los_2024_q1']= df_los_all_d5['los_2024_q1'].astype(int)\n",
    "# df_los_all_d5['los_2024_q2']= df_los_all_d5['los_2024_q2'].astype(int)\n",
    "# df_los_all_d5['los_2024_q3']= df_los_all_d5['los_2024_q3'].astype(int)\n",
    "# df_los_all_d5['los_2024_q4']= df_los_all_d5['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d5['los_2022_q1']= pd.to_numeric(df_los_all_d5['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d5['los_2022_q2']= pd.to_numeric(df_los_all_d5['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d5['los_2022_q3']= pd.to_numeric(df_los_all_d5['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d5['los_2022_q4']= pd.to_numeric(df_los_all_d5['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d5['los_2023_q1']= pd.to_numeric(df_los_all_d5['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d5['los_2023_q2']= pd.to_numeric(df_los_all_d5['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d5['los_2023_q3']= pd.to_numeric(df_los_all_d5['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d5['los_2023_q4']= pd.to_numeric(df_los_all_d5['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d5['los_2024_q1']= pd.to_numeric(df_los_all_d5['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d5['los_2024_q2']= pd.to_numeric(df_los_all_d5['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d5['los_2024_q3']= pd.to_numeric(df_los_all_d5['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d5['los_2024_q4']= pd.to_numeric(df_los_all_d5['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d5 = df_los_all_d5.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d5, 'Data Profile: los_avg_all_d5')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d6['Average LOS score']= df_los_all_d6[df_los_all_d6['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d6['los_2022_q1']= df_los_all_d6['los_2022_q1'].astype(int)\n",
    "# df_los_all_d6['los_2022_q2']= df_los_all_d6['los_2022_q2'].astype(int)\n",
    "# df_los_all_d6['los_2022_q3']= df_los_all_d6['los_2022_q3'].astype(int)\n",
    "# df_los_all_d6['los_2022_q4']= df_los_all_d6['los_2022_q4'].astype(int)\n",
    "# df_los_all_d6['los_2023_q1']= df_los_all_d6['los_2023_q1'].astype(int)\n",
    "# df_los_all_d6['los_2023_q2']= df_los_all_d6['los_2023_q2'].astype(int)\n",
    "# df_los_all_d6['los_2023_q3']= df_los_all_d6['los_2023_q3'].astype(int)\n",
    "# df_los_all_d6['los_2023_q4']= df_los_all_d6['los_2023_q4'].astype(int)\n",
    "# df_los_all_d6['los_2024_q1']= df_los_all_d6['los_2024_q1'].astype(int)\n",
    "# df_los_all_d6['los_2024_q2']= df_los_all_d6['los_2024_q2'].astype(int)\n",
    "# df_los_all_d6['los_2024_q3']= df_los_all_d6['los_2024_q3'].astype(int)\n",
    "# df_los_all_d6['los_2024_q4']= df_los_all_d6['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d6['los_2022_q1']= pd.to_numeric(df_los_all_d6['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d6['los_2022_q2']= pd.to_numeric(df_los_all_d6['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d6['los_2022_q3']= pd.to_numeric(df_los_all_d6['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d6['los_2022_q4']= pd.to_numeric(df_los_all_d6['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d6['los_2023_q1']= pd.to_numeric(df_los_all_d6['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d6['los_2023_q2']= pd.to_numeric(df_los_all_d6['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d6['los_2023_q3']= pd.to_numeric(df_los_all_d6['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d6['los_2023_q4']= pd.to_numeric(df_los_all_d6['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d6['los_2024_q1']= pd.to_numeric(df_los_all_d6['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d6['los_2024_q2']= pd.to_numeric(df_los_all_d6['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d6['los_2024_q3']= pd.to_numeric(df_los_all_d6['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d6['los_2024_q4']= pd.to_numeric(df_los_all_d6['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d6 = df_los_all_d6.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d6, 'Data Profile: los_avg_all_d6')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d7['Average LOS score']= df_los_all_d7[df_los_all_d7['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d7['los_2022_q1']= df_los_all_d7['los_2022_q1'].astype(int)\n",
    "# df_los_all_d7['los_2022_q2']= df_los_all_d7['los_2022_q2'].astype(int)\n",
    "# df_los_all_d7['los_2022_q3']= df_los_all_d7['los_2022_q3'].astype(int)\n",
    "# df_los_all_d7['los_2022_q4']= df_los_all_d7['los_2022_q4'].astype(int)\n",
    "# df_los_all_d7['los_2023_q1']= df_los_all_d7['los_2023_q1'].astype(int)\n",
    "# df_los_all_d7['los_2023_q2']= df_los_all_d7['los_2023_q2'].astype(int)\n",
    "# df_los_all_d7['los_2023_q3']= df_los_all_d7['los_2023_q3'].astype(int)\n",
    "# df_los_all_d7['los_2023_q4']= df_los_all_d7['los_2023_q4'].astype(int)\n",
    "# df_los_all_d7['los_2024_q1']= df_los_all_d7['los_2024_q1'].astype(int)\n",
    "# df_los_all_d7['los_2024_q2']= df_los_all_d7['los_2024_q2'].astype(int)\n",
    "# df_los_all_d7['los_2024_q3']= df_los_all_d7['los_2024_q3'].astype(int)\n",
    "# df_los_all_d7['los_2024_q4']= df_los_all_d7['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d7['los_2022_q1']= pd.to_numeric(df_los_all_d7['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d7['los_2022_q2']= pd.to_numeric(df_los_all_d7['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d7['los_2022_q3']= pd.to_numeric(df_los_all_d7['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d7['los_2022_q4']= pd.to_numeric(df_los_all_d7['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d7['los_2023_q1']= pd.to_numeric(df_los_all_d7['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d7['los_2023_q2']= pd.to_numeric(df_los_all_d7['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d7['los_2023_q3']= pd.to_numeric(df_los_all_d7['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d7['los_2023_q4']= pd.to_numeric(df_los_all_d7['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d7['los_2024_q1']= pd.to_numeric(df_los_all_d7['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d7['los_2024_q2']= pd.to_numeric(df_los_all_d7['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d7['los_2024_q3']= pd.to_numeric(df_los_all_d7['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d7['los_2024_q4']= pd.to_numeric(df_los_all_d7['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d7 = df_los_all_d7.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d7, 'Data Profile: los_avg_all_d7')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d8['Average LOS score']= df_los_all_d8[df_los_all_d8['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d8['los_2022_q1']= df_los_all_d8['los_2022_q1'].astype(int)\n",
    "# df_los_all_d8['los_2022_q2']= df_los_all_d8['los_2022_q2'].astype(int)\n",
    "# df_los_all_d8['los_2022_q3']= df_los_all_d8['los_2022_q3'].astype(int)\n",
    "# df_los_all_d8['los_2022_q4']= df_los_all_d8['los_2022_q4'].astype(int)\n",
    "# df_los_all_d8['los_2023_q1']= df_los_all_d8['los_2023_q1'].astype(int)\n",
    "# df_los_all_d8['los_2023_q2']= df_los_all_d8['los_2023_q2'].astype(int)\n",
    "# df_los_all_d8['los_2023_q3']= df_los_all_d8['los_2023_q3'].astype(int)\n",
    "# df_los_all_d8['los_2023_q4']= df_los_all_d8['los_2023_q4'].astype(int)\n",
    "# df_los_all_d8['los_2024_q1']= df_los_all_d8['los_2024_q1'].astype(int)\n",
    "# df_los_all_d8['los_2024_q2']= df_los_all_d8['los_2024_q2'].astype(int)\n",
    "# df_los_all_d8['los_2024_q3']= df_los_all_d8['los_2024_q3'].astype(int)\n",
    "# df_los_all_d8['los_2024_q4']= df_los_all_d8['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d8['los_2022_q1']= pd.to_numeric(df_los_all_d8['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d8['los_2022_q2']= pd.to_numeric(df_los_all_d8['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d8['los_2022_q3']= pd.to_numeric(df_los_all_d8['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d8['los_2022_q4']= pd.to_numeric(df_los_all_d8['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d8['los_2023_q1']= pd.to_numeric(df_los_all_d8['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d8['los_2023_q2']= pd.to_numeric(df_los_all_d8['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d8['los_2023_q3']= pd.to_numeric(df_los_all_d8['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d8['los_2023_q4']= pd.to_numeric(df_los_all_d8['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d8['los_2024_q1']= pd.to_numeric(df_los_all_d8['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d8['los_2024_q2']= pd.to_numeric(df_los_all_d8['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d8['los_2024_q3']= pd.to_numeric(df_los_all_d8['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d8['los_2024_q4']= pd.to_numeric(df_los_all_d8['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d8 = df_los_all_d8.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d8, 'Data Profile: los_avg_all_d8')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d9['Average LOS score']= df_los_all_d9[df_los_all_d9['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d9['los_2022_q1']= df_los_all_d9['los_2022_q1'].astype(int)\n",
    "# df_los_all_d9['los_2022_q2']= df_los_all_d9['los_2022_q2'].astype(int)\n",
    "# df_los_all_d9['los_2022_q3']= df_los_all_d9['los_2022_q3'].astype(int)\n",
    "# df_los_all_d9['los_2022_q4']= df_los_all_d9['los_2022_q4'].astype(int)\n",
    "# df_los_all_d9['los_2023_q1']= df_los_all_d9['los_2023_q1'].astype(int)\n",
    "# df_los_all_d9['los_2023_q2']= df_los_all_d9['los_2023_q2'].astype(int)\n",
    "# df_los_all_d9['los_2023_q3']= df_los_all_d9['los_2023_q3'].astype(int)\n",
    "# df_los_all_d9['los_2023_q4']= df_los_all_d9['los_2023_q4'].astype(int)\n",
    "# df_los_all_d9['los_2024_q1']= df_los_all_d9['los_2024_q1'].astype(int)\n",
    "# df_los_all_d9['los_2024_q2']= df_los_all_d9['los_2024_q2'].astype(int)\n",
    "# df_los_all_d9['los_2024_q3']= df_los_all_d9['los_2024_q3'].astype(int)\n",
    "# df_los_all_d9['los_2024_q4']= df_los_all_d9['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d9['los_2022_q1']= pd.to_numeric(df_los_all_d9['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d9['los_2022_q2']= pd.to_numeric(df_los_all_d9['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d9['los_2022_q3']= pd.to_numeric(df_los_all_d9['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d9['los_2022_q4']= pd.to_numeric(df_los_all_d9['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d9['los_2023_q1']= pd.to_numeric(df_los_all_d9['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d9['los_2023_q2']= pd.to_numeric(df_los_all_d9['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d9['los_2023_q3']= pd.to_numeric(df_los_all_d9['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d9['los_2023_q4']= pd.to_numeric(df_los_all_d9['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d9['los_2024_q1']= pd.to_numeric(df_los_all_d9['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d9['los_2024_q2']= pd.to_numeric(df_los_all_d9['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d9['los_2024_q3']= pd.to_numeric(df_los_all_d9['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d9['los_2024_q4']= pd.to_numeric(df_los_all_d9['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d9 = df_los_all_d9.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d9, 'Data Profile: los_avg_all_d9')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d10['Average LOS score']= df_los_all_d10[df_los_all_d10['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d10['los_2022_q1']= df_los_all_d10['los_2022_q1'].astype(int)\n",
    "# df_los_all_d10['los_2022_q2']= df_los_all_d10['los_2022_q2'].astype(int)\n",
    "# df_los_all_d10['los_2022_q3']= df_los_all_d10['los_2022_q3'].astype(int)\n",
    "# df_los_all_d10['los_2022_q4']= df_los_all_d10['los_2022_q4'].astype(int)\n",
    "# df_los_all_d10['los_2023_q1']= df_los_all_d10['los_2023_q1'].astype(int)\n",
    "# df_los_all_d10['los_2023_q2']= df_los_all_d10['los_2023_q2'].astype(int)\n",
    "# df_los_all_d10['los_2023_q3']= df_los_all_d10['los_2023_q3'].astype(int)\n",
    "# df_los_all_d10['los_2023_q4']= df_los_all_d10['los_2023_q4'].astype(int)\n",
    "# df_los_all_d10['los_2024_q1']= df_los_all_d10['los_2024_q1'].astype(int)\n",
    "# df_los_all_d10['los_2024_q2']= df_los_all_d10['los_2024_q2'].astype(int)\n",
    "# df_los_all_d10['los_2024_q3']= df_los_all_d10['los_2024_q3'].astype(int)\n",
    "# df_los_all_d10['los_2024_q4']= df_los_all_d10['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d10['los_2022_q1']= pd.to_numeric(df_los_all_d10['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d10['los_2022_q2']= pd.to_numeric(df_los_all_d10['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d10['los_2022_q3']= pd.to_numeric(df_los_all_d10['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d10['los_2022_q4']= pd.to_numeric(df_los_all_d10['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d10['los_2023_q1']= pd.to_numeric(df_los_all_d10['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d10['los_2023_q2']= pd.to_numeric(df_los_all_d10['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d10['los_2023_q3']= pd.to_numeric(df_los_all_d10['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d10['los_2023_q4']= pd.to_numeric(df_los_all_d10['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d10['los_2024_q1']= pd.to_numeric(df_los_all_d10['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d10['los_2024_q2']= pd.to_numeric(df_los_all_d10['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d10['los_2024_q3']= pd.to_numeric(df_los_all_d10['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d10['los_2024_q4']= pd.to_numeric(df_los_all_d10['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d10 = df_los_all_d10.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d10, 'Data Profile: los_avg_all_d10')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d11['Average LOS score']= df_los_all_d11[df_los_all_d11['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d11['los_2022_q1']= df_los_all_d11['los_2022_q1'].astype(int)\n",
    "# df_los_all_d11['los_2022_q2']= df_los_all_d11['los_2022_q2'].astype(int)\n",
    "# df_los_all_d11['los_2022_q3']= df_los_all_d11['los_2022_q3'].astype(int)\n",
    "# df_los_all_d11['los_2022_q4']= df_los_all_d11['los_2022_q4'].astype(int)\n",
    "# df_los_all_d11['los_2023_q1']= df_los_all_d11['los_2023_q1'].astype(int)\n",
    "# df_los_all_d11['los_2023_q2']= df_los_all_d11['los_2023_q2'].astype(int)\n",
    "# df_los_all_d11['los_2023_q3']= df_los_all_d11['los_2023_q3'].astype(int)\n",
    "# df_los_all_d11['los_2023_q4']= df_los_all_d11['los_2023_q4'].astype(int)\n",
    "# df_los_all_d11['los_2024_q1']= df_los_all_d11['los_2024_q1'].astype(int)\n",
    "# df_los_all_d11['los_2024_q2']= df_los_all_d11['los_2024_q2'].astype(int)\n",
    "# df_los_all_d11['los_2024_q3']= df_los_all_d11['los_2024_q3'].astype(int)\n",
    "# df_los_all_d11['los_2024_q4']= df_los_all_d11['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d11['los_2022_q1']= pd.to_numeric(df_los_all_d11['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d11['los_2022_q2']= pd.to_numeric(df_los_all_d11['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d11['los_2022_q3']= pd.to_numeric(df_los_all_d11['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d11['los_2022_q4']= pd.to_numeric(df_los_all_d11['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d11['los_2023_q1']= pd.to_numeric(df_los_all_d11['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d11['los_2023_q2']= pd.to_numeric(df_los_all_d11['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d11['los_2023_q3']= pd.to_numeric(df_los_all_d11['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d11['los_2023_q4']= pd.to_numeric(df_los_all_d11['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d11['los_2024_q1']= pd.to_numeric(df_los_all_d11['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d11['los_2024_q2']= pd.to_numeric(df_los_all_d11['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d11['los_2024_q3']= pd.to_numeric(df_los_all_d11['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d11['los_2024_q4']= pd.to_numeric(df_los_all_d11['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d11 = df_los_all_d11.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d11, 'Data Profile: los_avg_all_d11')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d12['Average LOS score']= df_los_all_d12[df_los_all_d12['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d12['los_2022_q1']= df_los_all_d12['los_2022_q1'].astype(int)\n",
    "# df_los_all_d12['los_2022_q2']= df_los_all_d12['los_2022_q2'].astype(int)\n",
    "# df_los_all_d12['los_2022_q3']= df_los_all_d12['los_2022_q3'].astype(int)\n",
    "# df_los_all_d12['los_2022_q4']= df_los_all_d12['los_2022_q4'].astype(int)\n",
    "# df_los_all_d12['los_2023_q1']= df_los_all_d12['los_2023_q1'].astype(int)\n",
    "# df_los_all_d12['los_2023_q2']= df_los_all_d12['los_2023_q2'].astype(int)\n",
    "# df_los_all_d12['los_2023_q3']= df_los_all_d12['los_2023_q3'].astype(int)\n",
    "# df_los_all_d12['los_2023_q4']= df_los_all_d12['los_2023_q4'].astype(int)\n",
    "# df_los_all_d12['los_2024_q1']= df_los_all_d12['los_2024_q1'].astype(int)\n",
    "# df_los_all_d12['los_2024_q2']= df_los_all_d12['los_2024_q2'].astype(int)\n",
    "# df_los_all_d12['los_2024_q3']= df_los_all_d12['los_2024_q3'].astype(int)\n",
    "# df_los_all_d12['los_2024_q4']= df_los_all_d12['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d12['los_2022_q1']= pd.to_numeric(df_los_all_d12['los_2022_q1'], errors='coerce')\n",
    "df_los_all_d12['los_2022_q2']= pd.to_numeric(df_los_all_d12['los_2022_q2'], errors='coerce')\n",
    "df_los_all_d12['los_2022_q3']= pd.to_numeric(df_los_all_d12['los_2022_q3'], errors='coerce')\n",
    "df_los_all_d12['los_2022_q4']= pd.to_numeric(df_los_all_d12['los_2022_q4'], errors='coerce')\n",
    "df_los_all_d12['los_2023_q1']= pd.to_numeric(df_los_all_d12['los_2023_q1'], errors='coerce')\n",
    "df_los_all_d12['los_2023_q2']= pd.to_numeric(df_los_all_d12['los_2023_q2'], errors='coerce')\n",
    "df_los_all_d12['los_2023_q3']= pd.to_numeric(df_los_all_d12['los_2023_q3'], errors='coerce')\n",
    "df_los_all_d12['los_2023_q4']= pd.to_numeric(df_los_all_d12['los_2023_q4'], errors='coerce')\n",
    "df_los_all_d12['los_2024_q1']= pd.to_numeric(df_los_all_d12['los_2024_q1'], errors='coerce')\n",
    "df_los_all_d12['los_2024_q2']= pd.to_numeric(df_los_all_d12['los_2024_q2'], errors='coerce')\n",
    "df_los_all_d12['los_2024_q3']= pd.to_numeric(df_los_all_d12['los_2024_q3'], errors='coerce')\n",
    "df_los_all_d12['los_2024_q4']= pd.to_numeric(df_los_all_d12['los_2024_q4'], errors='coerce')\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d12 = df_los_all_d12.groupby(['co_rte']).agg({\n",
    "    'los_2022_q1': 'mean',\n",
    "    'los_2022_q2': 'mean',\n",
    "    'los_2022_q3': 'mean',\n",
    "    'los_2022_q4': 'mean',\n",
    "    'los_2023_q1': 'mean',\n",
    "    'los_2023_q2': 'mean',\n",
    "    'los_2023_q3': 'mean',\n",
    "    'los_2023_q4': 'mean',\n",
    "    'los_2024_q1': 'mean',\n",
    "    'los_2024_q2': 'mean',\n",
    "    'los_2024_q3': 'mean',\n",
    "    'los_2024_q4': 'mean'\n",
    "})\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d12, 'Data Profile: los_avg_all_d12')\n",
    "\n",
    "# export final csv file\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d1,\n",
    "    'data/05.02.04_los_all_avg_d1.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d2,\n",
    "    'data/05.02.04_los_all_avg_d2.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d3,\n",
    "    'data/05.02.04_los_all_avg_d3.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d4,\n",
    "    'data/05.02.04_los_all_avg_d4.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d5,\n",
    "    'data/05.02.04_los_all_avg_d5.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d6,\n",
    "    'data/05.02.04_los_all_avg_d6.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d7,\n",
    "    'data/05.02.04_los_all_avg_d7.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d8,\n",
    "    'data/05.02.04_los_all_avg_d8.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d9,\n",
    "    'data/05.02.04_los_all_avg_d9.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d10,\n",
    "    'data/05.02.04_los_all_avg_d10.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d11,\n",
    "    'data/05.02.04_los_all_avg_d11.csv'\n",
    ")\n",
    "write_data_csv(\n",
    "    df_los_all_avg_d12,\n",
    "    'data/05.02.04_los_all_avg_d12.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.03 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_03sac005,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.03 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_03sac050,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.03 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_03sac080,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04ala580b,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04ala680,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04ala880,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04cc004a,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04cc680,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.06 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_06fre099,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.06 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_06ker099,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la005a,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la010,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la101,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la110,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la405,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.08 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_08riv010,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.08 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_08riv060,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.11 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_11sd005,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.11 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_11sd805,\n",
    "    x='Production Quantity',\n",
    "    y='From Miles',\n",
    "    hue='Activity Description',\n",
    "    style='Activity Description',\n",
    "    palette='deep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.01 - plot work activty counts by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_count.plot.bar(stacked=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.01 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.02 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.03 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.04 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(25,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.05 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.06 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.07 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(25,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.08 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.09 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.10 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.11 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.12 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.13 - plot work activity counts by litter hotspot\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_count.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.01 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.02 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.03 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.04 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(25,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.05 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.06 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.07 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.08 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.09 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.10 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.11 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.12 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.13 - plot work activity totals by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_sum.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.01 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.02 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.03 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.04 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(25,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.05 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.06 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.07 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.08 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.09 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.10 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.11 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.12 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.13 - plot work activity cost by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_cost.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.14 - plot work total labor by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_labor.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.01 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.02 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.03 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.04 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,15)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.05 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.06 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.07 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,15)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.08 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.09 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.10 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.11 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.12 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.01 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.02 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.03 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.04 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.05 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.06 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.07 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.08 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.09 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.10 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.11 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 05.11.12 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={'figure.figsize':(20,10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d12.plot.bar(stacked=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
