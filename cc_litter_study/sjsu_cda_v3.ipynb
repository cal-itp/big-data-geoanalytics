{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5403c9a1-a179-415f-bde2-2704cfd86a69",
   "metadata": {},
   "source": [
    "## SJSU Capstone Data Analysis\n",
    "*SJSU-MSTM*\n",
    "\n",
    "### README\n",
    "This notebook contains data cleaning, analysis and visualization for the SJSU capstone data; it validates data based on the Caltrans Data Quality Management Plan (DQMP) data quality dimensions listed below.\n",
    "\n",
    "> Note: Similar to software [unit testing][01.00], it is intended to serve as a test suite for the specified dataset.\n",
    "\n",
    "*Change Log*\n",
    "* 10-21-2020: Submit Version 1.0\n",
    "* 10-21-2020: Baseline Version v0.1\n",
    "* 11-26-2024: SJSU Capstone Update\n",
    "\n",
    "*Deliverables*\n",
    "1. Test case are organized into separate modules and prints test results\n",
    "2. Each test will output non-compliant records into CSV files for action\n",
    "3. Data processing module produces transformed data (e.g. table joins)\n",
    "4. Notebook generates data dictionary after running all test cases\n",
    "5. All test cases are repeatable and documented\n",
    "\n",
    "*Data Quality Dimensions (DQMP)*\n",
    "1. Accuracy and Precision: Data is close to true value and exactness\n",
    "2. Validity: Conforms to established formats, data types and ranges\n",
    "3. Completeness: Absence of gaps in data, especially missing values\n",
    "4. Consistency: Data is collected at similar datetime and location\n",
    "5. Timeliness: Data is updated on a regular basis\n",
    "6. Granularity: Data is collected at appropriate level of detail for use\n",
    "7. Uniqueness: Best effort to collect data from authoritative sources\n",
    "8. Accessibility: Data is collected or processed into useable formats\n",
    "9. Reputation: Data is trusted as reliable source\n",
    "\n",
    "### Results (Summary)\n",
    "This section reports data validation findings and process steps.\n",
    "\n",
    "> Note: Data validation is intended to flag non-compliant values for discussion and not correction until confirmed by the team. As a result, the following issues were observed during data validation in addition to non-compliance report.\n",
    "\n",
    "*Datasets Cleaned, Analyzed & Visualized*\n",
    "1. Caltrans and Clean CA Litter Collection Totals\n",
    "2. Clean CA Level of Service (LOS) Scores\n",
    "3. Caltrans Customer Service Requests (CSRs)\n",
    "\n",
    "*Data Processing Steps*\n",
    "1. Import raw data/template files and save as table variables\n",
    "2. Crosswalk raw data/template fields; populate template\n",
    "3. Flag missing columns as \"Column not provided\"\n",
    "4. Convert column data types as needed\n",
    "5. Join project with corresponding table\n",
    "6. Save merged data for validation\n",
    "\n",
    "### Jupyter Introduction\n",
    "This notebook will require some basic understanding of the Python programming language, Jupyter platform and data analysis concepts. It is based on this [tutorial][01.02] and [Github Repo][01.03].\n",
    "\n",
    "Jupyter is a powerful collaborative tool which is open-source and light-weight. It provides all the tools necessary to run data analysis, visualization, statistics and data science [out of the box][01.04]. In addition, it has gain acceptance from industry and academia for collaborating on projects and publishing work.\n",
    "\n",
    "Jupyter is a combination of text and code with the programming run-time built into the platform so there is no need to install additional software. The text is in the markdown file format (similar to HTML), and code in several languages. It is organized by cells which can consist of either text or code; placed together, they can be sent as a single document to share/publish work.\n",
    "\n",
    "### Jupyter Notebook\n",
    "Notebooks are organized by cells, which mainly consist of text (in markdown) and code (Python). It operations like a hybrid between MS Word and Excel file; whereas the entire file is like a document, the cells operate like a spreadsheet. For getting started, feel free to scroll down each cell and navigate around the cells for a quick tour. Here is a breakdown of how to view/edit cells:\n",
    "\n",
    "*Navigation*\n",
    "1. Each cell may be edited by hitting ENTER; toggle between cells using the arrow keys or mouse/scroller\n",
    "2. When editing a cell, be sure to select \"markdown\" for text or \"code\" before writing into it\n",
    "3. Each cell can be run by hitting CTRL + ENTER or the \"run\" button form the menu bar\n",
    "4. Output from each cell will appear below; if an error occurs, please read and try to debug it(!)\n",
    "5. File can be saved by hitting CTRL + \"s\" or file/save from the pulldown menu above\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "*Notes*\n",
    "1. This notebook will require some Python programming\n",
    "2. It is widely used and taught in [high school][01.05] and AP Computer Science [courses][01.06]\n",
    "3. [Jupyter][01.07] supports many other languages, including R, Scala and Julia\n",
    "4. Python is the most popular of them and can be used for other tasks, primarily data science and web applications\n",
    "\n",
    "### Exercises\n",
    "\n",
    "*Jupyter*\n",
    "1. [Intro Guide (DataQuest)][01.08]\n",
    "2. [Intro Guide (DataCamp)][01.09]\n",
    "3. [Notebook Intro (Medium)][01.10]\n",
    "4. [Data Science Tutorial (Jupyter)][01.11]\n",
    "\n",
    "*Python*\n",
    "1. [Quick Start][01.12]\n",
    "2. [Intro Tutorials][01.13]\n",
    "3. [Quick Start (FCC)][01.14]\n",
    "\n",
    "*Markdown*\n",
    "1. [Quick Start (Github)][01.15]\n",
    "2. [Quick Start Guide (Markdown)][01.16]\n",
    "3. [Quick Start Tutorial (Markdown)][01.17]\n",
    "\n",
    "[01.00]: https://en.wikipedia.org/wiki/Unit_testing\n",
    "[01.01]: https://www.anaconda.com/distribution/\n",
    "[01.02]: https://medium.com/python-pandemonium/introduction-to-exploratory-data-analysis-in-python-8b6bcb55c190\n",
    "[01.03]: https://github.com/kadnan/EDA_Python/\n",
    "[01.04]: https://jupyter.org/jupyter-book/01/what-is-data-science.html\n",
    "[01.05]: https://codehs.com/info/curriculum/intropython\n",
    "[01.06]: https://code.org/educate/curriculum/high-school\n",
    "[01.07]: https://jupyter.org/\n",
    "[01.08]: https://www.dataquest.io/blog/jupyter-notebook-tutorial/\n",
    "[01.09]: https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\n",
    "[01.10]: https://towardsdatascience.com/a-beginners-tutorial-to-jupyter-notebooks-1b2f8705888a\n",
    "[01.11]: https://jupyter.org/jupyter-book/01/what-is-data-science.html\n",
    "[01.12]: https://www.python.org/about/gettingstarted/\n",
    "[01.13]: https://realpython.com/learning-paths/python3-introduction/\n",
    "[01.14]: https://guide.freecodecamp.org/python/\n",
    "[01.15]: https://guides.github.com/features/mastering-markdown/\n",
    "[01.16]: https://www.markdownguide.org/getting-started/\n",
    "[01.17]: https://www.markdowntutorial.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a114478-c7e1-4aa5-b4ab-58b38549297e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 01.01 - load python modules into notebook\n",
    "\n",
    "# install pip package in current kernel; run only for initial install:\n",
    "# https://medium.com/@rohanguptha.bompally/python-data-visualization-using-folium-and-geopandas-981857948f02\n",
    "# !pip install descartes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# data analysis modules\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# data visualization modules\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# for the PDF export\n",
    "import json\n",
    "import nbformat\n",
    "from textwrap import wrap\n",
    "\n",
    "# Added by Noah to help with importing\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# excel module\n",
    "# !pip install openpyxl\n",
    "# import openpyxl\n",
    "\n",
    "# set numeric output; turn off scientific notation\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "\n",
    "# adjust print settings\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 35\n",
    "\n",
    "# suppress warning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15e04c5-3935-4476-ab19-6cfde92f604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imms_2021b = \"imms2021b.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b535a53-0820-4bf6-8272-8809a842a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the location of the data\n",
    "source_folder = Path.cwd() / \"0_source_data\"\n",
    "output_folder = Path.cwd() / \"1_report_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da05e3-d336-4874-a89a-164ca0a4a424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4025152-37e5-4413-9d6b-04b61d6f79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage and validation\n",
    "\n",
    "# Load up one of the CSVs and create a dataframe, then display the first 5 lines of the dataframe\n",
    "# df_imms_2021b = load_csv_from_local_folder(\"imms_2021b.csv\")\n",
    "# df_imms_2021b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10af7d91-3f54-4453-b831-f82b138f96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.01 - data import functions\n",
    "\n",
    "\n",
    "\n",
    "# Added by Noah Sanchez June 2025\n",
    "def load_csv_from_local_folder(filename):\n",
    "    \"\"\"\n",
    "    Load a CSV file from a synced SharePoint/Teams folder via OneDrive.\n",
    "\n",
    "    Args:\n",
    "        file_relative_path (str): The relative path to the CSV file from your local OneDrive root.\n",
    "                                  Example: \"Teams - MyTeamName/General/my_data.csv\"\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded CSV as a DataFrame, or None if not found.\n",
    "    \"\"\"\n",
    "    full_path = source_folder / filename\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(full_path)\n",
    "        print(f\"Loaded CSV from: {full_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found at: {full_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Added by Noah Sanchez June 2025\n",
    "# function to write csv file to local folder \"1_report_data\"\n",
    "# study created data (scd)\n",
    "def write_data_csv(df, output_folder):\n",
    "    df.to_csv(output_folder, index=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function to read excel, return csv/dataframe\n",
    "# https://towardsdatascience.com/loading-ridiculously-large-excel-files-in-python-44ba0a7bea24\n",
    "def excel2csv(path_excel, engine_type, path_csv):\n",
    "    # note: new excel, xlsx files - use openpyxl\n",
    "    # df_publish = pd.read_excel(data_path, index_col=0, engine=\"openpyxl\")\n",
    "    # note: old excel, xls files - use xlrd\n",
    "    # df_publish = pd.read_excel(data_path, index_col=0, engine=\"xlrd\")\n",
    "    df = pd.read_excel(path_excel, index_col=0, engine=engine_type)\n",
    "    # return file/dataframe\n",
    "    write_data_csv(df, path_csv)\n",
    "    return df\n",
    "\n",
    "\n",
    "# call function to read excel, return csv/dataframe\n",
    "# df_allv_count = excel2csv(\n",
    "#     \"data/excel/OTM_ALLV_COUNTS_01012018.xlsx\",\n",
    "#     \"openpyxl\",\n",
    "#     \"data/csv/OTM_ALLV_COUNTS_01012018.csv\"\n",
    "# )\n",
    "\n",
    "\n",
    "# function to read csv, output zip\n",
    "# https://stackoverflow.com/questions/37754165/python-pandas-create-zip-file-from-csv\n",
    "def csv2zip(df, path_csv, comp, path_zip):\n",
    "    compression_opts = dict(method=comp, archive_name=path_csv)\n",
    "    df.to_csv(path_zip, compression=compression_opts)\n",
    "\n",
    "\n",
    "# call function to read csv, output zip\n",
    "# csv2zip(\n",
    "#     df_publish,\n",
    "#     \"data/csv/OTM_LATEST_PUBLISHED_YEAR.csv\",\n",
    "#     \"zip\",\n",
    "#     \"data/OTM_LATEST_PUBLISHED_YEAR.zip\"\n",
    "# )\n",
    "\n",
    "\n",
    "# function to show table info\n",
    "def data_profile(df, msg):\n",
    "    # pass in variable into string\n",
    "    # https://stackoverflow.com/questions/2960772/how-do-i-put-a-variable-inside-a-string\n",
    "    print(\"*** Table Info: %s ***\" % msg, \"\\n\")\n",
    "    print(df.info(), \"\\n\")\n",
    "    print(\"*** Table Info: Table Dimensions ***\", \"\\n\")\n",
    "    print(df.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# function to show unique value for given column\n",
    "def show_unique(df, col):\n",
    "    # pass in variable into string\n",
    "    # https://stackoverflow.com/questions/2960772/how-do-i-put-a-variable-inside-a-string\n",
    "    print(\"*** Unique Values: %s ***\" % col, \"\\n\")\n",
    "    print(df[col].unique(), \"\\n\")\n",
    "\n",
    "\n",
    "# define function to create and populate template\n",
    "def data_import_project(df, path):\n",
    "    # convert raw data columns into list type for import\n",
    "    # start project data\n",
    "    list_projid = df[\"Project ID\"].to_list()\n",
    "    list_ppno = df[\"PPNO\"].to_list()\n",
    "    list_projtitle = df[\"Project Title\"].to_list()\n",
    "    list_projdesc = df[\"Project Description\"].to_list()\n",
    "    list_projstatus = df[\"Project Status\"].to_list()\n",
    "    list_sb1funds = df[\"SB1 Funds\"].to_list()\n",
    "    list_totalcost = df[\"Total Project Cost\"].to_list()\n",
    "    list_fy = df[\"Fiscal Year\"].to_list()\n",
    "    list_sb1flag = df[\"Is SB1?\"].to_list()\n",
    "    list_onshs = df[\"ON SHS?\"].to_list()\n",
    "    list_ctdist = df[\"Caltrans District\"].to_list()\n",
    "    list_assembly = df[\"Assembly Districts\"].to_list()\n",
    "    list_senate = df[\"Senate Districts\"].to_list()\n",
    "    list_citycode = df[\"City Code\"].to_list()\n",
    "    list_cityid = df[\"City Agency ID\"].to_list()\n",
    "    list_countycode = df[\"County Code\"].to_list()\n",
    "    list_countyid = df[\"County Agency ID\"].to_list()\n",
    "    list_impagencyid = df[\"Implementing Agency ID\"].to_list()\n",
    "\n",
    "    # import columns as list type into empty dataframe\n",
    "    # start project data\n",
    "    df_import = pd.DataFrame()\n",
    "    df_import = df_import.assign(ProjectID=list_projid)\n",
    "    df_import = df_import.assign(PPNO=list_ppno)\n",
    "    df_import = df_import.assign(ProjectTitle=list_projtitle)\n",
    "    df_import = df_import.assign(ProjectDescription=list_projdesc)\n",
    "    df_import = df_import.assign(ProjectStatus=list_projstatus)\n",
    "    df_import = df_import.assign(SB1Funds=list_sb1funds)\n",
    "    df_import = df_import.assign(TotalProjectCost=list_totalcost)\n",
    "    df_import = df_import.assign(FiscalYear=list_fy)\n",
    "    df_import = df_import.assign(SB1Flag=list_sb1flag)\n",
    "    df_import = df_import.assign(OnSHS=list_onshs)\n",
    "    df_import = df_import.assign(CaltransDistrict=list_ctdist)\n",
    "    df_import = df_import.assign(AssemblyDistricts=list_assembly)\n",
    "    df_import = df_import.assign(SenateDistricts=list_senate)\n",
    "    df_import = df_import.assign(CityCodes=list_citycode)\n",
    "    df_import = df_import.assign(CityAgencyID=list_cityid)\n",
    "    df_import = df_import.assign(CountyCode=list_countycode)\n",
    "    df_import = df_import.assign(CountyAgencyID=list_countyid)\n",
    "    df_import = df_import.assign(ImplementingAgencyID=list_impagencyid)\n",
    "\n",
    "    # write to csv file\n",
    "    df_import.to_csv(path)\n",
    "    return df_import\n",
    "\n",
    "\n",
    "# define function to create and populate template\n",
    "def data_import_location(df, path):\n",
    "    # convert raw data columns into list type for import\n",
    "    # start location data\n",
    "    list_projid = df[\"Project ID\"].to_list()\n",
    "    list_route = df[\"Route\"].to_list()\n",
    "    list_co_begin = df[\"Beg_County\"].to_list()\n",
    "    list_pm_begin_prefix = df[\"Beg_PM_Prefix\"].to_list()\n",
    "    list_pm_begin = df[\"Beg_Postmile\"].to_list()\n",
    "    list_pm_begin_suffix = df[\"Beg_Postmile\"].to_list()\n",
    "    list_co_end = df[\"End_County\"].to_list()\n",
    "    list_pm_end_prefix = df[\"End_PM_Prefix\"].to_list()\n",
    "    list_pm_end = df[\"End_Postmile\"].to_list()\n",
    "    list_pm_end_suffix = df[\"End_PM_Suffix\"].to_list()\n",
    "\n",
    "    # import columns as list type into empty dataframe\n",
    "    # start location data\n",
    "    df_import = pd.DataFrame()\n",
    "    df_import = df_import.assign(ProjectID=list_projid)\n",
    "    df_import = df_import.assign(Route=list_route)\n",
    "    df_import = df_import.assign(Beg_County=list_co_begin)\n",
    "    df_import = df_import.assign(Beg_PM_Prefix=list_pm_begin_prefix)\n",
    "    df_import = df_import.assign(Beg_Postmile=list_pm_begin)\n",
    "    df_import = df_import.assign(Beg_PM_Suffix=list_pm_begin_suffix)\n",
    "    df_import = df_import.assign(End_County=list_co_end)\n",
    "    df_import = df_import.assign(End_PM_Prefix=list_pm_end_prefix)\n",
    "    df_import = df_import.assign(End_Postmile=list_pm_end)\n",
    "    df_import = df_import.assign(End_PM_Suffix=list_pm_end_suffix)\n",
    "\n",
    "    # write to csv file\n",
    "    df_import.to_csv(path)\n",
    "    return df_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d26880e-d00a-4e55-826c-ab3c98319e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.02 - data processing functions\n",
    "\n",
    "\n",
    "# function to rename columns\n",
    "# https://www.geeksforgeeks.org/how-to-rename-columns-in-pandas-dataframe/\n",
    "def rename_col(df, old_col, new_col):\n",
    "    df = df.rename(columns={old_col: new_col}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# call function to rename columns\n",
    "# df_project = rename_col(\n",
    "#     df_project,\n",
    "#     'Assembly District\\n-Overlay-',\n",
    "#     'assembly_dist'\n",
    "# )\n",
    "\n",
    "\n",
    "# function to replace col val\n",
    "# https://www.geeksforgeeks.org/python-pandas-dataframe-replace/\n",
    "def replace_col(df, col, old_val, new_val):\n",
    "    df[col] = df[col].replace(to_replace=old_val, value=new_val)\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to flag null values for data subset\n",
    "def null_flag(df, col):\n",
    "    df[col].fillna(\" | null | \", inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# function convert col to numeric type\n",
    "# reference: https://stackoverflow.com/questions/47333227/pandas-valueerror-cannot-convert-float-nan-to-integer\n",
    "def convert_num(df, col):\n",
    "    # convert type\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# call function to convert col to numeric type\n",
    "# df_project = convert_num(df_project, 'TotalProjectCost')\n",
    "\n",
    "\n",
    "# function convert col to string type\n",
    "# https://www.geeksforgeeks.org/python-pandas-series-astype-to-convert-data-type-of-series/\n",
    "def convert_str(df, col):\n",
    "    df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "# convert string to datetime\n",
    "# reference: https://stackoverflow.com/questions/32888124/pandas-out-of-bounds-nanosecond-timestamp-after-offset-rollforward-plus-adding-a\n",
    "def convert_date(df, col):\n",
    "    # convert type\n",
    "    df[col] = pd.to_datetime(df[col], infer_datetime_format=True, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# call function to show table info\n",
    "# data_profile(df_project, 'Project List')\n",
    "\n",
    "\n",
    "# function to replace newline\n",
    "# https://stackoverflow.com/questions/53872063/removing-quote-and-hidden-new-line/53872406#53872406\n",
    "def replace_newline(df, col):\n",
    "    # df[col].str.replace('\\n', '')\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .str.replace(chr(10), \" \")\n",
    "        .str.replace(chr(13), \" \")\n",
    "        .str.replace(chr(34), \" \")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# create function to print validation test results\n",
    "def print_result(invalid_count, df, total_count, invalid_ratio):\n",
    "    if invalid_count >= 1:\n",
    "        print(\"* Results: | \")\n",
    "        print(\"\\tNon-Compliant Rows:\", invalid_count, \" | \")\n",
    "        print(\"\\tTotal Rows:\", total_count, \" | \")\n",
    "        print(\"\\tPercent Non-Compliant:\", round(invalid_ratio, 4), \"\\n\")\n",
    "    elif invalid_count < 1:\n",
    "        print(\"* Results: 100% Passing (All Rows Compliant)\\n\")\n",
    "\n",
    "\n",
    "def output_result(df, filepath):\n",
    "    # output error report to csv file\n",
    "    df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011366ec-8ed1-4cee-9c24-86515b0ae79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03.00 - data subset and table join functions\n",
    "\n",
    "# subset dataset by row values; for example, project list by funding source\n",
    "# https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "# df_projects_atp = df_projects[df_projects['SOURCE'].str.contains('ATP')]\n",
    "\n",
    "\n",
    "# define table join function; merge new and old tables on given column\n",
    "def join_table(df_left, df_right, col, method, msg):\n",
    "    df_join = pd.merge(df_left, df_right, on=col, how=method)\n",
    "    print(msg, \"\\n\")\n",
    "    print(\"Before Table Join: \")\n",
    "    print(\"Left Table: \", df_left.shape)\n",
    "    print(\"Right Table: \", df_right.shape, \"\\n\")\n",
    "    print(\"After Table Join: \")\n",
    "    print(\"Left + Right Table: \", df_join.shape, \"\\n\")\n",
    "    return df_join\n",
    "\n",
    "\n",
    "# define table join function; merge new and old tables with different keys\n",
    "# https://stackoverflow.com/questions/25888207/pandas-join-dataframes-on-field-with-different-names\n",
    "def join_table_key(df_left, df_right, id_key, fk_key, msg):\n",
    "    df_join = pd.merge(\n",
    "        df_left, df_right, how=\"left\", left_on=[id_key], right_on=[fk_key]\n",
    "    )\n",
    "    print(msg, \"\\n\")\n",
    "    print(\"Before Table Join: \")\n",
    "    print(\"Left Table: \", df_left.shape)\n",
    "    print(\"Right Table: \", df_right.shape, \"\\n\")\n",
    "    print(\"After Table Join: \")\n",
    "    print(\"Left + Right Table: \", df_join.shape, \"\\n\")\n",
    "    return df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1d21ca-82aa-4273-8543-abddbb903417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/imms_2021b.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/imms_2022a.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/imms_2022b.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/imms_2023a.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/imms_2023b.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/imms_2024a.csv\n",
      "*** Table Dimensions: Original (IMMS 2021B) *** \n",
      "\n",
      "(26910, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2021B) *** \n",
      "\n",
      "(26910, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2021B) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2022A) *** \n",
      "\n",
      "(32379, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2022A) *** \n",
      "\n",
      "(32379, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2022A) *** \n",
      "\n",
      "(32379, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022A) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2022B) *** \n",
      "\n",
      "(34330, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2022B) *** \n",
      "\n",
      "(34330, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with null values in production columns (IMMS 2022B) ***\n",
      "\n",
      "(34330, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022B) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2023A) *** \n",
      "\n",
      "(32443, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2023A) *** \n",
      "\n",
      "(32443, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2023A) *** \n",
      "\n",
      "(32443, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023A) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2023B) *** \n",
      "\n",
      "(34346, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2023B) *** \n",
      "\n",
      "(34346, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2023B) *** \n",
      "\n",
      "(34346, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023B) ***\n",
      "\n",
      "(0, 32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 05.01.01 - data import/cleaning (imms)\n",
    "\n",
    "\n",
    "# import imms/litter collection totals as csv datasets from a local folder\n",
    "df_imms_2021b = load_csv_from_local_folder(\"imms_2021b.csv\")\n",
    "df_imms_2022a = load_csv_from_local_folder(\"imms_2022a.csv\")\n",
    "df_imms_2022b = load_csv_from_local_folder(\"imms_2022b.csv\")\n",
    "df_imms_2023a = load_csv_from_local_folder(\"imms_2023a.csv\")\n",
    "df_imms_2023b = load_csv_from_local_folder(\"imms_2023b.csv\")\n",
    "df_imms_2024a = load_csv_from_local_folder(\"imms_2024a.csv\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2021B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2021B) ***\", \"\\n\")\n",
    "print(df_imms_2021b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2021b = df_imms_2021b[~df_imms_2021b['From PM'].isnull()]\n",
    "# df_imms_2021b = df_imms_2021b[~df_imms_2021b['To PM'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null PM (IMMS 2021B) ***', '\\n')\n",
    "# print(df_imms_2021b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b[\"Production Quantity\"].isnull()]\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2021B) ***\", \"\\n\")\n",
    "print(df_imms_2021b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2021b = df_imms_2021b[df_imms_2021b[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2021b = df_imms_2021b[df_imms_2021b[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2021B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2021b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2022A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2022A) ***\", \"\\n\")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2022a = df_imms_2022a[~df_imms_2022a['From PM'].isnull()]\n",
    "# df_imms_2022a = df_imms_2022a[~df_imms_2022a['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2022A) ***\", \"\\n\")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a[\"Production Quantity\"].isnull()]\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2022A) ***\", \"\\n\")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2022a = df_imms_2022a[df_imms_2022a[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2022a = df_imms_2022a[df_imms_2022a[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022A) ***\\n\"\n",
    ")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2022B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2022B) ***\", \"\\n\")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2022b = df_imms_2022b[~df_imms_2022b['From PM'].isnull()]\n",
    "# df_imms_2022b = df_imms_2022b[~df_imms_2022b['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2022B) ***\", \"\\n\")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows with null values in 'Production Quantity' and 'Secondary Prod' columns\n",
    "df_imms_2022b = df_imms_2022b.dropna(subset=[\"Production Quantity\", \"Secondary Prod\"])\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with null values in production columns (IMMS 2022B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2022b = df_imms_2022b[df_imms_2022b[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2022b = df_imms_2022b[df_imms_2022b[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2023A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2023A) ***\", \"\\n\")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2023a = df_imms_2023a[~df_imms_2023a['From PM'].isnull()]\n",
    "# df_imms_2023a = df_imms_2023a[~df_imms_2023a['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2023A) ***\", \"\\n\")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a[\"Production Quantity\"].isnull()]\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2023A) ***\", \"\\n\")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2023a = df_imms_2023a[df_imms_2023a[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2023a = df_imms_2023a[df_imms_2023a[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023A) ***\\n\"\n",
    ")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2023B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2023B) ***\", \"\\n\")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2023b = df_imms_2023b[~df_imms_2023b['From PM'].isnull()]\n",
    "# df_imms_2023b = df_imms_2023b[~df_imms_2023b['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2023B) ***\", \"\\n\")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b[\"Production Quantity\"].isnull()]\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2023B) ***\", \"\\n\")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2023b = df_imms_2023b[df_imms_2023b[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2023b = df_imms_2023b[df_imms_2023b[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# Added by NS April 2025\n",
    "# export final csv file\n",
    "write_data_csv(df_imms_2021b, f\"{output_folder}/df_imms_2021b.csv\")\n",
    "write_data_csv(df_imms_2022a, f\"{output_folder}/df_imms_2022a.csv\")\n",
    "write_data_csv(df_imms_2022b, f\"{output_folder}/df_imms_2022b.csv\")\n",
    "write_data_csv(df_imms_2023a, f\"{output_folder}/df_imms_2023a.csv\")\n",
    "write_data_csv(df_imms_2023b, f\"{output_folder}/df_imms_2023b.csv\")\n",
    "write_data_csv(df_imms_2024a, f\"{output_folder}/df_imms_2024a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097a223c-7ff2-439f-81d8-e2b088b28ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/csr_litter_aah_2021b.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/csr_litter_aah_2022a.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/csr_litter_aah_2022b.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/csr_litter_aah_2023a.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/csr_litter_aah_2023b.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/csr_litter_aah_2024a.csv\n",
      "*** Table Dimensions: Original (CSR 2021B) *** \n",
      "\n",
      "(1045, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null date opened (CSR 2021B) *** \n",
      "\n",
      "(1045, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null lat/long (CSR 2021B) *** \n",
      "\n",
      "(1045, 39) \n",
      "\n",
      "*** Table Dimensions: Original (CSR 2022A) *** \n",
      "\n",
      "(3569, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null date opened (CSR 2022A) *** \n",
      "\n",
      "(3569, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null lat/long (CSR 2022A) *** \n",
      "\n",
      "(3569, 39) \n",
      "\n",
      "*** Table Dimensions: Original (CSR 2022B) *** \n",
      "\n",
      "(4079, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null date opened (CSR 2022B) *** \n",
      "\n",
      "(4079, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null lat/long (CSR 2022B) *** \n",
      "\n",
      "(4079, 39) \n",
      "\n",
      "*** Table Dimensions: Original (CSR 2023A) *** \n",
      "\n",
      "(3088, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null date opened (CSR 2023A) *** \n",
      "\n",
      "(3088, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null lat/long (CSR 2023A) *** \n",
      "\n",
      "(3088, 39) \n",
      "\n",
      "*** Table Dimensions: Original (CSR 2023B) *** \n",
      "\n",
      "(4031, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null date opened (CSR 2023B) *** \n",
      "\n",
      "(4031, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null lat/long (CSR 2023B) *** \n",
      "\n",
      "(4031, 39) \n",
      "\n",
      "*** Table Dimensions: Original (CSR 2024A) *** \n",
      "\n",
      "(3396, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null date opened (CSR 2024A) *** \n",
      "\n",
      "(3396, 39) \n",
      "\n",
      "*** Table Dimensions: Remove null lat/long (CSR 2024A) *** \n",
      "\n",
      "(3396, 39) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 05.01.02 - data import/cleaning (csr)\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# Import CSR data as CSV datasets\n",
    "df_csr_2021b = load_csv_from_local_folder(\"csr_litter_aah_2021b.csv\")\n",
    "df_csr_2022a = load_csv_from_local_folder(\"csr_litter_aah_2022a.csv\")\n",
    "df_csr_2022b = load_csv_from_local_folder(\"csr_litter_aah_2022b.csv\")\n",
    "df_csr_2023a = load_csv_from_local_folder(\"csr_litter_aah_2023a.csv\")\n",
    "df_csr_2023b = load_csv_from_local_folder(\"csr_litter_aah_2023b.csv\")\n",
    "df_csr_2024a = load_csv_from_local_folder(\"csr_litter_aah_2024a.csv\")\n",
    "\n",
    "# clean data - CSR 2021B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2021B) ***\", \"\\n\")\n",
    "print(df_csr_2021b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2021B) ***\", \"\\n\")\n",
    "print(df_csr_2021b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b[\"Latitude\"].isnull()]\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2021B) ***\", \"\\n\")\n",
    "print(df_csr_2021b.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2022A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2022A) ***\", \"\\n\")\n",
    "print(df_csr_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2022A) ***\", \"\\n\")\n",
    "print(df_csr_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a[\"Latitude\"].isnull()]\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2022A) ***\", \"\\n\")\n",
    "print(df_csr_2022a.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2022B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2022B) ***\", \"\\n\")\n",
    "print(df_csr_2022b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2022B) ***\", \"\\n\")\n",
    "print(df_csr_2022b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b[\"Latitude\"].isnull()]\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2022B) ***\", \"\\n\")\n",
    "print(df_csr_2022b.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2023A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2023A) ***\", \"\\n\")\n",
    "print(df_csr_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2023A) ***\", \"\\n\")\n",
    "print(df_csr_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a[\"Latitude\"].isnull()]\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2023A) ***\", \"\\n\")\n",
    "print(df_csr_2023a.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2023B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2023B) ***\", \"\\n\")\n",
    "print(df_csr_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2023B) ***\", \"\\n\")\n",
    "print(df_csr_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b[\"Latitude\"].isnull()]\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2023B) ***\", \"\\n\")\n",
    "print(df_csr_2023b.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2024A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2024A) ***\", \"\\n\")\n",
    "print(df_csr_2024a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2024A) ***\", \"\\n\")\n",
    "print(df_csr_2024a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a[\"Latitude\"].isnull()]\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2024A) ***\", \"\\n\")\n",
    "print(df_csr_2024a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Added by NS\n",
    "# export final csv file\n",
    "write_data_csv(df_csr_2021b, f\"{output_folder}/05.01.02_data_clean_csr_2021b.csv\")\n",
    "write_data_csv(df_csr_2022a, f\"{output_folder}/05.01.02_data_clean_csr_2022a.csv\")\n",
    "write_data_csv(df_csr_2022b, f\"{output_folder}/05.01.02_data_clean_csr_2022b.csv\")\n",
    "write_data_csv(df_csr_2023a, f\"{output_folder}/05.01.02_data_clean_csr_2023a.csv\")\n",
    "write_data_csv(df_csr_2023b, f\"{output_folder}/05.01.02_data_clean_csr_2023b.csv\")\n",
    "write_data_csv(df_csr_2024a, f\"{output_folder}/05.01.02_data_clean_csr_2024a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a876c3-ad08-44ef-917c-f9bae2d446db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d1.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d2.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d3.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d4.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d5.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d6.csv\n",
      "Error loading CSV: 'utf-8' codec can't decode byte 0xa0 in position 3844: invalid start byte\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d8.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d9.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d10.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d11.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_2023a_d12.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d1.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d2.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d3.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d4.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d5.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d6.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d7.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d8.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d9.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d10.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d11.csv\n",
      "Loaded CSV from: /home/jovyan/big-data-geoanalytics/cc_litter_study/0_source_data/los_scores_raw_d12.csv\n",
      "*** Table Info: Data Profile: LOS - d1 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Columns: 305 entries, SegID to los_2024_q4\n",
      "dtypes: float64(120), object(185)\n",
      "memory usage: 159.8+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(67, 305) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d2 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 185 entries, 0 to 184\n",
      "Columns: 304 entries, ID to los_2024_q4\n",
      "dtypes: float64(87), object(217)\n",
      "memory usage: 439.5+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(185, 304) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d3 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234 entries, 0 to 233\n",
      "Columns: 295 entries, ID to los_2024_q4\n",
      "dtypes: float64(78), object(217)\n",
      "memory usage: 539.4+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(234, 295) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d4 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356 entries, 0 to 355\n",
      "Columns: 309 entries, ID to los_2024_q4\n",
      "dtypes: float64(32), object(277)\n",
      "memory usage: 859.5+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(356, 309) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d5 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 236 entries, 0 to 235\n",
      "Columns: 304 entries, ID to los_2024_q4\n",
      "dtypes: float64(41), object(263)\n",
      "memory usage: 560.6+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(236, 304) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d6 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238 entries, 0 to 237\n",
      "Columns: 291 entries, ID to los_2024_q4\n",
      "dtypes: float64(43), object(248)\n",
      "memory usage: 541.2+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(238, 291) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d7 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 411 entries, 0 to 410\n",
      "Columns: 311 entries, ID to los_2024_q4\n",
      "dtypes: float64(71), object(240)\n",
      "memory usage: 998.7+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(411, 311) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d8 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 272 entries, 0 to 271\n",
      "Columns: 306 entries, ID to los_2024_q4\n",
      "dtypes: float64(29), object(277)\n",
      "memory usage: 650.4+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(272, 306) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d9 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Columns: 277 entries, ID to los_2024_q4\n",
      "dtypes: float64(114), object(163)\n",
      "memory usage: 171.1+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(79, 277) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d10 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234 entries, 0 to 233\n",
      "Columns: 296 entries, ID to los_2024_q4\n",
      "dtypes: float64(77), object(219)\n",
      "memory usage: 541.3+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(234, 296) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d11 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212 entries, 0 to 211\n",
      "Columns: 304 entries, HQ Id to los_2024_q4\n",
      "dtypes: float64(51), object(253)\n",
      "memory usage: 503.6+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(212, 304) \n",
      "\n",
      "*** Table Info: Data Profile: LOS - d12 *** \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Columns: 304 entries, ID to los_2024_q4\n",
      "dtypes: float64(36), object(268)\n",
      "memory usage: 589.1+ KB\n",
      "None \n",
      "\n",
      "*** Table Info: Table Dimensions *** \n",
      "\n",
      "(248, 304) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d1) *** \n",
      "\n",
      "(67, 39) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d2) *** \n",
      "\n",
      "(183, 38) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d3) *** \n",
      "\n",
      "(227, 37) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d4) *** \n",
      "\n",
      "(339, 33) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d5) *** \n",
      "\n",
      "(212, 25) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d6) *** \n",
      "\n",
      "(212, 25) \n",
      "\n",
      "*** Table Dimensions: Original (los_2023a_d7) *** \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 123\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# check table dim\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d6) ***', '\\n')\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# print(df_los_2023a_d6.shape , '\\n')\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# clean data - los_2023a_d7\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# check table dim\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Table Dimensions: Original (los_2023a_d7) ***\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_los_2023a_d7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# remove null values from given column\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\u001b[39;00m\n\u001b[1;32m    126\u001b[0m df_los_2023a_d7 \u001b[38;5;241m=\u001b[39m df_los_2023a_d7[\u001b[38;5;241m~\u001b[39mdf_los_2023a_d7[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCO\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 05.01.03 - data import/cleaning (los)\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# Import LOS scores data as CSV datasets\n",
    "df_los_2023a_d1 = load_csv_from_local_folder(\"los_scores_2023a_d1.csv\")\n",
    "df_los_2023a_d2 = load_csv_from_local_folder(\"los_scores_2023a_d2.csv\")\n",
    "df_los_2023a_d3 = load_csv_from_local_folder(\"los_scores_2023a_d3.csv\")\n",
    "df_los_2023a_d4 = load_csv_from_local_folder(\"los_scores_2023a_d4.csv\")\n",
    "df_los_2023a_d5 = load_csv_from_local_folder(\"los_scores_2023a_d5.csv\")\n",
    "df_los_2023a_d6 = load_csv_from_local_folder(\"los_scores_2023a_d6.csv\")\n",
    "df_los_2023a_d7 = load_csv_from_local_folder(\"los_scores_2023a_d7.csv\")\n",
    "df_los_2023a_d8 = load_csv_from_local_folder(\"los_scores_2023a_d8.csv\")\n",
    "df_los_2023a_d9 = load_csv_from_local_folder(\"los_scores_2023a_d9.csv\")\n",
    "df_los_2023a_d10 = load_csv_from_local_folder(\"los_scores_2023a_d10.csv\")\n",
    "df_los_2023a_d11 = load_csv_from_local_folder(\"los_scores_2023a_d11.csv\")\n",
    "df_los_2023a_d12 = load_csv_from_local_folder(\"los_scores_2023a_d12.csv\")\n",
    "\n",
    "\n",
    "# Import LOS scores (raw) as CSV datasets\n",
    "df_los_all_d1 = load_csv_from_local_folder(\"los_scores_raw_d1.csv\")\n",
    "df_los_all_d2 = load_csv_from_local_folder(\"los_scores_raw_d2.csv\")\n",
    "df_los_all_d3 = load_csv_from_local_folder(\"los_scores_raw_d3.csv\")\n",
    "df_los_all_d4 = load_csv_from_local_folder(\"los_scores_raw_d4.csv\")\n",
    "df_los_all_d5 = load_csv_from_local_folder(\"los_scores_raw_d5.csv\")\n",
    "df_los_all_d6 = load_csv_from_local_folder(\"los_scores_raw_d6.csv\")\n",
    "df_los_all_d7 = load_csv_from_local_folder(\"los_scores_raw_d7.csv\")\n",
    "df_los_all_d8 = load_csv_from_local_folder(\"los_scores_raw_d8.csv\")\n",
    "df_los_all_d9 = load_csv_from_local_folder(\"los_scores_raw_d9.csv\")\n",
    "df_los_all_d10 = load_csv_from_local_folder(\"los_scores_raw_d10.csv\")\n",
    "df_los_all_d11 = load_csv_from_local_folder(\"los_scores_raw_d11.csv\")\n",
    "df_los_all_d12 = load_csv_from_local_folder(\"los_scores_raw_d12.csv\")\n",
    "\n",
    "\n",
    "# import los scores as csv datasets\n",
    "data_profile(df_los_all_d1, \"Data Profile: LOS - d1\")\n",
    "data_profile(df_los_all_d2, \"Data Profile: LOS - d2\")\n",
    "data_profile(df_los_all_d3, \"Data Profile: LOS - d3\")\n",
    "data_profile(df_los_all_d4, \"Data Profile: LOS - d4\")\n",
    "data_profile(df_los_all_d5, \"Data Profile: LOS - d5\")\n",
    "data_profile(df_los_all_d6, \"Data Profile: LOS - d6\")\n",
    "data_profile(df_los_all_d7, \"Data Profile: LOS - d7\")\n",
    "data_profile(df_los_all_d8, \"Data Profile: LOS - d8\")\n",
    "data_profile(df_los_all_d9, \"Data Profile: LOS - d9\")\n",
    "data_profile(df_los_all_d10, \"Data Profile: LOS - d10\")\n",
    "data_profile(df_los_all_d11, \"Data Profile: LOS - d11\")\n",
    "data_profile(df_los_all_d12, \"Data Profile: LOS - d12\")\n",
    "\n",
    "# clean data - los_2023a_d1\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d1) ***\", \"\\n\")\n",
    "print(df_los_2023a_d1.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d1 = df_los_2023a_d1[~df_los_2023a_d1[\"CO\"].isnull()]\n",
    "df_los_2023a_d1 = df_los_2023a_d1[~df_los_2023a_d1[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d1) ***', '\\n')\n",
    "# print(df_los_2023a_d1.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d2\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d2) ***\", \"\\n\")\n",
    "print(df_los_2023a_d2.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d2 = df_los_2023a_d2[~df_los_2023a_d2[\"CO\"].isnull()]\n",
    "df_los_2023a_d2 = df_los_2023a_d2[~df_los_2023a_d2[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d2) ***', '\\n')\n",
    "# print(df_los_2023a_d2.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d3\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d3) ***\", \"\\n\")\n",
    "print(df_los_2023a_d3.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d3 = df_los_2023a_d3[~df_los_2023a_d3[\"CO\"].isnull()]\n",
    "df_los_2023a_d3 = df_los_2023a_d3[~df_los_2023a_d3[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d3) ***', '\\n')\n",
    "# print(df_los_2023a_d3.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d4\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d4) ***\", \"\\n\")\n",
    "print(df_los_2023a_d4.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d4 = df_los_2023a_d4[~df_los_2023a_d4[\"CO\"].isnull()]\n",
    "df_los_2023a_d4 = df_los_2023a_d4[~df_los_2023a_d4[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d4) ***', '\\n')\n",
    "# print(df_los_2023a_d4.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d5\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d5) ***\", \"\\n\")\n",
    "print(df_los_2023a_d5.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d5 = df_los_2023a_d5[~df_los_2023a_d5[\"CO\"].isnull()]\n",
    "df_los_2023a_d5 = df_los_2023a_d5[~df_los_2023a_d5[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d5) ***', '\\n')\n",
    "# print(df_los_2023a_d5.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d6\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d6) ***\", \"\\n\")\n",
    "print(df_los_2023a_d6.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d6 = df_los_2023a_d6[~df_los_2023a_d6[\"CO\"].isnull()]\n",
    "df_los_2023a_d6 = df_los_2023a_d6[~df_los_2023a_d6[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d6) ***', '\\n')\n",
    "# print(df_los_2023a_d6.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d7\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d7) ***\", \"\\n\")\n",
    "print(df_los_2023a_d7.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d7 = df_los_2023a_d7[~df_los_2023a_d7[\"CO\"].isnull()]\n",
    "df_los_2023a_d7 = df_los_2023a_d7[~df_los_2023a_d7[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d7) ***', '\\n')\n",
    "# print(df_los_2023a_d7.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d8\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d8) ***\", \"\\n\")\n",
    "print(df_los_2023a_d8.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d8 = df_los_2023a_d8[~df_los_2023a_d8[\"CO\"].isnull()]\n",
    "df_los_2023a_d8 = df_los_2023a_d8[~df_los_2023a_d8[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d8) ***', '\\n')\n",
    "# print(df_los_2023a_d8.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d9\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d9) ***\", \"\\n\")\n",
    "print(df_los_2023a_d9.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d9 = df_los_2023a_d9[~df_los_2023a_d9[\"CO\"].isnull()]\n",
    "df_los_2023a_d9 = df_los_2023a_d9[~df_los_2023a_d9[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d9) ***', '\\n')\n",
    "# print(df_los_2023a_d9.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d10\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d10) ***\", \"\\n\")\n",
    "print(df_los_2023a_d10.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d10 = df_los_2023a_d10[~df_los_2023a_d10[\"CO\"].isnull()]\n",
    "df_los_2023a_d10 = df_los_2023a_d10[~df_los_2023a_d10[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d10) ***', '\\n')\n",
    "# print(df_los_2023a_d10.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d11\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d11) ***\", \"\\n\")\n",
    "print(df_los_2023a_d11.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d11 = df_los_2023a_d11[~df_los_2023a_d11[\"CO\"].isnull()]\n",
    "df_los_2023a_d11 = df_los_2023a_d11[~df_los_2023a_d11[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d11) ***', '\\n')\n",
    "# print(df_los_2023a_d11.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d12\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d12) ***\", \"\\n\")\n",
    "print(df_los_2023a_d12.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d12 = df_los_2023a_d12[~df_los_2023a_d12[\"CO\"].isnull()]\n",
    "df_los_2023a_d12 = df_los_2023a_d12[~df_los_2023a_d12[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d12) ***', '\\n')\n",
    "# print(df_los_2023a_d12.shape , '\\n')\n",
    "\n",
    "\n",
    "# Added by NS April 2025\n",
    "# export final csv file\n",
    "write_data_csv(df_los_2023a_d1, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d1.csv\")\n",
    "write_data_csv(df_los_2023a_d2, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d2.csv\")\n",
    "write_data_csv(df_los_2023a_d3, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d3.csv\")\n",
    "write_data_csv(df_los_2023a_d4, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d4.csv\")\n",
    "write_data_csv(df_los_2023a_d5, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d5.csv\")\n",
    "write_data_csv(df_los_2023a_d6, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d6.csv\")\n",
    "write_data_csv(df_los_2023a_d7, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d7.csv\")\n",
    "write_data_csv(df_los_2023a_d8, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d8.csv\")\n",
    "write_data_csv(df_los_2023a_d9, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d9.csv\")\n",
    "write_data_csv(df_los_2023a_d10, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d10.csv\")\n",
    "write_data_csv(df_los_2023a_d11, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d11.csv\")\n",
    "write_data_csv(df_los_2023a_d12, f\"{data_output_folder}/05.01.03_data_clean_los_2023a_d12.csv\")\n",
    "\n",
    "\n",
    "# clean data - los_all_d1\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d1) ***\", \"\\n\")\n",
    "print(df_los_all_d1.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d1 = df_los_all_d1[~df_los_all_d1[\"CO\"].isnull()]\n",
    "df_los_all_d1 = df_los_all_d1[~df_los_all_d1[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d1) ***\", \"\\n\")\n",
    "print(df_los_all_d1.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d2\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d2) ***\", \"\\n\")\n",
    "print(df_los_all_d2.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d2 = df_los_all_d2[~df_los_all_d2[\"CO\"].isnull()]\n",
    "df_los_all_d2 = df_los_all_d2[~df_los_all_d2[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d2) ***\", \"\\n\")\n",
    "print(df_los_all_d2.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d3\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d3) ***\", \"\\n\")\n",
    "print(df_los_all_d3.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d3 = df_los_all_d3[~df_los_all_d3[\"CO\"].isnull()]\n",
    "df_los_all_d3 = df_los_all_d3[~df_los_all_d3[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d3) ***\", \"\\n\")\n",
    "print(df_los_all_d3.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d4\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d4) ***\", \"\\n\")\n",
    "print(df_los_all_d4.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d4 = df_los_all_d4[~df_los_all_d4[\"CO\"].isnull()]\n",
    "df_los_all_d4 = df_los_all_d4[~df_los_all_d4[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d4) ***\", \"\\n\")\n",
    "print(df_los_all_d4.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d5\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d5) ***\", \"\\n\")\n",
    "print(df_los_all_d5.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d5 = df_los_all_d5[~df_los_all_d5[\"CO\"].isnull()]\n",
    "df_los_all_d5 = df_los_all_d5[~df_los_all_d5[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d5) ***\", \"\\n\")\n",
    "print(df_los_all_d5.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d6\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d6) ***\", \"\\n\")\n",
    "print(df_los_all_d6.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d6 = df_los_all_d6[~df_los_all_d6[\"CO\"].isnull()]\n",
    "df_los_all_d6 = df_los_all_d6[~df_los_all_d6[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d6) ***\", \"\\n\")\n",
    "print(df_los_all_d6.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d7\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d7) ***\", \"\\n\")\n",
    "print(df_los_all_d7.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d7 = df_los_all_d7[~df_los_all_d7[\"CO\"].isnull()]\n",
    "df_los_all_d7 = df_los_all_d7[~df_los_all_d7[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d7) ***\", \"\\n\")\n",
    "print(df_los_all_d7.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d8\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d8) ***\", \"\\n\")\n",
    "print(df_los_all_d8.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d8 = df_los_all_d8[~df_los_all_d8[\"CO\"].isnull()]\n",
    "df_los_all_d8 = df_los_all_d8[~df_los_all_d8[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d8) ***\", \"\\n\")\n",
    "print(df_los_all_d8.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d9\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d9) ***\", \"\\n\")\n",
    "print(df_los_all_d9.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d9 = df_los_all_d9[~df_los_all_d9[\"CO\"].isnull()]\n",
    "df_los_all_d9 = df_los_all_d9[~df_los_all_d9[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d9) ***\", \"\\n\")\n",
    "print(df_los_all_d9.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d10\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d10) ***\", \"\\n\")\n",
    "print(df_los_all_d10.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d10 = df_los_all_d10[~df_los_all_d10[\"CO\"].isnull()]\n",
    "df_los_all_d10 = df_los_all_d10[~df_los_all_d10[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d10) ***\", \"\\n\")\n",
    "print(df_los_all_d10.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d11\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d11) ***\", \"\\n\")\n",
    "print(df_los_all_d11.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d11 = df_los_all_d11[~df_los_all_d11[\"CO\"].isnull()]\n",
    "df_los_all_d11 = df_los_all_d11[~df_los_all_d11[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d11) ***\", \"\\n\")\n",
    "print(df_los_all_d11.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d12\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d12) ***\", \"\\n\")\n",
    "print(df_los_all_d12.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d12 = df_los_all_d12[~df_los_all_d12[\"CO\"].isnull()]\n",
    "df_los_all_d12 = df_los_all_d12[~df_los_all_d12[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d12) ***\", \"\\n\")\n",
    "print(df_los_all_d12.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# export final csv file\n",
    "write_data_csv(df_los_all_d1, f\"{data_output_folder}/05.01.03_data_clean_los_all_d1.csv\")\n",
    "write_data_csv(df_los_all_d2, f\"{data_output_folder}/05.01.03_data_clean_los_all_d2.csv\")\n",
    "write_data_csv(df_los_all_d3, f\"{data_output_folder}/05.01.03_data_clean_los_all_d3.csv\")\n",
    "write_data_csv(df_los_all_d4, f\"{data_output_folder}/05.01.03_data_clean_los_all_d4.csv\")\n",
    "write_data_csv(df_los_all_d5, f\"{data_output_folder}/05.01.03_data_clean_los_all_d5.csv\")\n",
    "write_data_csv(df_los_all_d6, f\"{data_output_folder}/05.01.03_data_clean_los_all_d6.csv\")\n",
    "write_data_csv(df_los_all_d7, f\"{data_output_folder}/05.01.03_data_clean_los_all_d7.csv\")\n",
    "write_data_csv(df_los_all_d8, f\"{data_output_folder}/05.01.03_data_clean_los_all_d8.csv\")\n",
    "write_data_csv(df_los_all_d9, f\"{data_output_folder}/05.01.03_data_clean_los_all_d9.csv\")\n",
    "write_data_csv(df_los_all_d10, f\"{data_output_folder}/05.01.03_data_clean_los_all_d10.csv\")\n",
    "write_data_csv(df_los_all_d11, f\"{data_output_folder}/05.01.03_data_clean_los_all_d11.csv\")\n",
    "write_data_csv(df_los_all_d12, f\"{data_output_folder}/05.01.03_data_clean_los_all_d12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de73b1-f5a7-45e7-8628-b7b879bfc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.01 - data analysis (imms)\n",
    "\n",
    "# format data for plotting\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Data without emtpy CY values (IMMS 2023A) ***', '\\n')\n",
    "# print(df_imms_2023a.shape , '\\n')\n",
    "\n",
    "\n",
    "# NS, this next section was commented out and replaced with a function (I was receiving errors with this current format)\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d1 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d1 = df_imms_2023a_bar_d1[df_imms_2023a_bar_d1['Resp. District'].astype(np.int) == 1]\n",
    "\n",
    "# # subset data for additional plots on corridors with high litter totals\n",
    "# # df_imms_2023a_bar_01hum101 = df_imms_2023a_bar_d1[df_imms_2023a_bar_d1['IMMS Unit ID'].str.contains('01-HUM-101')]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d2 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d2 = df_imms_2023a_bar_d2[df_imms_2023a_bar_d2['Resp. District'].astype(np.int) == 2]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d3 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d3 = df_imms_2023a_bar_d3[df_imms_2023a_bar_d3['Resp. District'].astype(np.int) == 3]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d4 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d4 = df_imms_2023a_bar_d4[df_imms_2023a_bar_d4['Resp. District'].astype(np.int) == 4]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d5 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d5 = df_imms_2023a_bar_d5[df_imms_2023a_bar_d5['Resp. District'].astype(np.int) == 5]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d6 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d6 = df_imms_2023a_bar_d6[df_imms_2023a_bar_d6['Resp. District'].astype(np.int) == 6]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d7 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d7 = df_imms_2023a_bar_d7[df_imms_2023a_bar_d7['Resp. District'].astype(np.int) == 7]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d8 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d8 = df_imms_2023a_bar_d8[df_imms_2023a_bar_d8['Resp. District'].astype(np.int) == 8]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d9 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d9 = df_imms_2023a_bar_d9[df_imms_2023a_bar_d9['Resp. District'].astype(np.int) == 9]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d10 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d10 = df_imms_2023a_bar_d10[df_imms_2023a_bar_d10['Resp. District'].astype(np.int) == 10]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d11 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d11 = df_imms_2023a_bar_d11[df_imms_2023a_bar_d11['Resp. District'].astype(np.int) == 11]\n",
    "\n",
    "# # remove row if value is greater than given value\n",
    "# # https://stackoverflow.com/questions/41800424/remove-rows-in-python-less-than-a-certain-value\n",
    "# # https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_imms_2023a_bar_d12 = df_imms_2023a[df_imms_2023a['UOM'].str.contains('CUYD')]\n",
    "# df_imms_2023a_bar_d12 = df_imms_2023a_bar_d12[df_imms_2023a_bar_d12['Resp. District'].astype(np.int) == 12]\n",
    "\n",
    "\n",
    "# The replacement\n",
    "def filter_by_uom_and_district(df, district_number):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame for rows where 'UOM' contains 'CUYD' and 'Resp. District' equals the specified district_number.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    district_number (int): The district number to filter by.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure 'Resp. District' is of integer type for accurate comparison\n",
    "    df[\"Resp. District\"] = pd.to_numeric(df[\"Resp. District\"], errors=\"coerce\")\n",
    "\n",
    "    # Filter rows where 'UOM' contains 'CUYD' and 'Resp. District' matches the specified number\n",
    "    filtered_df = df[\n",
    "        df[\"UOM\"].str.contains(\"CUYD\", na=False)\n",
    "        & (df[\"Resp. District\"] == district_number)\n",
    "    ]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Apply the function to create various dataframes\n",
    "df_imms_2023a_bar_d1 = filter_by_uom_and_district(df_imms_2023a, 1)\n",
    "df_imms_2023a_bar_d2 = filter_by_uom_and_district(df_imms_2023a, 2)\n",
    "df_imms_2023a_bar_d3 = filter_by_uom_and_district(df_imms_2023a, 3)\n",
    "df_imms_2023a_bar_d4 = filter_by_uom_and_district(df_imms_2023a, 4)\n",
    "df_imms_2023a_bar_d5 = filter_by_uom_and_district(df_imms_2023a, 5)\n",
    "df_imms_2023a_bar_d6 = filter_by_uom_and_district(df_imms_2023a, 6)\n",
    "df_imms_2023a_bar_d7 = filter_by_uom_and_district(df_imms_2023a, 7)\n",
    "df_imms_2023a_bar_d8 = filter_by_uom_and_district(df_imms_2023a, 8)\n",
    "df_imms_2023a_bar_d9 = filter_by_uom_and_district(df_imms_2023a, 9)\n",
    "df_imms_2023a_bar_d10 = filter_by_uom_and_district(df_imms_2023a, 10)\n",
    "df_imms_2023a_bar_d11 = filter_by_uom_and_district(df_imms_2023a, 11)\n",
    "df_imms_2023a_bar_d12 = filter_by_uom_and_district(df_imms_2023a, 12)\n",
    "\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D1) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D2) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D3) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D4) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D5) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D6) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D7) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D8) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D9) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D10) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D11) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D12) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac005 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac005 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac005 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac005 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac005 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac005 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac005, 'Data Profile: IMMS 2021b - 03sac005')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac005, 'Data Profile: IMMS 2022a - 03sac005')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac005, 'Data Profile: IMMS 2022b - 03sac005')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac005, 'Data Profile: IMMS 2023a - 03sac005')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac005, 'Data Profile: IMMS 2023b - 03sac005')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac005, 'Data Profile: IMMS 2024a - 03sac005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac005 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_03sac005,\n",
    "        df_imms_2022a_hotspot_03sac005,\n",
    "        df_imms_2022b_hotspot_03sac005,\n",
    "        df_imms_2023a_hotspot_03sac005,\n",
    "        df_imms_2023b_hotspot_03sac005,\n",
    "        df_imms_2024a_hotspot_03sac005,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_03sac005, 'Data Profile: IMMS Litter Hotspot - 03sac005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac050 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac050 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac050 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac050 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac050 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac050 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac050, 'Data Profile: IMMS 2021b - 03sac050')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac050, 'Data Profile: IMMS 2022a - 03sac050')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac050, 'Data Profile: IMMS 2022b - 03sac050')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac050, 'Data Profile: IMMS 2023a - 03sac050')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac050, 'Data Profile: IMMS 2023b - 03sac050')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac050, 'Data Profile: IMMS 2024a - 03sac050')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac050 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_03sac050,\n",
    "        df_imms_2022a_hotspot_03sac050,\n",
    "        df_imms_2022b_hotspot_03sac050,\n",
    "        df_imms_2023a_hotspot_03sac050,\n",
    "        df_imms_2023b_hotspot_03sac050,\n",
    "        df_imms_2024a_hotspot_03sac050,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_03sac050, 'Data Profile: IMMS Litter Hotspot - 03sac050')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac080 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac080 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac080 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac080 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac080 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac080 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac080, 'Data Profile: IMMS 2021b - 03sac080')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac080, 'Data Profile: IMMS 2022a - 03sac080')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac080, 'Data Profile: IMMS 2022b - 03sac080')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac080, 'Data Profile: IMMS 2023a - 03sac080')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac080, 'Data Profile: IMMS 2023b - 03sac080')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac080, 'Data Profile: IMMS 2024a - 03sac080')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac080 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_03sac080,\n",
    "        df_imms_2022a_hotspot_03sac080,\n",
    "        df_imms_2022b_hotspot_03sac080,\n",
    "        df_imms_2023a_hotspot_03sac080,\n",
    "        df_imms_2023b_hotspot_03sac080,\n",
    "        df_imms_2024a_hotspot_03sac080,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_03sac080, 'Data Profile: IMMS Litter Hotspot - 03sac080')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala580b = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala580b = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala580b = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala580b = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala580b = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala580b = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala580b, 'Data Profile: IMMS 2021b - 04ala580b')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala580b, 'Data Profile: IMMS 2022a - 04ala580b')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala580b, 'Data Profile: IMMS 2022b - 04ala580b')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala580b, 'Data Profile: IMMS 2023a - 04ala580b')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala580b, 'Data Profile: IMMS 2023b - 04ala580b')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala580b, 'Data Profile: IMMS 2024a - 04ala580b')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala580b = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04ala580b,\n",
    "        df_imms_2022a_hotspot_04ala580b,\n",
    "        df_imms_2022b_hotspot_04ala580b,\n",
    "        df_imms_2023a_hotspot_04ala580b,\n",
    "        df_imms_2023b_hotspot_04ala580b,\n",
    "        df_imms_2024a_hotspot_04ala580b,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04ala580b, 'Data Profile: IMMS Litter Hotspot - 04ala580b')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala680 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala680 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala680 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala680 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala680 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala680 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala680, 'Data Profile: IMMS 2021b - 04ala680')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala680, 'Data Profile: IMMS 2022a - 04ala680')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala680, 'Data Profile: IMMS 2022b - 04ala680')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala680, 'Data Profile: IMMS 2023a - 04ala680')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala680, 'Data Profile: IMMS 2023b - 04ala680')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala680, 'Data Profile: IMMS 2024a - 04ala680')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala680 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04ala680,\n",
    "        df_imms_2022a_hotspot_04ala680,\n",
    "        df_imms_2022b_hotspot_04ala680,\n",
    "        df_imms_2023a_hotspot_04ala680,\n",
    "        df_imms_2023b_hotspot_04ala680,\n",
    "        df_imms_2024a_hotspot_04ala680,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04ala680, 'Data Profile: IMMS Litter Hotspot - 04ala680')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala880 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala880 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala880 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala880 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala880 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala880 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala880, 'Data Profile: IMMS 2021b - 04ala880')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala880, 'Data Profile: IMMS 2022a - 04ala880')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala880, 'Data Profile: IMMS 2022b - 04ala880')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala880, 'Data Profile: IMMS 2023a - 04ala880')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala880, 'Data Profile: IMMS 2023b - 04ala880')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala880, 'Data Profile: IMMS 2024a - 04ala880')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala880 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04ala880,\n",
    "        df_imms_2022a_hotspot_04ala880,\n",
    "        df_imms_2022b_hotspot_04ala880,\n",
    "        df_imms_2023a_hotspot_04ala880,\n",
    "        df_imms_2023b_hotspot_04ala880,\n",
    "        df_imms_2024a_hotspot_04ala880,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04ala880, 'Data Profile: IMMS Litter Hotspot - 04ala880')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04cc004a = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04cc004a = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04cc004a = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04cc004a = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04cc004a = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04cc004a = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04cc004a, 'Data Profile: IMMS 2021b - 04cc004a')\n",
    "# data_profile(df_imms_2022a_hotspot_04cc004a, 'Data Profile: IMMS 2022a - 04cc004a')\n",
    "# data_profile(df_imms_2022b_hotspot_04cc004a, 'Data Profile: IMMS 2022b - 04cc004a')\n",
    "# data_profile(df_imms_2023a_hotspot_04cc004a, 'Data Profile: IMMS 2023a - 04cc004a')\n",
    "# data_profile(df_imms_2023b_hotspot_04cc004a, 'Data Profile: IMMS 2023b - 04cc004a')\n",
    "# data_profile(df_imms_2024a_hotspot_04cc004a, 'Data Profile: IMMS 2024a - 04cc004a')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04cc004a = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04cc004a,\n",
    "        df_imms_2022a_hotspot_04cc004a,\n",
    "        df_imms_2022b_hotspot_04cc004a,\n",
    "        df_imms_2023a_hotspot_04cc004a,\n",
    "        df_imms_2023b_hotspot_04cc004a,\n",
    "        df_imms_2024a_hotspot_04cc004a,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04cc004a, 'Data Profile: IMMS Litter Hotspot - 04cc004a')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04cc680 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04cc680 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04cc680 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04cc680 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04cc680 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04cc680 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04cc680, 'Data Profile: IMMS 2021b - 04cc680')\n",
    "# data_profile(df_imms_2022a_hotspot_04cc680, 'Data Profile: IMMS 2022a - 04cc680')\n",
    "# data_profile(df_imms_2022b_hotspot_04cc680, 'Data Profile: IMMS 2022b - 04cc680')\n",
    "# data_profile(df_imms_2023a_hotspot_04cc680, 'Data Profile: IMMS 2023a - 04cc680')\n",
    "# data_profile(df_imms_2023b_hotspot_04cc680, 'Data Profile: IMMS 2023b - 04cc680')\n",
    "# data_profile(df_imms_2024a_hotspot_04cc680, 'Data Profile: IMMS 2024a - 04cc680')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04cc680 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04cc680,\n",
    "        df_imms_2022a_hotspot_04cc680,\n",
    "        df_imms_2022b_hotspot_04cc680,\n",
    "        df_imms_2023a_hotspot_04cc680,\n",
    "        df_imms_2023b_hotspot_04cc680,\n",
    "        df_imms_2024a_hotspot_04cc680,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04cc680, 'Data Profile: IMMS Litter Hotspot - 04cc680')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_06fre099 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2022a_hotspot_06fre099 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2022b_hotspot_06fre099 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2023a_hotspot_06fre099 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2023b_hotspot_06fre099 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2024a_hotspot_06fre099 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_06fre099, 'Data Profile: IMMS 2021b - 06fre099')\n",
    "# data_profile(df_imms_2022a_hotspot_06fre099, 'Data Profile: IMMS 2022a - 06fre099')\n",
    "# data_profile(df_imms_2022b_hotspot_06fre099, 'Data Profile: IMMS 2022b - 06fre099')\n",
    "# data_profile(df_imms_2023a_hotspot_06fre099, 'Data Profile: IMMS 2023a - 06fre099')\n",
    "# data_profile(df_imms_2023b_hotspot_06fre099, 'Data Profile: IMMS 2023b - 06fre099')\n",
    "# data_profile(df_imms_2024a_hotspot_06fre099, 'Data Profile: IMMS 2024a - 06fre099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_06fre099 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_06fre099,\n",
    "        df_imms_2022a_hotspot_06fre099,\n",
    "        df_imms_2022b_hotspot_06fre099,\n",
    "        df_imms_2023a_hotspot_06fre099,\n",
    "        df_imms_2023b_hotspot_06fre099,\n",
    "        df_imms_2024a_hotspot_06fre099,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_06fre099, 'Data Profile: IMMS Litter Hotspot - 06fre099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_06ker099 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2022a_hotspot_06ker099 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2022b_hotspot_06ker099 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2023a_hotspot_06ker099 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2023b_hotspot_06ker099 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2024a_hotspot_06ker099 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_06ker099, 'Data Profile: IMMS 2021b - 06ker099')\n",
    "# data_profile(df_imms_2022a_hotspot_06ker099, 'Data Profile: IMMS 2022a - 06ker099')\n",
    "# data_profile(df_imms_2022b_hotspot_06ker099, 'Data Profile: IMMS 2022b - 06ker099')\n",
    "# data_profile(df_imms_2023a_hotspot_06ker099, 'Data Profile: IMMS 2023a - 06ker099')\n",
    "# data_profile(df_imms_2023b_hotspot_06ker099, 'Data Profile: IMMS 2023b - 06ker099')\n",
    "# data_profile(df_imms_2024a_hotspot_06ker099, 'Data Profile: IMMS 2024a - 06ker099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_06ker099 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_06ker099,\n",
    "        df_imms_2022a_hotspot_06ker099,\n",
    "        df_imms_2022b_hotspot_06ker099,\n",
    "        df_imms_2023a_hotspot_06ker099,\n",
    "        df_imms_2023b_hotspot_06ker099,\n",
    "        df_imms_2024a_hotspot_06ker099,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_06ker099, 'Data Profile: IMMS Litter Hotspot - 06ker099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la005a = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la005a = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la005a = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la005a = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la005a = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la005a = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la005a, 'Data Profile: IMMS 2021b - 07la005a')\n",
    "# data_profile(df_imms_2022a_hotspot_07la005a, 'Data Profile: IMMS 2022a - 07la005a')\n",
    "# data_profile(df_imms_2022b_hotspot_07la005a, 'Data Profile: IMMS 2022b - 07la005a')\n",
    "# data_profile(df_imms_2023a_hotspot_07la005a, 'Data Profile: IMMS 2023a - 07la005a')\n",
    "# data_profile(df_imms_2023b_hotspot_07la005a, 'Data Profile: IMMS 2023b - 07la005a')\n",
    "# data_profile(df_imms_2024a_hotspot_07la005a, 'Data Profile: IMMS 2024a - 07la005a')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la005a = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la005a,\n",
    "        df_imms_2022a_hotspot_07la005a,\n",
    "        df_imms_2022b_hotspot_07la005a,\n",
    "        df_imms_2023a_hotspot_07la005a,\n",
    "        df_imms_2023b_hotspot_07la005a,\n",
    "        df_imms_2024a_hotspot_07la005a,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la005a, 'Data Profile: IMMS Litter Hotspot - 07la005a')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la010 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la010 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la010 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la010 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la010 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la010 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la010, 'Data Profile: IMMS 2021b - 07la010')\n",
    "# data_profile(df_imms_2022a_hotspot_07la010, 'Data Profile: IMMS 2022a - 07la010')\n",
    "# data_profile(df_imms_2022b_hotspot_07la010, 'Data Profile: IMMS 2022b - 07la010')\n",
    "# data_profile(df_imms_2023a_hotspot_07la010, 'Data Profile: IMMS 2023a - 07la010')\n",
    "# data_profile(df_imms_2023b_hotspot_07la010, 'Data Profile: IMMS 2023b - 07la010')\n",
    "# data_profile(df_imms_2024a_hotspot_07la010, 'Data Profile: IMMS 2024a - 07la010')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la010 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la010,\n",
    "        df_imms_2022a_hotspot_07la010,\n",
    "        df_imms_2022b_hotspot_07la010,\n",
    "        df_imms_2023a_hotspot_07la010,\n",
    "        df_imms_2023b_hotspot_07la010,\n",
    "        df_imms_2024a_hotspot_07la010,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la010, 'Data Profile: IMMS Litter Hotspot - 07la010')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la101 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la101 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la101 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la101 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la101 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la101 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la101, 'Data Profile: IMMS 2021b - 07la101')\n",
    "# data_profile(df_imms_2022a_hotspot_07la101, 'Data Profile: IMMS 2022a - 07la101')\n",
    "# data_profile(df_imms_2022b_hotspot_07la101, 'Data Profile: IMMS 2022b - 07la101')\n",
    "# data_profile(df_imms_2023a_hotspot_07la101, 'Data Profile: IMMS 2023a - 07la101')\n",
    "# data_profile(df_imms_2023b_hotspot_07la101, 'Data Profile: IMMS 2023b - 07la101')\n",
    "# data_profile(df_imms_2024a_hotspot_07la101, 'Data Profile: IMMS 2024a - 07la101')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la101 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la101,\n",
    "        df_imms_2022a_hotspot_07la101,\n",
    "        df_imms_2022b_hotspot_07la101,\n",
    "        df_imms_2023a_hotspot_07la101,\n",
    "        df_imms_2023b_hotspot_07la101,\n",
    "        df_imms_2024a_hotspot_07la101,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la101, 'Data Profile: IMMS Litter Hotspot - 07la101')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la110 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la110 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la110 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la110 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la110 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la110 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la110, 'Data Profile: IMMS 2021b - 07la110')\n",
    "# data_profile(df_imms_2022a_hotspot_07la110, 'Data Profile: IMMS 2022a - 07la110')\n",
    "# data_profile(df_imms_2022b_hotspot_07la110, 'Data Profile: IMMS 2022b - 07la110')\n",
    "# data_profile(df_imms_2023a_hotspot_07la110, 'Data Profile: IMMS 2023a - 07la110')\n",
    "# data_profile(df_imms_2023b_hotspot_07la110, 'Data Profile: IMMS 2023b - 07la110')\n",
    "# data_profile(df_imms_2024a_hotspot_07la110, 'Data Profile: IMMS 2024a - 07la110')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la110 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la110,\n",
    "        df_imms_2022a_hotspot_07la110,\n",
    "        df_imms_2022b_hotspot_07la110,\n",
    "        df_imms_2023a_hotspot_07la110,\n",
    "        df_imms_2023b_hotspot_07la110,\n",
    "        df_imms_2024a_hotspot_07la110,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la110, 'Data Profile: IMMS Litter Hotspot - 07la110')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la405 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la405 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la405 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la405 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la405 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la405 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la405, 'Data Profile: IMMS 2021b - 07la405')\n",
    "# data_profile(df_imms_2022a_hotspot_07la405, 'Data Profile: IMMS 2022a - 07la405')\n",
    "# data_profile(df_imms_2022b_hotspot_07la405, 'Data Profile: IMMS 2022b - 07la405')\n",
    "# data_profile(df_imms_2023a_hotspot_07la405, 'Data Profile: IMMS 2023a - 07la405')\n",
    "# data_profile(df_imms_2023b_hotspot_07la405, 'Data Profile: IMMS 2023b - 07la405')\n",
    "# data_profile(df_imms_2024a_hotspot_07la405, 'Data Profile: IMMS 2024a - 07la405')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la405 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la405,\n",
    "        df_imms_2022a_hotspot_07la405,\n",
    "        df_imms_2022b_hotspot_07la405,\n",
    "        df_imms_2023a_hotspot_07la405,\n",
    "        df_imms_2023b_hotspot_07la405,\n",
    "        df_imms_2024a_hotspot_07la405,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la405, 'Data Profile: IMMS Litter Hotspot - 07la405')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_08riv010 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2022a_hotspot_08riv010 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2022b_hotspot_08riv010 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2023a_hotspot_08riv010 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2023b_hotspot_08riv010 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2024a_hotspot_08riv010 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_08riv010, 'Data Profile: IMMS 2021b - 08riv010')\n",
    "# data_profile(df_imms_2022a_hotspot_08riv010, 'Data Profile: IMMS 2022a - 08riv010')\n",
    "# data_profile(df_imms_2022b_hotspot_08riv010, 'Data Profile: IMMS 2022b - 08riv010')\n",
    "# data_profile(df_imms_2023a_hotspot_08riv010, 'Data Profile: IMMS 2023a - 08riv010')\n",
    "# data_profile(df_imms_2023b_hotspot_08riv010, 'Data Profile: IMMS 2023b - 08riv010')\n",
    "# data_profile(df_imms_2024a_hotspot_08riv010, 'Data Profile: IMMS 2024a - 08riv010')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_08riv010 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_08riv010,\n",
    "        df_imms_2022a_hotspot_08riv010,\n",
    "        df_imms_2022b_hotspot_08riv010,\n",
    "        df_imms_2023a_hotspot_08riv010,\n",
    "        df_imms_2023b_hotspot_08riv010,\n",
    "        df_imms_2024a_hotspot_08riv010,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_08riv010, 'Data Profile: IMMS Litter Hotspot - 08riv010')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_08riv060 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2022a_hotspot_08riv060 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2022b_hotspot_08riv060 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2023a_hotspot_08riv060 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2023b_hotspot_08riv060 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2024a_hotspot_08riv060 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_08riv060, 'Data Profile: IMMS 2021b - 08riv060')\n",
    "# data_profile(df_imms_2022a_hotspot_08riv060, 'Data Profile: IMMS 2022a - 08riv060')\n",
    "# data_profile(df_imms_2022b_hotspot_08riv060, 'Data Profile: IMMS 2022b - 08riv060')\n",
    "# data_profile(df_imms_2023a_hotspot_08riv060, 'Data Profile: IMMS 2023a - 08riv060')\n",
    "# data_profile(df_imms_2023b_hotspot_08riv060, 'Data Profile: IMMS 2023b - 08riv060')\n",
    "# data_profile(df_imms_2024a_hotspot_08riv060, 'Data Profile: IMMS 2024a - 08riv060')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_08riv060 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_08riv060,\n",
    "        df_imms_2022a_hotspot_08riv060,\n",
    "        df_imms_2022b_hotspot_08riv060,\n",
    "        df_imms_2023a_hotspot_08riv060,\n",
    "        df_imms_2023b_hotspot_08riv060,\n",
    "        df_imms_2024a_hotspot_08riv060,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_08riv060, 'Data Profile: IMMS Litter Hotspot - 08riv060')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_10sj005 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2022a_hotspot_10sj005 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2022b_hotspot_10sj005 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2023a_hotspot_10sj005 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2023b_hotspot_10sj005 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2024a_hotspot_10sj005 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_10sj005, 'Data Profile: IMMS 2021b - 10sj005')\n",
    "# data_profile(df_imms_2022a_hotspot_10sj005, 'Data Profile: IMMS 2022a - 10sj005')\n",
    "# data_profile(df_imms_2022b_hotspot_10sj005, 'Data Profile: IMMS 2022b - 10sj005')\n",
    "# data_profile(df_imms_2023a_hotspot_10sj005, 'Data Profile: IMMS 2023a - 10sj005')\n",
    "# data_profile(df_imms_2023b_hotspot_10sj005, 'Data Profile: IMMS 2023b - 10sj005')\n",
    "# data_profile(df_imms_2024a_hotspot_10sj005, 'Data Profile: IMMS 2024a - 10sj005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_10sj005 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_10sj005,\n",
    "        df_imms_2022a_hotspot_10sj005,\n",
    "        df_imms_2022b_hotspot_10sj005,\n",
    "        df_imms_2023a_hotspot_10sj005,\n",
    "        df_imms_2023b_hotspot_10sj005,\n",
    "        df_imms_2024a_hotspot_10sj005,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_10sj005, 'Data Profile: IMMS Litter Hotspot - 10sj005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_10sj099 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2022a_hotspot_10sj099 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2022b_hotspot_10sj099 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2023a_hotspot_10sj099 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2023b_hotspot_10sj099 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2024a_hotspot_10sj099 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_10sj099, 'Data Profile: IMMS 2021b - 10sj099')\n",
    "# data_profile(df_imms_2022a_hotspot_10sj099, 'Data Profile: IMMS 2022a - 10sj099')\n",
    "# data_profile(df_imms_2022b_hotspot_10sj099, 'Data Profile: IMMS 2022b - 10sj099')\n",
    "# data_profile(df_imms_2023a_hotspot_10sj099, 'Data Profile: IMMS 2023a - 10sj099')\n",
    "# data_profile(df_imms_2023b_hotspot_10sj099, 'Data Profile: IMMS 2023b - 10sj099')\n",
    "# data_profile(df_imms_2024a_hotspot_10sj099, 'Data Profile: IMMS 2024a - 10sj099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_10sj099 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_10sj099,\n",
    "        df_imms_2022a_hotspot_10sj099,\n",
    "        df_imms_2022b_hotspot_10sj099,\n",
    "        df_imms_2023a_hotspot_10sj099,\n",
    "        df_imms_2023b_hotspot_10sj099,\n",
    "        df_imms_2024a_hotspot_10sj099,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_10sj099, 'Data Profile: IMMS Litter Hotspot - 10sj099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_11sd005 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2022a_hotspot_11sd005 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2022b_hotspot_11sd005 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2023a_hotspot_11sd005 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2023b_hotspot_11sd005 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2024a_hotspot_11sd005 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_11sd005, 'Data Profile: IMMS 2021b - 11sd005')\n",
    "# data_profile(df_imms_2022a_hotspot_11sd005, 'Data Profile: IMMS 2022a - 11sd005')\n",
    "# data_profile(df_imms_2022b_hotspot_11sd005, 'Data Profile: IMMS 2022b - 11sd005')\n",
    "# data_profile(df_imms_2023a_hotspot_11sd005, 'Data Profile: IMMS 2023a - 11sd005')\n",
    "# data_profile(df_imms_2023b_hotspot_11sd005, 'Data Profile: IMMS 2023b - 11sd005')\n",
    "# data_profile(df_imms_2024a_hotspot_11sd005, 'Data Profile: IMMS 2024a - 11sd005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_11sd005 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_11sd005,\n",
    "        df_imms_2022a_hotspot_11sd005,\n",
    "        df_imms_2022b_hotspot_11sd005,\n",
    "        df_imms_2023a_hotspot_11sd005,\n",
    "        df_imms_2023b_hotspot_11sd005,\n",
    "        df_imms_2024a_hotspot_11sd005,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_11sd005, 'Data Profile: IMMS Litter Hotspot - 11sd005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_11sd805 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2022a_hotspot_11sd805 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2022b_hotspot_11sd805 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2023a_hotspot_11sd805 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2023b_hotspot_11sd805 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2024a_hotspot_11sd805 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_11sd805, 'Data Profile: IMMS 2021b - 11sd805')\n",
    "# data_profile(df_imms_2022a_hotspot_11sd805, 'Data Profile: IMMS 2022a - 11sd805')\n",
    "# data_profile(df_imms_2022b_hotspot_11sd805, 'Data Profile: IMMS 2022b - 11sd805')\n",
    "# data_profile(df_imms_2023a_hotspot_11sd805, 'Data Profile: IMMS 2023a - 11sd805')\n",
    "# data_profile(df_imms_2023b_hotspot_11sd805, 'Data Profile: IMMS 2023b - 11sd805')\n",
    "# data_profile(df_imms_2024a_hotspot_11sd805, 'Data Profile: IMMS 2024a - 11sd805')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_11sd805 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_11sd805,\n",
    "        df_imms_2022a_hotspot_11sd805,\n",
    "        df_imms_2022b_hotspot_11sd805,\n",
    "        df_imms_2023a_hotspot_11sd805,\n",
    "        df_imms_2023b_hotspot_11sd805,\n",
    "        df_imms_2024a_hotspot_11sd805,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_11sd805, 'Data Profile: IMMS Litter Hotspot - 11sd805')\n",
    "\n",
    "# create dataframe with all hotspots for analysis\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_all = pd.concat(\n",
    "    [\n",
    "        df_imms_hotspot_03sac005,\n",
    "        df_imms_hotspot_03sac050,\n",
    "        df_imms_hotspot_03sac080,\n",
    "        df_imms_hotspot_04ala580b,\n",
    "        df_imms_hotspot_04ala680,\n",
    "        df_imms_hotspot_04ala880,\n",
    "        df_imms_hotspot_04cc004a,\n",
    "        df_imms_hotspot_04cc680,\n",
    "        df_imms_hotspot_06fre099,\n",
    "        df_imms_hotspot_06ker099,\n",
    "        df_imms_hotspot_07la005a,\n",
    "        df_imms_hotspot_07la010,\n",
    "        df_imms_hotspot_07la101,\n",
    "        df_imms_hotspot_07la110,\n",
    "        df_imms_hotspot_07la405,\n",
    "        df_imms_hotspot_08riv010,\n",
    "        df_imms_hotspot_08riv060,\n",
    "        df_imms_hotspot_11sd005,\n",
    "        df_imms_hotspot_11sd805,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_all, 'Data Profile: IMMS Litter Hotspot - Total')\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_count = (\n",
    "    df_imms_hotspot_all.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_count,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Activity Count'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_sum = df_imms_hotspot_all[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_sum = (\n",
    "    df_imms_hotspot_all_activity_sum.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_sum,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Activity Sum'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_cost = df_imms_hotspot_all[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_cost = (\n",
    "    df_imms_hotspot_all_activity_cost.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_cost,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Total Cost'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (total labor)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_labor = df_imms_hotspot_all[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"P.Y.s\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_labor = (\n",
    "    df_imms_hotspot_all_activity_labor.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_labor,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Total Labor'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6d372-0911-4f25-a295-e36a8e22205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.02 - data analysis for stacked charts (imms)\n",
    "\n",
    "# concatenate all time periods to analyze frequency/CY by district\n",
    "df_imms_all_periods = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b,\n",
    "        df_imms_2022a,\n",
    "        df_imms_2022b,\n",
    "        df_imms_2023a,\n",
    "        df_imms_2023b,\n",
    "        df_imms_2024a,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(\n",
    "#     df_imms_all_periods,\n",
    "#     'Data Profile: IMMS Litter Collection - All Periods'\n",
    "# )\n",
    "# subset dataframe by district\n",
    "df_imms_all_periods_d1 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 1)\n",
    "]\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - All Periods (D1)'\n",
    "# )\n",
    "df_imms_all_periods_d2 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 2)\n",
    "]\n",
    "df_imms_all_periods_d3 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 3)\n",
    "]\n",
    "df_imms_all_periods_d4 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 4)\n",
    "]\n",
    "df_imms_all_periods_d5 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 5)\n",
    "]\n",
    "df_imms_all_periods_d6 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 6)\n",
    "]\n",
    "df_imms_all_periods_d7 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 7)\n",
    "]\n",
    "df_imms_all_periods_d8 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 8)\n",
    "]\n",
    "df_imms_all_periods_d9 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 9)\n",
    "]\n",
    "df_imms_all_periods_d10 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 10)\n",
    "]\n",
    "df_imms_all_periods_d11 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 11)\n",
    "]\n",
    "df_imms_all_periods_d12 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 12)\n",
    "]\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d1 = (\n",
    "    df_imms_all_periods_d1.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d2 = (\n",
    "    df_imms_all_periods_d2.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d3 = (\n",
    "    df_imms_all_periods_d3.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d4 = (\n",
    "    df_imms_all_periods_d4.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d5 = (\n",
    "    df_imms_all_periods_d5.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d6 = (\n",
    "    df_imms_all_periods_d6.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d7 = (\n",
    "    df_imms_all_periods_d7.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d8 = (\n",
    "    df_imms_all_periods_d8.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d9 = (\n",
    "    df_imms_all_periods_d9.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d10 = (\n",
    "    df_imms_all_periods_d10.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d11 = (\n",
    "    df_imms_all_periods_d11.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d12 = (\n",
    "    df_imms_all_periods_d12.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D1)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d2,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D2)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d3,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D3)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d4,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D4)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d5,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D5)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d6,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D6)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d7,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D7)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d8,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D8)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d9,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D9)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d10,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D10)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d11,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D11)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_count_d12,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Count (D12)'\n",
    "# )\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d1 = df_imms_all_periods_d1[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d1 = (\n",
    "    df_imms_all_periods_activity_sum_d1.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d2 = df_imms_all_periods_d2[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d2 = (\n",
    "    df_imms_all_periods_activity_sum_d2.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d3 = df_imms_all_periods_d3[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d3 = (\n",
    "    df_imms_all_periods_activity_sum_d3.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d4 = df_imms_all_periods_d4[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d4 = (\n",
    "    df_imms_all_periods_activity_sum_d4.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d5 = df_imms_all_periods_d5[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d5 = (\n",
    "    df_imms_all_periods_activity_sum_d5.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d6 = df_imms_all_periods_d6[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d6 = (\n",
    "    df_imms_all_periods_activity_sum_d6.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d7 = df_imms_all_periods_d7[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d7 = (\n",
    "    df_imms_all_periods_activity_sum_d7.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d8 = df_imms_all_periods_d8[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d8 = (\n",
    "    df_imms_all_periods_activity_sum_d8.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d9 = df_imms_all_periods_d9[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d9 = (\n",
    "    df_imms_all_periods_activity_sum_d9.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d10 = df_imms_all_periods_d10[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d10 = (\n",
    "    df_imms_all_periods_activity_sum_d10.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d11 = df_imms_all_periods_d11[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d11 = (\n",
    "    df_imms_all_periods_activity_sum_d11.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d12 = df_imms_all_periods_d12[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d12 = (\n",
    "    df_imms_all_periods_activity_sum_d12.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D1)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d2,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D2)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d3,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D3)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d4,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D4)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d5,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D5)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d6,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D6)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d7,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D7)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d8,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D8)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d9,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D9)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d10,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D10)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d11,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D11)'\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_activity_sum_d12,\n",
    "#     'Data Profile: IMMS Litter Collection - Activity Sum (D12)'\n",
    "# )\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d1 = df_imms_all_periods_d1[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d1 = (\n",
    "    df_imms_all_periods_activity_cost_d1.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d2 = df_imms_all_periods_d2[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d2 = (\n",
    "    df_imms_all_periods_activity_cost_d2.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d3 = df_imms_all_periods_d3[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d3 = (\n",
    "    df_imms_all_periods_activity_cost_d3.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d4 = df_imms_all_periods_d4[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d4 = (\n",
    "    df_imms_all_periods_activity_cost_d4.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d5 = df_imms_all_periods_d5[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d5 = (\n",
    "    df_imms_all_periods_activity_cost_d5.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d6 = df_imms_all_periods_d6[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d6 = (\n",
    "    df_imms_all_periods_activity_cost_d6.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d7 = df_imms_all_periods_d7[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d7 = (\n",
    "    df_imms_all_periods_activity_cost_d7.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d8 = df_imms_all_periods_d8[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d8 = (\n",
    "    df_imms_all_periods_activity_cost_d8.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d9 = df_imms_all_periods_d9[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d9 = (\n",
    "    df_imms_all_periods_activity_cost_d9.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d10 = df_imms_all_periods_d10[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d10 = (\n",
    "    df_imms_all_periods_activity_cost_d10.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d11 = df_imms_all_periods_d11[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d11 = (\n",
    "    df_imms_all_periods_activity_cost_d11.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d12 = df_imms_all_periods_d12[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d12 = (\n",
    "    df_imms_all_periods_activity_cost_d12.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# preview results\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d1,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D1)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d2,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D2)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d3,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D3)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d4,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D4)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d5,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D5)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d6,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D6)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d7,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D7)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d8,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D8)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d9,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D9)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d10,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D10)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d11,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D11)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d12,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D12)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad22598-be7e-4570-8db3-04c4ea3b7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.03 - data analysis (csr)\n",
    "\n",
    "# format data for plotting\n",
    "\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_csr_2023a_bar_d1 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 1]\n",
    "# df_csr_2023a_bar_d2 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 2]\n",
    "# df_csr_2023a_bar_d3 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 3]\n",
    "# df_csr_2023a_bar_d4 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 4]\n",
    "# df_csr_2023a_bar_d5 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 5]\n",
    "# df_csr_2023a_bar_d6 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 6]\n",
    "# df_csr_2023a_bar_d7 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 7]\n",
    "# df_csr_2023a_bar_d8 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 8]\n",
    "# df_csr_2023a_bar_d9 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 9]\n",
    "# df_csr_2023a_bar_d10 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 10]\n",
    "# df_csr_2023a_bar_d11 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 11]\n",
    "# df_csr_2023a_bar_d12 = df_csr_2023a[df_csr_2023a[\n",
    "#     'Responsible District'\n",
    "# ].astype(np.int) == 12]\n",
    "\n",
    "# NS, this next section was used to replace the previous section to get past an error\n",
    "df_csr_2023a_bar_d1 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 1\n",
    "]\n",
    "df_csr_2023a_bar_d2 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 2\n",
    "]\n",
    "df_csr_2023a_bar_d3 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 3\n",
    "]\n",
    "df_csr_2023a_bar_d4 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 4\n",
    "]\n",
    "df_csr_2023a_bar_d5 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 5\n",
    "]\n",
    "df_csr_2023a_bar_d6 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 6\n",
    "]\n",
    "df_csr_2023a_bar_d7 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 7\n",
    "]\n",
    "df_csr_2023a_bar_d8 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 8\n",
    "]\n",
    "df_csr_2023a_bar_d9 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 9\n",
    "]\n",
    "df_csr_2023a_bar_d10 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 10\n",
    "]\n",
    "df_csr_2023a_bar_d11 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 11\n",
    "]\n",
    "df_csr_2023a_bar_d12 = df_csr_2023a[\n",
    "    df_csr_2023a[\"Responsible District\"].astype(int) == 12\n",
    "]\n",
    "\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null date/loc values (D1) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D2) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D3) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D4) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D5) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D6) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D7) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D8) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D9) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D10) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D11) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D12) ***', '\\n')\n",
    "# print(df_csr_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# concatenate all time periods for analysis\n",
    "df_csr_all_periods = pd.concat(\n",
    "    [\n",
    "        df_csr_2021b,\n",
    "        df_csr_2022a,\n",
    "        df_csr_2022b,\n",
    "        df_csr_2023a,\n",
    "        df_csr_2023b,\n",
    "        df_csr_2024a,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "data_profile(df_csr_all_periods, \"Data Profile: CSR - All Periods\")\n",
    "\n",
    "# subset all periods by district\n",
    "df_csr_all_periods_d1 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 1)\n",
    "]\n",
    "df_csr_all_periods_d2 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 2)\n",
    "]\n",
    "df_csr_all_periods_d3 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 3)\n",
    "]\n",
    "df_csr_all_periods_d4 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 4)\n",
    "]\n",
    "df_csr_all_periods_d5 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 5)\n",
    "]\n",
    "df_csr_all_periods_d6 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 6)\n",
    "]\n",
    "df_csr_all_periods_d7 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 7)\n",
    "]\n",
    "df_csr_all_periods_d8 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 8)\n",
    "]\n",
    "df_csr_all_periods_d9 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 9)\n",
    "]\n",
    "df_csr_all_periods_d10 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 10)\n",
    "]\n",
    "df_csr_all_periods_d11 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 11)\n",
    "]\n",
    "df_csr_all_periods_d12 = df_csr_all_periods[\n",
    "    (df_csr_all_periods[\"Responsible District\"] == 12)\n",
    "]\n",
    "\n",
    "# aggregate total count based on dist/county/route\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_csr_all_periods_route_count_d1 = (\n",
    "    df_csr_all_periods_d1.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d2 = (\n",
    "    df_csr_all_periods_d2.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d3 = (\n",
    "    df_csr_all_periods_d3.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d4 = (\n",
    "    df_csr_all_periods_d4.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d5 = (\n",
    "    df_csr_all_periods_d5.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d6 = (\n",
    "    df_csr_all_periods_d6.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d7 = (\n",
    "    df_csr_all_periods_d7.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d8 = (\n",
    "    df_csr_all_periods_d8.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d9 = (\n",
    "    df_csr_all_periods_d9.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d10 = (\n",
    "    df_csr_all_periods_d10.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d11 = (\n",
    "    df_csr_all_periods_d11.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "df_csr_all_periods_route_count_d12 = (\n",
    "    df_csr_all_periods_d12.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    ")\n",
    "\n",
    "# preview results\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d1, \"Data Profile: CSR - Count by Route (D1)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d2, \"Data Profile: CSR - Count by Route (D2)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d3, \"Data Profile: CSR - Count by Route (D3)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d4, \"Data Profile: CSR - Count by Route (D4)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d5, \"Data Profile: CSR - Count by Route (D5)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d6, \"Data Profile: CSR - Count by Route (D6)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d7, \"Data Profile: CSR - Count by Route (D7)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d8, \"Data Profile: CSR - Count by Route (D8)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d9, \"Data Profile: CSR - Count by Route (D9)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d10, \"Data Profile: CSR - Count by Route (D10)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d11, \"Data Profile: CSR - Count by Route (D11)\"\n",
    ")\n",
    "data_profile(\n",
    "    df_csr_all_periods_route_count_d12, \"Data Profile: CSR - Count by Route (D12)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624014b-b9c5-4bb4-b893-386c461637e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.04 - data analysis (los)\n",
    "\n",
    "# format data for plotting\n",
    "\n",
    "# https://www.geeksforgeeks.org/select-rows-that-contain-specific-text-using-pandas/\n",
    "# df_los_2023a_bar_d1 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 1]\n",
    "# df_los_2023a_bar_d2 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 2]\n",
    "# df_los_2023a_bar_d3 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 3]\n",
    "# df_los_2023a_bar_d4 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 4]\n",
    "# df_los_2023a_bar_d5 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 5]\n",
    "# df_los_2023a_bar_d6 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 6]\n",
    "# df_los_2023a_bar_d7 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 7]\n",
    "# df_los_2023a_bar_d8 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 8]\n",
    "# df_los_2023a_bar_d9 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 9]\n",
    "# df_los_2023a_bar_d10 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 10]\n",
    "# df_los_2023a_bar_d11 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 11]\n",
    "# df_los_2023a_bar_d12 = df_los_2023a[df_los_2023a['DIST'].astype(np.int) == 12]\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null date/loc values (D1) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D2) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D3) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D4) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D5) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D6) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D7) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D8) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D9) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D10) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D11) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove null empty and loc values (D12) ***', '\\n')\n",
    "# print(df_los_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d1['Average LOS score']= df_los_2023a_d1[df_los_2023a_d1['Average LOS score'] != '#DIV/0!']\n",
    "# group los records for plot\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d1 = (\n",
    "    df_los_2023a_d1.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d1, 'Data Profile: los_avg_2023a_d1')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d2['Average LOS score']= df_los_2023a_d2[df_los_2023a_d2['Average LOS score'] != '#DIV/0!']\n",
    "# group los records for plot\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d2 = (\n",
    "    df_los_2023a_d2.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d2, 'Data Profile: los_avg_2023a_d2')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d3['Average LOS score']= df_los_2023a_d3[df_los_2023a_d3['Average LOS score'] != '#DIV/0!']\n",
    "# group los records for plot\n",
    "df_los_2023a_d3[\"Average LOS score\"] = df_los_2023a_d3[\"Average LOS score\"].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d3 = (\n",
    "    df_los_2023a_d3.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d3, 'Data Profile: los_avg_2023a_d3')\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d4, 'Data Profile: los_avg_2023a_d4')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d4['Average LOS score']= df_los_2023a_d4[df_los_2023a_d4['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_2023a_d4['Average LOS score']= df_los_2023a_d4['Average LOS score'].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d4 = (\n",
    "    df_los_2023a_d4.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d5, 'Data Profile: los_avg_2023a_d5')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d5['Average LOS score']= df_los_2023a_d5[df_los_2023a_d5['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d5[\"Average LOS score\"] = df_los_2023a_d5[\"Average LOS score\"].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d5 = (\n",
    "    df_los_2023a_d5.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d6, 'Data Profile: los_avg_2023a_d6')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d6['Average LOS score']= df_los_2023a_d6[df_los_2023a_d6['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d6[\"Average LOS score\"] = df_los_2023a_d6[\"Average LOS score\"].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d6 = (\n",
    "    df_los_2023a_d6.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d7, 'Data Profile: los_avg_2023a_d7')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d7['Average LOS score']= df_los_2023a_d7[df_los_2023a_d7['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d7[\"Average LOS score\"] = df_los_2023a_d7[\"Average LOS score\"].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d7 = (\n",
    "    df_los_2023a_d7.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d8, 'Data Profile: los_avg_2023a_d8')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d8['Average LOS score']= df_los_2023a_d8[df_los_2023a_d8['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d8[\"Average LOS score\"] = df_los_2023a_d8[\"Average LOS score\"].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d8 = (\n",
    "    df_los_2023a_d8.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d9, 'Data Profile: los_avg_2023a_d9')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d9['Average LOS score']= df_los_2023a_d9[df_los_2023a_d9['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d9[\"Average LOS score\"] = df_los_2023a_d9[\"Average LOS score\"].astype(int)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d9 = (\n",
    "    df_los_2023a_d9.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d10, 'Data Profile: los_avg_2023a_d10')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d10['Average LOS score']= df_los_2023a_d10[df_los_2023a_d10['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d10[\"Average LOS score\"] = df_los_2023a_d10[\"Average LOS score\"].astype(\n",
    "    int\n",
    ")\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d10 = (\n",
    "    df_los_2023a_d10.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d11, 'Data Profile: los_avg_2023a_d11')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d11['Average LOS score']= df_los_2023a_d11[df_los_2023a_d11['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d11[\"Average LOS score\"] = df_los_2023a_d11[\"Average LOS score\"].astype(\n",
    "    int\n",
    ")\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d11 = (\n",
    "    df_los_2023a_d11.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# view data for plot\n",
    "# data_profile(df_los_2023a_avg_d12, 'Data Profile: los_avg_2023a_d12')\n",
    "# remove nan/error values\n",
    "# df_los_2023a_d12['Average LOS score']= df_los_2023a_d12[df_los_2023a_d12['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "df_los_2023a_d12[\"Average LOS score\"] = df_los_2023a_d12[\"Average LOS score\"].astype(\n",
    "    int\n",
    ")\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_los_2023a_avg_d12 = (\n",
    "    df_los_2023a_d12.groupby([\"CO\", \"RTE\"])[\"Average LOS score\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"Average LOS score\")\n",
    ")\n",
    "\n",
    "# convert county to string for county/route column\n",
    "convert_str(df_los_all_d1, \"RTE\")\n",
    "convert_str(df_los_all_d2, \"RTE\")\n",
    "convert_str(df_los_all_d3, \"RTE\")\n",
    "convert_str(df_los_all_d4, \"RTE\")\n",
    "convert_str(df_los_all_d5, \"RTE\")\n",
    "convert_str(df_los_all_d6, \"RTE\")\n",
    "convert_str(df_los_all_d7, \"RTE\")\n",
    "convert_str(df_los_all_d8, \"RTE\")\n",
    "convert_str(df_los_all_d9, \"RTE\")\n",
    "convert_str(df_los_all_d10, \"RTE\")\n",
    "convert_str(df_los_all_d11, \"RTE\")\n",
    "convert_str(df_los_all_d12, \"RTE\")\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d1 = df_los_all_d1[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d1[\"co_rte\"] = df_los_all_d1[\"CO\"] + \"-\" + df_los_all_d1[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d2 = df_los_all_d2[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d2[\"co_rte\"] = df_los_all_d2[\"CO\"] + \"-\" + df_los_all_d2[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d3 = df_los_all_d3[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d3[\"co_rte\"] = df_los_all_d3[\"CO\"] + \"-\" + df_los_all_d3[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d4 = df_los_all_d4[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d4[\"co_rte\"] = df_los_all_d4[\"CO\"] + \"-\" + df_los_all_d4[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d5 = df_los_all_d5[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d5[\"co_rte\"] = df_los_all_d5[\"CO\"] + \"-\" + df_los_all_d5[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d6 = df_los_all_d6[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d6[\"co_rte\"] = df_los_all_d6[\"CO\"] + \"-\" + df_los_all_d6[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d7 = df_los_all_d7[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d7[\"co_rte\"] = df_los_all_d7[\"CO\"] + \"-\" + df_los_all_d7[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d8 = df_los_all_d8[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d8[\"co_rte\"] = df_los_all_d8[\"CO\"] + \"-\" + df_los_all_d8[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d9 = df_los_all_d9[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d9[\"co_rte\"] = df_los_all_d9[\"CO\"] + \"-\" + df_los_all_d9[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d10 = df_los_all_d10[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d10[\"co_rte\"] = df_los_all_d10[\"CO\"] + \"-\" + df_los_all_d10[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d11 = df_los_all_d11[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d11[\"co_rte\"] = df_los_all_d11[\"CO\"] + \"-\" + df_los_all_d11[\"RTE\"]\n",
    "\n",
    "# subset data for only county/route and los scores\n",
    "df_los_all_d12 = df_los_all_d12[\n",
    "    [\n",
    "        \"CO\",\n",
    "        \"RTE\",\n",
    "        \"los_2022_q1\",\n",
    "        \"los_2022_q2\",\n",
    "        \"los_2022_q3\",\n",
    "        \"los_2022_q4\",\n",
    "        \"los_2023_q1\",\n",
    "        \"los_2023_q2\",\n",
    "        \"los_2023_q3\",\n",
    "        \"los_2023_q4\",\n",
    "        \"los_2024_q1\",\n",
    "        \"los_2024_q2\",\n",
    "        \"los_2024_q3\",\n",
    "        \"los_2024_q4\",\n",
    "    ]\n",
    "]\n",
    "# add county/route column\n",
    "df_los_all_d12[\"co_rte\"] = df_los_all_d12[\"CO\"] + \"-\" + df_los_all_d12[\"RTE\"]\n",
    "\n",
    "# remove rows with nan as los score\n",
    "# https://stackoverflow.com/questions/13413590/how-to-drop-rows-of-pandas-dataframe-whose-value-in-a-certain-column-is-nan\n",
    "df_los_all_d1.dropna(inplace=True)\n",
    "df_los_all_d2.dropna(inplace=True)\n",
    "df_los_all_d3.dropna(inplace=True)\n",
    "df_los_all_d4.dropna(inplace=True)\n",
    "df_los_all_d5.dropna(inplace=True)\n",
    "df_los_all_d6.dropna(inplace=True)\n",
    "df_los_all_d7.dropna(inplace=True)\n",
    "df_los_all_d8.dropna(inplace=True)\n",
    "df_los_all_d9.dropna(inplace=True)\n",
    "df_los_all_d10.dropna(inplace=True)\n",
    "df_los_all_d11.dropna(inplace=True)\n",
    "df_los_all_d12.dropna(inplace=True)\n",
    "# preview data\n",
    "# print(df_los_all_d1)\n",
    "\n",
    "# group route segments by count to create stacked bar chart\n",
    "df_los_all_count_d1 = df_los_all_d1.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d2 = df_los_all_d2.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d3 = df_los_all_d3.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d4 = df_los_all_d4.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d5 = df_los_all_d5.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d6 = df_los_all_d6.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d7 = df_los_all_d7.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d8 = df_los_all_d8.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d9 = df_los_all_d9.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d10 = df_los_all_d10.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d11 = df_los_all_d11.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "df_los_all_count_d12 = df_los_all_d12.groupby([\"CO\", \"RTE\"]).size().unstack(\"RTE\")\n",
    "\n",
    "# convert quarterly columns into row values\n",
    "# https://pandas.pydata.org/pandas-docs/version/1.0.0/reference/api/pandas.DataFrame.melt.html\n",
    "# df_los_all_d1.melt(id_vars=[\n",
    "#     'CO',\n",
    "#     'RTE'\n",
    "# ], value_vars=[\n",
    "#     'los_2022_q1',\n",
    "#     'los_2022_q2',\n",
    "#     'los_2022_q3',\n",
    "#     'los_2022_q4',\n",
    "#     'los_2023_q1',\n",
    "#     'los_2023_q2',\n",
    "#     'los_2023_q3',\n",
    "#     'los_2023_q4',\n",
    "#     'los_2024_q1',\n",
    "#     'los_2024_q2',\n",
    "#     'los_2024_q3',\n",
    "#     'los_2024_q4'\n",
    "# ])\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_d1, 'Data Profile: los_all_d1')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d1['Average LOS score']= df_los_all_d1[df_los_all_d1['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d1['los_2022_q1']= df_los_all_d1['los_2022_q1'].astype(int)\n",
    "# df_los_all_d1['los_2022_q2']= df_los_all_d1['los_2022_q2'].astype(int)\n",
    "# df_los_all_d1['los_2022_q3']= df_los_all_d1['los_2022_q3'].astype(int)\n",
    "# df_los_all_d1['los_2022_q4']= df_los_all_d1['los_2022_q4'].astype(int)\n",
    "# df_los_all_d1['los_2023_q1']= df_los_all_d1['los_2023_q1'].astype(int)\n",
    "# df_los_all_d1['los_2023_q2']= df_los_all_d1['los_2023_q2'].astype(int)\n",
    "# df_los_all_d1['los_2023_q3']= df_los_all_d1['los_2023_q3'].astype(int)\n",
    "# df_los_all_d1['los_2023_q4']= df_los_all_d1['los_2023_q4'].astype(int)\n",
    "# df_los_all_d1['los_2024_q1']= df_los_all_d1['los_2024_q1'].astype(int)\n",
    "# df_los_all_d1['los_2024_q2']= df_los_all_d1['los_2024_q2'].astype(int)\n",
    "# df_los_all_d1['los_2024_q3']= df_los_all_d1['los_2024_q3'].astype(int)\n",
    "# df_los_all_d1['los_2024_q4']= df_los_all_d1['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d1[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d1[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d1[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d1 = df_los_all_d1.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d1, 'Data Profile: los_avg_all_d1')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d2['Average LOS score']= df_los_all_d2[df_los_all_d2['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d2['los_2022_q1']= df_los_all_d2['los_2022_q1'].astype(int)\n",
    "# df_los_all_d2['los_2022_q2']= df_los_all_d2['los_2022_q2'].astype(int)\n",
    "# df_los_all_d2['los_2022_q3']= df_los_all_d2['los_2022_q3'].astype(int)\n",
    "# df_los_all_d2['los_2022_q4']= df_los_all_d2['los_2022_q4'].astype(int)\n",
    "# df_los_all_d2['los_2023_q1']= df_los_all_d2['los_2023_q1'].astype(int)\n",
    "# df_los_all_d2['los_2023_q2']= df_los_all_d2['los_2023_q2'].astype(int)\n",
    "# df_los_all_d2['los_2023_q3']= df_los_all_d2['los_2023_q3'].astype(int)\n",
    "# df_los_all_d2['los_2023_q4']= df_los_all_d2['los_2023_q4'].astype(int)\n",
    "# df_los_all_d2['los_2024_q1']= df_los_all_d2['los_2024_q1'].astype(int)\n",
    "# df_los_all_d2['los_2024_q2']= df_los_all_d2['los_2024_q2'].astype(int)\n",
    "# df_los_all_d2['los_2024_q3']= df_los_all_d2['los_2024_q3'].astype(int)\n",
    "# df_los_all_d2['los_2024_q4']= df_los_all_d2['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d2[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d2[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d2[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d2 = df_los_all_d2.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d2, 'Data Profile: los_avg_all_d2')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d3['Average LOS score']= df_los_all_d3[df_los_all_d3['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d3['los_2022_q1']= df_los_all_d3['los_2022_q1'].astype(int)\n",
    "# df_los_all_d3['los_2022_q2']= df_los_all_d3['los_2022_q2'].astype(int)\n",
    "# df_los_all_d3['los_2022_q3']= df_los_all_d3['los_2022_q3'].astype(int)\n",
    "# df_los_all_d3['los_2022_q4']= df_los_all_d3['los_2022_q4'].astype(int)\n",
    "# df_los_all_d3['los_2023_q1']= df_los_all_d3['los_2023_q1'].astype(int)\n",
    "# df_los_all_d3['los_2023_q2']= df_los_all_d3['los_2023_q2'].astype(int)\n",
    "# df_los_all_d3['los_2023_q3']= df_los_all_d3['los_2023_q3'].astype(int)\n",
    "# df_los_all_d3['los_2023_q4']= df_los_all_d3['los_2023_q4'].astype(int)\n",
    "# df_los_all_d3['los_2024_q1']= df_los_all_d3['los_2024_q1'].astype(int)\n",
    "# df_los_all_d3['los_2024_q2']= df_los_all_d3['los_2024_q2'].astype(int)\n",
    "# df_los_all_d3['los_2024_q3']= df_los_all_d3['los_2024_q3'].astype(int)\n",
    "# df_los_all_d3['los_2024_q4']= df_los_all_d3['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d3[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d3[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d3[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d3 = df_los_all_d3.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d3, 'Data Profile: los_avg_all_d3')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d4['Average LOS score']= df_los_all_d4[df_los_all_d4['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d4['los_2022_q1']= df_los_all_d4['los_2022_q1'].astype(int)\n",
    "# df_los_all_d4['los_2022_q2']= df_los_all_d4['los_2022_q2'].astype(int)\n",
    "# df_los_all_d4['los_2022_q3']= df_los_all_d4['los_2022_q3'].astype(int)\n",
    "# df_los_all_d4['los_2022_q4']= df_los_all_d4['los_2022_q4'].astype(int)\n",
    "# df_los_all_d4['los_2023_q1']= df_los_all_d4['los_2023_q1'].astype(int)\n",
    "# df_los_all_d4['los_2023_q2']= df_los_all_d4['los_2023_q2'].astype(int)\n",
    "# df_los_all_d4['los_2023_q3']= df_los_all_d4['los_2023_q3'].astype(int)\n",
    "# df_los_all_d4['los_2023_q4']= df_los_all_d4['los_2023_q4'].astype(int)\n",
    "# df_los_all_d4['los_2024_q1']= df_los_all_d4['los_2024_q1'].astype(int)\n",
    "# df_los_all_d4['los_2024_q2']= df_los_all_d4['los_2024_q2'].astype(int)\n",
    "# df_los_all_d4['los_2024_q3']= df_los_all_d4['los_2024_q3'].astype(int)\n",
    "# df_los_all_d4['los_2024_q4']= df_los_all_d4['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d4[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d4[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d4[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d4 = df_los_all_d4.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d4, 'Data Profile: los_avg_all_d4')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d5['Average LOS score']= df_los_all_d5[df_los_all_d5['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d5['los_2022_q1']= df_los_all_d5['los_2022_q1'].astype(int)\n",
    "# df_los_all_d5['los_2022_q2']= df_los_all_d5['los_2022_q2'].astype(int)\n",
    "# df_los_all_d5['los_2022_q3']= df_los_all_d5['los_2022_q3'].astype(int)\n",
    "# df_los_all_d5['los_2022_q4']= df_los_all_d5['los_2022_q4'].astype(int)\n",
    "# df_los_all_d5['los_2023_q1']= df_los_all_d5['los_2023_q1'].astype(int)\n",
    "# df_los_all_d5['los_2023_q2']= df_los_all_d5['los_2023_q2'].astype(int)\n",
    "# df_los_all_d5['los_2023_q3']= df_los_all_d5['los_2023_q3'].astype(int)\n",
    "# df_los_all_d5['los_2023_q4']= df_los_all_d5['los_2023_q4'].astype(int)\n",
    "# df_los_all_d5['los_2024_q1']= df_los_all_d5['los_2024_q1'].astype(int)\n",
    "# df_los_all_d5['los_2024_q2']= df_los_all_d5['los_2024_q2'].astype(int)\n",
    "# df_los_all_d5['los_2024_q3']= df_los_all_d5['los_2024_q3'].astype(int)\n",
    "# df_los_all_d5['los_2024_q4']= df_los_all_d5['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d5[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d5[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d5[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d5 = df_los_all_d5.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d5, 'Data Profile: los_avg_all_d5')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d6['Average LOS score']= df_los_all_d6[df_los_all_d6['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d6['los_2022_q1']= df_los_all_d6['los_2022_q1'].astype(int)\n",
    "# df_los_all_d6['los_2022_q2']= df_los_all_d6['los_2022_q2'].astype(int)\n",
    "# df_los_all_d6['los_2022_q3']= df_los_all_d6['los_2022_q3'].astype(int)\n",
    "# df_los_all_d6['los_2022_q4']= df_los_all_d6['los_2022_q4'].astype(int)\n",
    "# df_los_all_d6['los_2023_q1']= df_los_all_d6['los_2023_q1'].astype(int)\n",
    "# df_los_all_d6['los_2023_q2']= df_los_all_d6['los_2023_q2'].astype(int)\n",
    "# df_los_all_d6['los_2023_q3']= df_los_all_d6['los_2023_q3'].astype(int)\n",
    "# df_los_all_d6['los_2023_q4']= df_los_all_d6['los_2023_q4'].astype(int)\n",
    "# df_los_all_d6['los_2024_q1']= df_los_all_d6['los_2024_q1'].astype(int)\n",
    "# df_los_all_d6['los_2024_q2']= df_los_all_d6['los_2024_q2'].astype(int)\n",
    "# df_los_all_d6['los_2024_q3']= df_los_all_d6['los_2024_q3'].astype(int)\n",
    "# df_los_all_d6['los_2024_q4']= df_los_all_d6['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d6[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d6[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d6[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d6 = df_los_all_d6.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d6, 'Data Profile: los_avg_all_d6')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d7['Average LOS score']= df_los_all_d7[df_los_all_d7['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d7['los_2022_q1']= df_los_all_d7['los_2022_q1'].astype(int)\n",
    "# df_los_all_d7['los_2022_q2']= df_los_all_d7['los_2022_q2'].astype(int)\n",
    "# df_los_all_d7['los_2022_q3']= df_los_all_d7['los_2022_q3'].astype(int)\n",
    "# df_los_all_d7['los_2022_q4']= df_los_all_d7['los_2022_q4'].astype(int)\n",
    "# df_los_all_d7['los_2023_q1']= df_los_all_d7['los_2023_q1'].astype(int)\n",
    "# df_los_all_d7['los_2023_q2']= df_los_all_d7['los_2023_q2'].astype(int)\n",
    "# df_los_all_d7['los_2023_q3']= df_los_all_d7['los_2023_q3'].astype(int)\n",
    "# df_los_all_d7['los_2023_q4']= df_los_all_d7['los_2023_q4'].astype(int)\n",
    "# df_los_all_d7['los_2024_q1']= df_los_all_d7['los_2024_q1'].astype(int)\n",
    "# df_los_all_d7['los_2024_q2']= df_los_all_d7['los_2024_q2'].astype(int)\n",
    "# df_los_all_d7['los_2024_q3']= df_los_all_d7['los_2024_q3'].astype(int)\n",
    "# df_los_all_d7['los_2024_q4']= df_los_all_d7['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d7[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d7[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d7[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d7 = df_los_all_d7.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d7, 'Data Profile: los_avg_all_d7')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d8['Average LOS score']= df_los_all_d8[df_los_all_d8['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d8['los_2022_q1']= df_los_all_d8['los_2022_q1'].astype(int)\n",
    "# df_los_all_d8['los_2022_q2']= df_los_all_d8['los_2022_q2'].astype(int)\n",
    "# df_los_all_d8['los_2022_q3']= df_los_all_d8['los_2022_q3'].astype(int)\n",
    "# df_los_all_d8['los_2022_q4']= df_los_all_d8['los_2022_q4'].astype(int)\n",
    "# df_los_all_d8['los_2023_q1']= df_los_all_d8['los_2023_q1'].astype(int)\n",
    "# df_los_all_d8['los_2023_q2']= df_los_all_d8['los_2023_q2'].astype(int)\n",
    "# df_los_all_d8['los_2023_q3']= df_los_all_d8['los_2023_q3'].astype(int)\n",
    "# df_los_all_d8['los_2023_q4']= df_los_all_d8['los_2023_q4'].astype(int)\n",
    "# df_los_all_d8['los_2024_q1']= df_los_all_d8['los_2024_q1'].astype(int)\n",
    "# df_los_all_d8['los_2024_q2']= df_los_all_d8['los_2024_q2'].astype(int)\n",
    "# df_los_all_d8['los_2024_q3']= df_los_all_d8['los_2024_q3'].astype(int)\n",
    "# df_los_all_d8['los_2024_q4']= df_los_all_d8['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d8[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d8[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d8[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d8 = df_los_all_d8.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d8, 'Data Profile: los_avg_all_d8')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d9['Average LOS score']= df_los_all_d9[df_los_all_d9['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d9['los_2022_q1']= df_los_all_d9['los_2022_q1'].astype(int)\n",
    "# df_los_all_d9['los_2022_q2']= df_los_all_d9['los_2022_q2'].astype(int)\n",
    "# df_los_all_d9['los_2022_q3']= df_los_all_d9['los_2022_q3'].astype(int)\n",
    "# df_los_all_d9['los_2022_q4']= df_los_all_d9['los_2022_q4'].astype(int)\n",
    "# df_los_all_d9['los_2023_q1']= df_los_all_d9['los_2023_q1'].astype(int)\n",
    "# df_los_all_d9['los_2023_q2']= df_los_all_d9['los_2023_q2'].astype(int)\n",
    "# df_los_all_d9['los_2023_q3']= df_los_all_d9['los_2023_q3'].astype(int)\n",
    "# df_los_all_d9['los_2023_q4']= df_los_all_d9['los_2023_q4'].astype(int)\n",
    "# df_los_all_d9['los_2024_q1']= df_los_all_d9['los_2024_q1'].astype(int)\n",
    "# df_los_all_d9['los_2024_q2']= df_los_all_d9['los_2024_q2'].astype(int)\n",
    "# df_los_all_d9['los_2024_q3']= df_los_all_d9['los_2024_q3'].astype(int)\n",
    "# df_los_all_d9['los_2024_q4']= df_los_all_d9['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d9[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d9[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d9[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d9 = df_los_all_d9.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d9, 'Data Profile: los_avg_all_d9')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d10['Average LOS score']= df_los_all_d10[df_los_all_d10['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d10['los_2022_q1']= df_los_all_d10['los_2022_q1'].astype(int)\n",
    "# df_los_all_d10['los_2022_q2']= df_los_all_d10['los_2022_q2'].astype(int)\n",
    "# df_los_all_d10['los_2022_q3']= df_los_all_d10['los_2022_q3'].astype(int)\n",
    "# df_los_all_d10['los_2022_q4']= df_los_all_d10['los_2022_q4'].astype(int)\n",
    "# df_los_all_d10['los_2023_q1']= df_los_all_d10['los_2023_q1'].astype(int)\n",
    "# df_los_all_d10['los_2023_q2']= df_los_all_d10['los_2023_q2'].astype(int)\n",
    "# df_los_all_d10['los_2023_q3']= df_los_all_d10['los_2023_q3'].astype(int)\n",
    "# df_los_all_d10['los_2023_q4']= df_los_all_d10['los_2023_q4'].astype(int)\n",
    "# df_los_all_d10['los_2024_q1']= df_los_all_d10['los_2024_q1'].astype(int)\n",
    "# df_los_all_d10['los_2024_q2']= df_los_all_d10['los_2024_q2'].astype(int)\n",
    "# df_los_all_d10['los_2024_q3']= df_los_all_d10['los_2024_q3'].astype(int)\n",
    "# df_los_all_d10['los_2024_q4']= df_los_all_d10['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d10[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d10[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d10[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d10 = df_los_all_d10.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d10, 'Data Profile: los_avg_all_d10')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d11['Average LOS score']= df_los_all_d11[df_los_all_d11['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d11['los_2022_q1']= df_los_all_d11['los_2022_q1'].astype(int)\n",
    "# df_los_all_d11['los_2022_q2']= df_los_all_d11['los_2022_q2'].astype(int)\n",
    "# df_los_all_d11['los_2022_q3']= df_los_all_d11['los_2022_q3'].astype(int)\n",
    "# df_los_all_d11['los_2022_q4']= df_los_all_d11['los_2022_q4'].astype(int)\n",
    "# df_los_all_d11['los_2023_q1']= df_los_all_d11['los_2023_q1'].astype(int)\n",
    "# df_los_all_d11['los_2023_q2']= df_los_all_d11['los_2023_q2'].astype(int)\n",
    "# df_los_all_d11['los_2023_q3']= df_los_all_d11['los_2023_q3'].astype(int)\n",
    "# df_los_all_d11['los_2023_q4']= df_los_all_d11['los_2023_q4'].astype(int)\n",
    "# df_los_all_d11['los_2024_q1']= df_los_all_d11['los_2024_q1'].astype(int)\n",
    "# df_los_all_d11['los_2024_q2']= df_los_all_d11['los_2024_q2'].astype(int)\n",
    "# df_los_all_d11['los_2024_q3']= df_los_all_d11['los_2024_q3'].astype(int)\n",
    "# df_los_all_d11['los_2024_q4']= df_los_all_d11['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d11[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d11[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d11[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d11 = df_los_all_d11.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d11, 'Data Profile: los_avg_all_d11')\n",
    "\n",
    "# remove nan/error values\n",
    "# df_los_all_d12['Average LOS score']= df_los_all_d12[df_los_all_d12['Average LOS score'] != '#DIV/0!']\n",
    "# convert column to int data type\n",
    "# df_los_all_d12['los_2022_q1']= df_los_all_d12['los_2022_q1'].astype(int)\n",
    "# df_los_all_d12['los_2022_q2']= df_los_all_d12['los_2022_q2'].astype(int)\n",
    "# df_los_all_d12['los_2022_q3']= df_los_all_d12['los_2022_q3'].astype(int)\n",
    "# df_los_all_d12['los_2022_q4']= df_los_all_d12['los_2022_q4'].astype(int)\n",
    "# df_los_all_d12['los_2023_q1']= df_los_all_d12['los_2023_q1'].astype(int)\n",
    "# df_los_all_d12['los_2023_q2']= df_los_all_d12['los_2023_q2'].astype(int)\n",
    "# df_los_all_d12['los_2023_q3']= df_los_all_d12['los_2023_q3'].astype(int)\n",
    "# df_los_all_d12['los_2023_q4']= df_los_all_d12['los_2023_q4'].astype(int)\n",
    "# df_los_all_d12['los_2024_q1']= df_los_all_d12['los_2024_q1'].astype(int)\n",
    "# df_los_all_d12['los_2024_q2']= df_los_all_d12['los_2024_q2'].astype(int)\n",
    "# df_los_all_d12['los_2024_q3']= df_los_all_d12['los_2024_q3'].astype(int)\n",
    "# df_los_all_d12['los_2024_q4']= df_los_all_d12['los_2024_q4'].astype(int)\n",
    "# convert scores to numeric\n",
    "df_los_all_d12[\"los_2022_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2022_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2022_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2022_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2022_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2022_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2022_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2022_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2023_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2023_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2023_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2023_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2023_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2023_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2023_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2023_q4\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2024_q1\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2024_q1\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2024_q2\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2024_q2\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2024_q3\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2024_q3\"], errors=\"coerce\"\n",
    ")\n",
    "df_los_all_d12[\"los_2024_q4\"] = pd.to_numeric(\n",
    "    df_los_all_d12[\"los_2024_q4\"], errors=\"coerce\"\n",
    ")\n",
    "# group los records for plot\n",
    "# group by county/route, then calculate average los for each quarter\n",
    "# https://stackoverflow.com/questions/49560809/pandas-return-average-of-multiple-columns\n",
    "df_los_all_avg_d12 = df_los_all_d12.groupby([\"co_rte\"]).agg(\n",
    "    {\n",
    "        \"los_2022_q1\": \"mean\",\n",
    "        \"los_2022_q2\": \"mean\",\n",
    "        \"los_2022_q3\": \"mean\",\n",
    "        \"los_2022_q4\": \"mean\",\n",
    "        \"los_2023_q1\": \"mean\",\n",
    "        \"los_2023_q2\": \"mean\",\n",
    "        \"los_2023_q3\": \"mean\",\n",
    "        \"los_2023_q4\": \"mean\",\n",
    "        \"los_2024_q1\": \"mean\",\n",
    "        \"los_2024_q2\": \"mean\",\n",
    "        \"los_2024_q3\": \"mean\",\n",
    "        \"los_2024_q4\": \"mean\",\n",
    "    }\n",
    ")\n",
    "# view data for plot\n",
    "# data_profile(df_los_all_avg_d12, 'Data Profile: los_avg_all_d12')\n",
    "\n",
    "\n",
    "# Commented out by NS April 2025\n",
    "# # export final csv file\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d1,\n",
    "#     'data/05.02.04_los_all_avg_d1.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d2,\n",
    "#     'data/05.02.04_los_all_avg_d2.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d3,\n",
    "#     'data/05.02.04_los_all_avg_d3.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d4,\n",
    "#     'data/05.02.04_los_all_avg_d4.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d5,\n",
    "#     'data/05.02.04_los_all_avg_d5.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d6,\n",
    "#     'data/05.02.04_los_all_avg_d6.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d7,\n",
    "#     'data/05.02.04_los_all_avg_d7.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d8,\n",
    "#     'data/05.02.04_los_all_avg_d8.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d9,\n",
    "#     'data/05.02.04_los_all_avg_d9.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d10,\n",
    "#     'data/05.02.04_los_all_avg_d10.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d11,\n",
    "#     'data/05.02.04_los_all_avg_d11.csv'\n",
    "# )\n",
    "# write_data_csv(\n",
    "#     df_los_all_avg_d12,\n",
    "#     'data/05.02.04_los_all_avg_d12.csv'\n",
    "# )\n",
    "\n",
    "\n",
    "# export final csv file\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d1, f\"{data_output_folder}/05.02.04_los_all_avg_d1.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d2, f\"{data_output_folder}/05.02.04_los_all_avg_d2.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d3, f\"{data_output_folder}/05.02.04_los_all_avg_d3.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d4, f\"{data_output_folder}/05.02.04_los_all_avg_d4.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d5, f\"{data_output_folder}/05.02.04_los_all_avg_d5.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d6, f\"{data_output_folder}/05.02.04_los_all_avg_d6.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d7, f\"{data_output_folder}/05.02.04_los_all_avg_d7.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d8, f\"{data_output_folder}/05.02.04_los_all_avg_d8.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d9, f\"{data_output_folder}/05.02.04_los_all_avg_d9.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d10, f\"{data_output_folder}/05.02.04_los_all_avg_d10.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d11, f\"{data_output_folder}/05.02.04_los_all_avg_d11.csv\"\n",
    ")\n",
    "write_scd_data_csv(\n",
    "    df_los_all_avg_d12, f\"{data_output_folder}/05.02.04_los_all_avg_d12.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdf594-516a-431c-8fc0-fcf3d2f5f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.03 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_03sac005,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3f9aa-92f6-4e77-b512-b12bb664ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.03 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_03sac050,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769e4f7-b3c0-456b-93f4-d85fe193ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.03 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_03sac080,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3dc6f4-4cf4-4fa2-a7c4-09d569569b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04ala580b,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656fde1-a04c-4f56-ac37-e77d84930703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04ala680,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3af3c4-f071-4044-875a-f2fbd7d3d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04ala880,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2c237-0588-4431-8354-e64e29a5760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04cc004a,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d757d28-7d56-434d-b6ba-186eed866244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.04 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_04cc680,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f8fd0-90f1-419b-8fc7-ec788e6adaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.06 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_06fre099,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8bb382-986b-4d49-b68f-cf6fa71acdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.06 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_06ker099,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98f4bf-1e2d-45c4-9600-a2ac82c0f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la005a,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd720b-2353-4ee8-be42-f4e08df539d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la010,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bbcc5-8af7-49c6-a8f2-ff5f5173e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la101,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb018c-94da-4930-9907-641808aae377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la110,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784aa06-971f-4f1a-8d5d-ca13fe0e00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.07 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_07la405,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d67a5-d1bf-42f8-af1e-51fe54ba33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.08 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_08riv010,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0630689-f442-4515-bc39-8b0b6cb69400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.08 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_08riv060,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9f1de-73d3-4d08-8e1b-029719485016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.11 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_11sd005,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ce0bb-1c6d-4d7a-9b55-f2b16a51bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.06.11 - plot corridor litter totals by postmile\n",
    "\n",
    "# https://stackoverflow.com/questions/31594549/how-to-change-the-figure-size-of-a-seaborn-axes-or-figure-level-plot\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "sns.scatterplot(\n",
    "    data=df_imms_hotspot_11sd805,\n",
    "    x=\"Production Quantity\",\n",
    "    y=\"From Miles\",\n",
    "    hue=\"Activity Description\",\n",
    "    style=\"Activity Description\",\n",
    "    palette=\"deep\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121b7a8-a96d-434d-adfc-9bff1dd82f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.01 - plot work activty counts by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_count.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c33a8-334b-4877-9b6d-60f972d28b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.01 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcaafb-d6b1-4fca-9ad5-ef31b48811b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.02 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3a193-196e-4f3f-8c97-9f48e6e87858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.03 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a658e6-19b7-4d7f-98c6-c427c197d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.04 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (25, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd9a50-c91e-4a53-854f-e9e1c017dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.05 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3339689-7592-44f5-9423-802fb19fce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.06 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33300e10-cc0e-4088-8450-e2a84b93f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.07 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (25, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4ca76-a499-43db-abe1-101400ad5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.08 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820dab5-f5e0-4704-97a0-0285ce814818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.09 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbd0da-9808-4f04-8842-22c24fa094d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.10 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e5eb1-023b-41bc-9821-062078d5e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.11 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea829b71-c6dc-4755-bac5-c1a391c0ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.12 - plot work activity counts by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_count_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e78e6-d718-44de-972f-0257a2948d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.07.13 - plot work activity counts by litter hotspot\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_count.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf46ad-4e2a-4528-8cc3-5117a18f138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.01 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d84b48-2a17-4a7a-9cc8-1cd8c3dcaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.02 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30547a16-04b3-4780-b70a-81493222604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.03 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883140d9-9efc-4314-aa22-3505079ea7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.04 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (25, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062559e2-6eb0-4eb2-a126-b79ab57d02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.05 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ced62-36f9-405e-8c12-e3a2e41ccaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.06 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10730386-881d-400e-aec4-7bb5135bcfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.07 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e2c1f-200d-4bdf-b1c1-5d91e187d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.08 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece83f7-28ac-4fe2-82c1-bd883306fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.09 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a9f2a-5874-42a0-a453-ca8bc99d492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.10 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509523e8-aa94-4c28-81d2-6be9dccb1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.11 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e3a33-d68b-4370-b430-d71dc4eb395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.12 - plot work activity totals by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_sum_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581b54e-4c67-4ffb-9f46-096568e499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.13 - plot work activity totals by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_sum.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6fb67-dc0b-465b-946f-54209ef4047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.01 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef3002-1fae-4ef7-a472-4f3e6f2ae240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.02 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43458d05-9f47-4604-90b0-81dfb92c190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.03 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e605e-6ce6-4326-ae9a-af5ce5a966d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.04 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (25, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4ee08-6a28-403f-9422-683e3d2b3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.05 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df807f13-c668-4ac7-99a8-ad5368224e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.06 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50396e2d-c5ba-4050-a1e3-698e7f779894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.07 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb8380-905d-4977-a436-93d23e547880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.08 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a78cf4-b418-4f24-ae7f-852a195a10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.09 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76ecda-8378-47e4-911b-ed78e43bbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.10 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7afdf3-3713-4be5-9b42-edda52f4e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.11 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743ea77-48fb-49e6-9560-f40e8a343e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.12 - plot work activity cost by district\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_all_periods_activity_cost_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14634303-cc73-4bf6-9834-bee40ae42469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.13 - plot work activity cost by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_cost.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c97f1-9d3b-4d18-9905-7d7b445ef1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.14 - plot work total labor by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_labor.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af66c0-3170-4dc9-a7f7-03ffc73307eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.01 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c44b7-d1a4-471c-a987-21de0e1ee3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.02 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8c865-6bd4-4757-b57c-b61e8f2223b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.03 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f13d26-60d1-4128-b461-51316b8895e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.04 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 15)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ea803-f9e3-4ff3-aeed-a5616857f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.05 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97243986-bb5f-49fd-8a3b-95fb67d190db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.06 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696ee3c-bcff-4315-b96f-e43713372d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.07 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 15)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932b97c-981d-4a4a-9254-a4f7796c3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.08 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab885b12-afcd-4913-87fb-7975c251fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.09 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80756d7-a2e7-4514-bdd5-0212730f442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.10 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905e611-3904-4e9d-bb8e-30040912655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.11 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8cfc2-a5f4-427f-b0c2-aae61b16bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.10.12 - plot csr counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_csr_all_periods_route_count_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecf7e6-bde3-435d-83e3-d982b04b756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.01 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d1.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4d169-168e-47e1-a936-cd2680bacdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.02 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2be8a-73f7-44dc-a6bf-bcaa063cc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.03 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d3.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5e022-8aa3-4a43-af4c-5d5001e86721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.04 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d4.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f56988-a36a-47ec-8f9c-030fde73c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.05 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d5.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf36648-c3fb-422a-bdcb-0e029c7681b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.06 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d6.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02baef08-d059-4ab4-a43e-817195e267cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.07 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d7.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744820e-d942-4de3-a1e4-146172c549fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.08 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d8.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b8a48-c18e-47f9-9be4-1d5c5f4cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.09 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d9.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa111e-c3c2-4147-822c-7a448af26edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.10 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d10.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df076b8d-53ca-4311-b1f4-f42d0bc9ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.11 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d11.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c7504-eb25-4a52-8fe3-7803ba4c5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.11.12 - plot lost counts by dist/county/route\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on csr count\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_los_all_count_d12.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a10162-c302-484c-bcb6-969b21704f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualizations_to_pdf(df1, df2, df3, filename=\"work_activity_visuals.pdf\"):\n",
    "    \"\"\"\n",
    "    Create three stacked bar plots from input DataFrames and save them into a single PDF.\n",
    "\n",
    "    Parameters:\n",
    "        df1 (pd.DataFrame): Data for total work activity\n",
    "        df2 (pd.DataFrame): Data for labor totals\n",
    "        df3 (pd.DataFrame): Data for cost breakdown\n",
    "        filename (str): Output PDF filename\n",
    "    \"\"\"\n",
    "    sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "\n",
    "    with PdfPages(filename) as pdf:\n",
    "        # Visualization 1\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        df1.plot.bar(stacked=True, ax=ax1)\n",
    "        ax1.set_title(\"Total Work Activity by Hotspot Corridors\")\n",
    "        ax1.set_ylabel(\"Work Activity Total\")\n",
    "        ax1.set_xlabel(\"Hotspot Corridors\")\n",
    "        pdf.savefig(fig1)\n",
    "        plt.close(fig1)\n",
    "\n",
    "        # Visualization 2\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        df2.plot.bar(stacked=True, ax=ax2)\n",
    "        ax2.set_title(\"Labor Totals by Hotspot Corridors\")\n",
    "        ax2.set_ylabel(\"Total Labor Cost\")\n",
    "        ax2.set_xlabel(\"Hotspot Corridors\")\n",
    "        pdf.savefig(fig2)\n",
    "        plt.close(fig2)\n",
    "\n",
    "        # Visualization 3\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        df3.plot.bar(stacked=True, ax=ax3)\n",
    "        ax3.set_title(\"Work Activity Cost by Hotspot Corridors\")\n",
    "        ax3.set_ylabel(\"Activity Cost\")\n",
    "        ax3.set_xlabel(\"Hotspot Corridors\")\n",
    "        pdf.savefig(fig3)\n",
    "        plt.close(fig3)\n",
    "\n",
    "    print(f\"PDF saved successfully as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81844ad7-c4ba-469e-b01d-6e4b37a97258",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_visualizations_to_pdf(\n",
    "    df_imms_hotspot_all_activity_sum,\n",
    "    df_imms_hotspot_all_activity_labor,\n",
    "    df_imms_hotspot_all_activity_cost,\n",
    "    filename=\"hotspot_work_summary.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae2cc4-538b-404c-9753-9345ec88e68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4685b-8a0d-4fdd-ba40-6fdcd9d8e10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
