{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5403c9a1-a179-415f-bde2-2704cfd86a69",
   "metadata": {},
   "source": [
    "## SJSU Capstone Data Analysis\n",
    "*SJSU-MSTM*\n",
    "\n",
    "### README\n",
    "This notebook contains data cleaning, analysis and visualization for the SJSU capstone data; it validates data based on the Caltrans Data Quality Management Plan (DQMP) data quality dimensions listed below.\n",
    "\n",
    "> Note: Similar to software [unit testing][01.00], it is intended to serve as a test suite for the specified dataset.\n",
    "\n",
    "*Change Log*\n",
    "* 10-21-2020: Submit Version 1.0\n",
    "* 10-21-2020: Baseline Version v0.1\n",
    "* 11-26-2024: SJSU Capstone Update\n",
    "* 06-26-2025: Streamlined for simplicity - narrowing down to only requested visuals\n",
    "        * Total Work Activity by Hotspot Corridors\n",
    "        * Labor Totals by Hotspot Corridors\n",
    "        * Work Activity Cost by Hotspot Corridors\n",
    "\n",
    "*Deliverables*\n",
    "1. Test case are organized into separate modules and prints test results\n",
    "2. Each test will output non-compliant records into CSV files for action\n",
    "3. Data processing module produces transformed data (e.g. table joins)\n",
    "4. Notebook generates data dictionary after running all test cases\n",
    "5. All test cases are repeatable and documented\n",
    "\n",
    "*Data Quality Dimensions (DQMP)*\n",
    "1. Accuracy and Precision: Data is close to true value and exactness\n",
    "2. Validity: Conforms to established formats, data types and ranges\n",
    "3. Completeness: Absence of gaps in data, especially missing values\n",
    "4. Consistency: Data is collected at similar datetime and location\n",
    "5. Timeliness: Data is updated on a regular basis\n",
    "6. Granularity: Data is collected at appropriate level of detail for use\n",
    "7. Uniqueness: Best effort to collect data from authoritative sources\n",
    "8. Accessibility: Data is collected or processed into useable formats\n",
    "9. Reputation: Data is trusted as reliable source\n",
    "\n",
    "### Results (Summary)\n",
    "This section reports data validation findings and process steps.\n",
    "\n",
    "> Note: Data validation is intended to flag non-compliant values for discussion and not correction until confirmed by the team. As a result, the following issues were observed during data validation in addition to non-compliance report.\n",
    "\n",
    "*Datasets Cleaned, Analyzed & Visualized*\n",
    "1. Caltrans and Clean CA Litter Collection Totals\n",
    "2. Clean CA Level of Service (LOS) Scores\n",
    "3. Caltrans Customer Service Requests (CSRs)\n",
    "\n",
    "*Data Processing Steps*\n",
    "1. Import raw data/template files and save as table variables\n",
    "2. Crosswalk raw data/template fields; populate template\n",
    "3. Flag missing columns as \"Column not provided\"\n",
    "4. Convert column data types as needed\n",
    "5. Join project with corresponding table\n",
    "6. Save merged data for validation\n",
    "\n",
    "### Jupyter Introduction\n",
    "This notebook will require some basic understanding of the Python programming language, Jupyter platform and data analysis concepts. It is based on this [tutorial][01.02] and [Github Repo][01.03].\n",
    "\n",
    "Jupyter is a powerful collaborative tool which is open-source and light-weight. It provides all the tools necessary to run data analysis, visualization, statistics and data science [out of the box][01.04]. In addition, it has gain acceptance from industry and academia for collaborating on projects and publishing work.\n",
    "\n",
    "Jupyter is a combination of text and code with the programming run-time built into the platform so there is no need to install additional software. The text is in the markdown file format (similar to HTML), and code in several languages. It is organized by cells which can consist of either text or code; placed together, they can be sent as a single document to share/publish work.\n",
    "\n",
    "### Jupyter Notebook\n",
    "Notebooks are organized by cells, which mainly consist of text (in markdown) and code (Python). It operations like a hybrid between MS Word and Excel file; whereas the entire file is like a document, the cells operate like a spreadsheet. For getting started, feel free to scroll down each cell and navigate around the cells for a quick tour. Here is a breakdown of how to view/edit cells:\n",
    "\n",
    "*Navigation*\n",
    "1. Each cell may be edited by hitting ENTER; toggle between cells using the arrow keys or mouse/scroller\n",
    "2. When editing a cell, be sure to select \"markdown\" for text or \"code\" before writing into it\n",
    "3. Each cell can be run by hitting CTRL + ENTER or the \"run\" button form the menu bar\n",
    "4. Output from each cell will appear below; if an error occurs, please read and try to debug it(!)\n",
    "5. File can be saved by hitting CTRL + \"s\" or file/save from the pulldown menu above\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "*Notes*\n",
    "1. This notebook will require some Python programming\n",
    "2. It is widely used and taught in [high school][01.05] and AP Computer Science [courses][01.06]\n",
    "3. [Jupyter][01.07] supports many other languages, including R, Scala and Julia\n",
    "4. Python is the most popular of them and can be used for other tasks, primarily data science and web applications\n",
    "\n",
    "### Data\n",
    "#### IMMS OBI Reports\n",
    "\n",
    "*IMMS Activity Codes - Caltrans Maintenance Litter Abatement*  \n",
    "* D30050 - Caltrans Maintenance Sweeping\n",
    "* D40050 - Caltrans Maintenance Litter Control\n",
    "* D40150 - Caltrans Maintenance Road Patrol/Debris Pickup\n",
    "* D41050 - Caltrans Maintenance Adopt-A-Highway Litter Control\n",
    "* D42050 - Caltrans Maintenance Encampment Litter-Debris Removal\n",
    "* D44050 - Caltrans Maintenance Special Programs People (SPP) Litter Control  \n",
    "* D45050 - Illegal Dumping Debris Removal # Added June 26, 2025\n",
    "* D60050 - Caltrans Maintenance Graffiti Removal\n",
    "\n",
    "*IMMS Activity Codes - Clean California Litter Abatement*  \n",
    "* D30051 - Clean California Sweeping\n",
    "* D40051 - Clean California Litter Control\n",
    "* D40151 - Clean California Road Patrol/Debris Pickup\n",
    "* D41051 - Clean California Adopt-A-Highway Litter Control\n",
    "* D42051 - Clean California Encampment Litter/Debris Removal\n",
    "* D43051 - Clean California Dump Days\n",
    "* D44051 - Clean California Special Programs People (SPP) Litter Control\n",
    "* D60051 - Clean California Graffiti Removal  \n",
    "  \n",
    "*The Data query consists of the parameters listed below which was input into the query interface:\n",
    "* Maintenance Activity Family: D (Litter Abatement)\n",
    "* Activity Codes \"D30050;D30051;D40050;D40051;D40150;D40151;D41050;D41051;D42050;D42051;D44050;D44051\"\n",
    "* Timeframe: 6-month increments (e.g., 07/01/2021 to 12/31/2021)\n",
    "\n",
    "#### Data Updates\n",
    "* I (noah) pulled data from imms on 6/17/2025 for 2024b (7/1/2024 to 12/31/2024) and 2025a (1/1/2025 to 6/16/2025)\n",
    "\n",
    "### Exercises\n",
    "\n",
    "*Jupyter*\n",
    "1. [Intro Guide (DataQuest)][01.08]\n",
    "2. [Intro Guide (DataCamp)][01.09]\n",
    "3. [Notebook Intro (Medium)][01.10]\n",
    "4. [Data Science Tutorial (Jupyter)][01.11]\n",
    "\n",
    "*Python*\n",
    "1. [Quick Start][01.12]\n",
    "2. [Intro Tutorials][01.13]\n",
    "3. [Quick Start (FCC)][01.14]\n",
    "\n",
    "*Markdown*\n",
    "1. [Quick Start (Github)][01.15]\n",
    "2. [Quick Start Guide (Markdown)][01.16]\n",
    "3. [Quick Start Tutorial (Markdown)][01.17]\n",
    "\n",
    "[01.00]: https://en.wikipedia.org/wiki/Unit_testing\n",
    "[01.01]: https://www.anaconda.com/distribution/\n",
    "[01.02]: https://medium.com/python-pandemonium/introduction-to-exploratory-data-analysis-in-python-8b6bcb55c190\n",
    "[01.03]: https://github.com/kadnan/EDA_Python/\n",
    "[01.04]: https://jupyter.org/jupyter-book/01/what-is-data-science.html\n",
    "[01.05]: https://codehs.com/info/curriculum/intropython\n",
    "[01.06]: https://code.org/educate/curriculum/high-school\n",
    "[01.07]: https://jupyter.org/\n",
    "[01.08]: https://www.dataquest.io/blog/jupyter-notebook-tutorial/\n",
    "[01.09]: https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\n",
    "[01.10]: https://towardsdatascience.com/a-beginners-tutorial-to-jupyter-notebooks-1b2f8705888a\n",
    "[01.11]: https://jupyter.org/jupyter-book/01/what-is-data-science.html\n",
    "[01.12]: https://www.python.org/about/gettingstarted/\n",
    "[01.13]: https://realpython.com/learning-paths/python3-introduction/\n",
    "[01.14]: https://guide.freecodecamp.org/python/\n",
    "[01.15]: https://guides.github.com/features/mastering-markdown/\n",
    "[01.16]: https://www.markdownguide.org/getting-started/\n",
    "[01.17]: https://www.markdowntutorial.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8633eadd-39b9-4645-924e-0db3b2410b64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gcsfs in /opt/conda/lib/python3.11/site-packages (2023.12.2.post1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from gcsfs) (3.11.11)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n",
      "Requirement already satisfied: fsspec==2023.12.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs) (2023.12.2)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.11/site-packages (from gcsfs) (1.2.1)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.11/site-packages (from gcsfs) (2.19.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from gcsfs) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.18.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.24.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (1.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->gcsfs) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->gcsfs) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->gcsfs) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->gcsfs) (2024.12.14)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (5.29.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.25.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# 01.01 - load python modules into notebook\n",
    "\n",
    "# install pip package in current kernel; run only for initial install:\n",
    "# https://medium.com/@rohanguptha.bompally/python-data-visualization-using-folium-and-geopandas-981857948f02\n",
    "# !pip install descartes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# data analysis modules\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# data visualization modules\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# for the PDF export\n",
    "import json\n",
    "import nbformat\n",
    "from textwrap import wrap\n",
    "\n",
    "# Added by Noah to help with importing\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# to help import the data\n",
    "!pip install gcsfs pandas\n",
    "\n",
    "# set numeric output; turn off scientific notation\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "\n",
    "# adjust print settings\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 35\n",
    "\n",
    "# suppress warning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63da05e3-d336-4874-a89a-164ca0a4a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added by NS 4/17/2025\n",
    "# Identify the path to the Data\n",
    "gcs_path = (\n",
    "    \"gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/\"\n",
    ")\n",
    "# Identify the path to the output data\n",
    "gcs_output_folder = \"gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/00_study_created_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10af7d91-3f54-4453-b831-f82b138f96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.01 - data import functions\n",
    "\n",
    "# A function to pull in a CSV file from DDS's Google Cloud Storage bucket\n",
    "def load_csv_from_gcs_folder(file_name):\n",
    "    \"\"\"\n",
    "    Load a CSV file from GCS using default credentials, with encoding fallback.\n",
    "\n",
    "    Parameters:\n",
    "        gcs_path (str): Base GCS path (e.g., 'gs://bucket/folder')\n",
    "        file_name (str): Name of the CSV file\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame or None if load fails\n",
    "    \"\"\"\n",
    "    gcs_uri = f\"{gcs_path.rstrip('/')}/{file_name}\"\n",
    "    print(f\"Attempting to load: {gcs_uri}\")\n",
    "\n",
    "    try:\n",
    "        # Try standard UTF-8 first\n",
    "        df = pd.read_csv(gcs_uri)\n",
    "        print(f\"Loaded CSV with UTF-8 encoding: {gcs_uri}\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            # Try with Latin-1 fallback if UTF-8 fails\n",
    "            df = pd.read_csv(gcs_uri, encoding='ISO-8859-1')\n",
    "            print(f\"Loaded CSV with ISO-8859-1 encoding: {gcs_uri}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load with ISO-8859-1: {e}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV from {gcs_uri}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Added by Noah Sanchez June 2025\n",
    "# function to write csv file to GCS\n",
    "# study created data (scd)\n",
    "def write_scd_data_csv(df, gcs_output_path):\n",
    "    df.to_csv(gcs_output_path, index=False)\n",
    "\n",
    "\n",
    "# function to show table info\n",
    "def data_profile(df, msg):\n",
    "    # pass in variable into string\n",
    "    # https://stackoverflow.com/questions/2960772/how-do-i-put-a-variable-inside-a-string\n",
    "    print(\"*** Table Info: %s ***\" % msg, \"\\n\")\n",
    "    print(df.info(), \"\\n\")\n",
    "    print(\"*** Table Info: Table Dimensions ***\", \"\\n\")\n",
    "    print(df.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d26880e-d00a-4e55-826c-ab3c98319e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.02 - data processing functions\n",
    "\n",
    "\n",
    "# function convert col to string type\n",
    "# https://www.geeksforgeeks.org/python-pandas-series-astype-to-convert-data-type-of-series/\n",
    "def convert_str(df, col):\n",
    "    df[col] = df[col].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011366ec-8ed1-4cee-9c24-86515b0ae79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03.00 - data subset and table join functions\n",
    "\n",
    "# subset dataset by row values; for example, project list by funding source\n",
    "# https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "# df_projects_atp = df_projects[df_projects['SOURCE'].str.contains('ATP')]\n",
    "\n",
    "\n",
    "# define table join function; merge new and old tables on given column\n",
    "def join_table(df_left, df_right, col, method, msg):\n",
    "    df_join = pd.merge(df_left, df_right, on=col, how=method)\n",
    "    print(msg, \"\\n\")\n",
    "    print(\"Before Table Join: \")\n",
    "    print(\"Left Table: \", df_left.shape)\n",
    "    print(\"Right Table: \", df_right.shape, \"\\n\")\n",
    "    print(\"After Table Join: \")\n",
    "    print(\"Left + Right Table: \", df_join.shape, \"\\n\")\n",
    "    return df_join\n",
    "\n",
    "\n",
    "# define table join function; merge new and old tables with different keys\n",
    "# https://stackoverflow.com/questions/25888207/pandas-join-dataframes-on-field-with-different-names\n",
    "def join_table_key(df_left, df_right, id_key, fk_key, msg):\n",
    "    df_join = pd.merge(\n",
    "        df_left, df_right, how=\"left\", left_on=[id_key], right_on=[fk_key]\n",
    "    )\n",
    "    print(msg, \"\\n\")\n",
    "    print(\"Before Table Join: \")\n",
    "    print(\"Left Table: \", df_left.shape)\n",
    "    print(\"Right Table: \", df_right.shape, \"\\n\")\n",
    "    print(\"After Table Join: \")\n",
    "    print(\"Left + Right Table: \", df_join.shape, \"\\n\")\n",
    "    return df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1d21ca-82aa-4273-8543-abddbb903417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2021b.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2021b.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2022a.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2022a.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2022b.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2022b.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2023a.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2023a.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2023b.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2023b.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2024a.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2024a.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2024b.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2024b.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2025a.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/imms_2025a.csv\n",
      "*** Table Dimensions: Original (IMMS 2021B) *** \n",
      "\n",
      "(26910, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2021B) *** \n",
      "\n",
      "(26910, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2021B) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2022A) *** \n",
      "\n",
      "(32379, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2022A) *** \n",
      "\n",
      "(32379, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2022A) *** \n",
      "\n",
      "(32379, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022A) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2022B) *** \n",
      "\n",
      "(34330, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2022B) *** \n",
      "\n",
      "(34330, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with null values in production columns (IMMS 2022B) ***\n",
      "\n",
      "(34330, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022B) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2023A) *** \n",
      "\n",
      "(32443, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2023A) *** \n",
      "\n",
      "(32443, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2023A) *** \n",
      "\n",
      "(32443, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023A) ***\n",
      "\n",
      "(0, 32) \n",
      "\n",
      "*** Table Dimensions: Original (IMMS 2023B) *** \n",
      "\n",
      "(34346, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null PM (IMMS 2023B) *** \n",
      "\n",
      "(34346, 32) \n",
      "\n",
      "*** Table Dimensions: Remove null litter prod (IMMS 2023B) *** \n",
      "\n",
      "(34346, 32) \n",
      "\n",
      "*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023B) ***\n",
      "\n",
      "(0, 32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 05.01.01 - data import/cleaning (imms)\n",
    "\n",
    "\n",
    "# import imms/litter collection totals as csv datasets from a local folder\n",
    "df_imms_2021b = load_csv_from_gcs_folder(\"imms_2021b.csv\")\n",
    "df_imms_2022a = load_csv_from_gcs_folder(\"imms_2022a.csv\")\n",
    "df_imms_2022b = load_csv_from_gcs_folder(\"imms_2022b.csv\")\n",
    "df_imms_2023a = load_csv_from_gcs_folder(\"imms_2023a.csv\")\n",
    "df_imms_2023b = load_csv_from_gcs_folder(\"imms_2023b.csv\")\n",
    "df_imms_2024a = load_csv_from_gcs_folder(\"imms_2024a.csv\")\n",
    "df_imms_2024b = load_csv_from_gcs_folder(\"imms_2024b.csv\") # Added by NS 6/17/2025\n",
    "df_imms_2025a = load_csv_from_gcs_folder(\"imms_2025a.csv\") # Added by NS 6/17/2025\n",
    "\n",
    "\n",
    "# clean data - IMMS 2021B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2021B) ***\", \"\\n\")\n",
    "print(df_imms_2021b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2021b = df_imms_2021b[~df_imms_2021b['From PM'].isnull()]\n",
    "# df_imms_2021b = df_imms_2021b[~df_imms_2021b['To PM'].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null PM (IMMS 2021B) ***', '\\n')\n",
    "# print(df_imms_2021b.shape , '\\n')\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b[\"Production Quantity\"].isnull()]\n",
    "df_imms_2021b = df_imms_2021b[~df_imms_2021b[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2021B) ***\", \"\\n\")\n",
    "print(df_imms_2021b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2021b = df_imms_2021b[df_imms_2021b[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2021b = df_imms_2021b[df_imms_2021b[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2021B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2021b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2022A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2022A) ***\", \"\\n\")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2022a = df_imms_2022a[~df_imms_2022a['From PM'].isnull()]\n",
    "# df_imms_2022a = df_imms_2022a[~df_imms_2022a['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2022A) ***\", \"\\n\")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a[\"Production Quantity\"].isnull()]\n",
    "df_imms_2022a = df_imms_2022a[~df_imms_2022a[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2022A) ***\", \"\\n\")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2022a = df_imms_2022a[df_imms_2022a[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2022a = df_imms_2022a[df_imms_2022a[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022A) ***\\n\"\n",
    ")\n",
    "print(df_imms_2022a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2022B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2022B) ***\", \"\\n\")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2022b = df_imms_2022b[~df_imms_2022b['From PM'].isnull()]\n",
    "# df_imms_2022b = df_imms_2022b[~df_imms_2022b['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2022B) ***\", \"\\n\")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows with null values in 'Production Quantity' and 'Secondary Prod' columns\n",
    "df_imms_2022b = df_imms_2022b.dropna(subset=[\"Production Quantity\", \"Secondary Prod\"])\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with null values in production columns (IMMS 2022B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2022b = df_imms_2022b[df_imms_2022b[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2022b = df_imms_2022b[df_imms_2022b[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2022B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2022b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2023A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2023A) ***\", \"\\n\")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2023a = df_imms_2023a[~df_imms_2023a['From PM'].isnull()]\n",
    "# df_imms_2023a = df_imms_2023a[~df_imms_2023a['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2023A) ***\", \"\\n\")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a[\"Production Quantity\"].isnull()]\n",
    "df_imms_2023a = df_imms_2023a[~df_imms_2023a[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2023A) ***\", \"\\n\")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2023a = df_imms_2023a[df_imms_2023a[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2023a = df_imms_2023a[df_imms_2023a[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023A) ***\\n\"\n",
    ")\n",
    "print(df_imms_2023a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# clean data - IMMS 2023B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (IMMS 2023B) ***\", \"\\n\")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_imms_2023b = df_imms_2023b[~df_imms_2023b['From PM'].isnull()]\n",
    "# df_imms_2023b = df_imms_2023b[~df_imms_2023b['To PM'].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null PM (IMMS 2023B) ***\", \"\\n\")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b[\"Production Quantity\"].isnull()]\n",
    "df_imms_2023b = df_imms_2023b[~df_imms_2023b[\"Secondary Prod\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null litter prod (IMMS 2023B) ***\", \"\\n\")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ns_edit_1: This section replaces the previous section.\n",
    "# Remove rows where 'Production Quantity' or 'Secondary Prod' is less than or equal to 1000\n",
    "df_imms_2023b = df_imms_2023b[df_imms_2023b[\"Production Quantity\"].astype(int) > 1000]\n",
    "df_imms_2023b = df_imms_2023b[df_imms_2023b[\"Secondary Prod\"].astype(int) > 1000]\n",
    "\n",
    "# Check table dimensions\n",
    "print(\n",
    "    \"*** Table Dimensions: Removed entries with production ≤ 1000 CY (IMMS 2023B) ***\\n\"\n",
    ")\n",
    "print(df_imms_2023b.shape, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Added by NS to clean the newly added dataframes\n",
    "def drop_last_three_columns(df):\n",
    "    \"\"\"\n",
    "    Drops columns at positions 32, 33, and 34 from the DataFrame, if they exist.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A copy of the DataFrame with specified columns removed.\n",
    "    \"\"\"\n",
    "    cols_to_drop = df.columns[32:35]  # positions 32, 33, 34\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "# remove the last three columns in the dataframe\n",
    "df_imms_2024b = drop_last_three_columns(df_imms_2024b)\n",
    "df_imms_2025a = drop_last_three_columns(df_imms_2025a)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Added by NS April 2025\n",
    "# export final csv file\n",
    "write_scd_data_csv(df_imms_2021b, f\"{gcs_output_folder}/df_imms_2021b.csv\")\n",
    "write_scd_data_csv(df_imms_2022a, f\"{gcs_output_folder}/df_imms_2022a.csv\")\n",
    "write_scd_data_csv(df_imms_2022b, f\"{gcs_output_folder}/df_imms_2022b.csv\")\n",
    "write_scd_data_csv(df_imms_2023a, f\"{gcs_output_folder}/df_imms_2023a.csv\")\n",
    "write_scd_data_csv(df_imms_2023b, f\"{gcs_output_folder}/df_imms_2023b.csv\")\n",
    "write_scd_data_csv(df_imms_2024a, f\"{gcs_output_folder}/df_imms_2024a.csv\")\n",
    "write_scd_data_csv(df_imms_2024b, f\"{gcs_output_folder}/df_imms_2024b.csv\") # Added by NS 6/17/2025\n",
    "write_scd_data_csv(df_imms_2025a, f\"{gcs_output_folder}/df_imms_2025a.csv\") # Added by NS 6/17/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e1743-cc03-4ec7-998d-051cee60c031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b9e26-9c36-4be6-828c-225c65869016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d51c88e1-0b8a-432d-9b17-3a99c143cedd",
   "metadata": {},
   "source": [
    "# CSR Data? Do I need to update?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a223c-7ff2-439f-81d8-e2b088b28ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/csr_litter_aah_2021b.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/csr_litter_aah_2021b.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/csr_litter_aah_2022a.csv\n",
      "Loaded CSV with UTF-8 encoding: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/csr_litter_aah_2022a.csv\n",
      "Attempting to load: gs://calitp-analytics-data/data-analyses/big_data/clean_california_litter_study/01_source_data/csr_litter_aah_2022b.csv\n"
     ]
    }
   ],
   "source": [
    "# 05.01.02 - data import/cleaning (csr)\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# Import CSR data as CSV datasets\n",
    "df_csr_2021b = load_csv_from_gcs_folder(\"csr_litter_aah_2021b.csv\")\n",
    "df_csr_2022a = load_csv_from_gcs_folder(\"csr_litter_aah_2022a.csv\")\n",
    "df_csr_2022b = load_csv_from_gcs_folder(\"csr_litter_aah_2022b.csv\")\n",
    "df_csr_2023a = load_csv_from_gcs_folder(\"csr_litter_aah_2023a.csv\")\n",
    "df_csr_2023b = load_csv_from_gcs_folder(\"csr_litter_aah_2023b.csv\")\n",
    "df_csr_2024a = load_csv_from_gcs_folder(\"csr_litter_aah_2024a.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clean data - CSR 2021B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2021B) ***\", \"\\n\")\n",
    "print(df_csr_2021b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2021B) ***\", \"\\n\")\n",
    "print(df_csr_2021b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b[\"Latitude\"].isnull()]\n",
    "df_csr_2021b = df_csr_2021b[~df_csr_2021b[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2021B) ***\", \"\\n\")\n",
    "print(df_csr_2021b.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2022A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2022A) ***\", \"\\n\")\n",
    "print(df_csr_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2022A) ***\", \"\\n\")\n",
    "print(df_csr_2022a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a[\"Latitude\"].isnull()]\n",
    "df_csr_2022a = df_csr_2022a[~df_csr_2022a[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2022A) ***\", \"\\n\")\n",
    "print(df_csr_2022a.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2022B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2022B) ***\", \"\\n\")\n",
    "print(df_csr_2022b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2022B) ***\", \"\\n\")\n",
    "print(df_csr_2022b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b[\"Latitude\"].isnull()]\n",
    "df_csr_2022b = df_csr_2022b[~df_csr_2022b[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2022B) ***\", \"\\n\")\n",
    "print(df_csr_2022b.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2023A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2023A) ***\", \"\\n\")\n",
    "print(df_csr_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2023A) ***\", \"\\n\")\n",
    "print(df_csr_2023a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a[\"Latitude\"].isnull()]\n",
    "df_csr_2023a = df_csr_2023a[~df_csr_2023a[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2023A) ***\", \"\\n\")\n",
    "print(df_csr_2023a.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2023B\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2023B) ***\", \"\\n\")\n",
    "print(df_csr_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2023B) ***\", \"\\n\")\n",
    "print(df_csr_2023b.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b[\"Latitude\"].isnull()]\n",
    "df_csr_2023b = df_csr_2023b[~df_csr_2023b[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2023B) ***\", \"\\n\")\n",
    "print(df_csr_2023b.shape, \"\\n\")\n",
    "\n",
    "# clean data - CSR 2024A\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (CSR 2024A) ***\", \"\\n\")\n",
    "print(df_csr_2024a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a[\"Date Opened\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null date opened (CSR 2024A) ***\", \"\\n\")\n",
    "print(df_csr_2024a.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a[\"Latitude\"].isnull()]\n",
    "df_csr_2024a = df_csr_2024a[~df_csr_2024a[\"Longitude\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null lat/long (CSR 2024A) ***\", \"\\n\")\n",
    "print(df_csr_2024a.shape, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Added by NS\n",
    "# export final csv file\n",
    "write_scd_data_csv(df_csr_2021b, f\"{gcs_output_folder}/05.01.02_data_clean_csr_2021b.csv\")\n",
    "write_scd_data_csv(df_csr_2022a, f\"{gcs_output_folder}/05.01.02_data_clean_csr_2022a.csv\")\n",
    "write_scd_data_csv(df_csr_2022b, f\"{gcs_output_folder}/05.01.02_data_clean_csr_2022b.csv\")\n",
    "write_scd_data_csv(df_csr_2023a, f\"{gcs_output_folder}/05.01.02_data_clean_csr_2023a.csv\")\n",
    "write_scd_data_csv(df_csr_2023b, f\"{gcs_output_folder}/05.01.02_data_clean_csr_2023b.csv\")\n",
    "write_scd_data_csv(df_csr_2024a, f\"{gcs_output_folder}/05.01.02_data_clean_csr_2024a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd7116-6fb7-4306-bab9-0be14583a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.01.03 - data import/cleaning (los)\n",
    "\n",
    "# Added by NS 4/17/2025\n",
    "# Import LOS scores data as CSV datasets\n",
    "df_los_2023a_d1 = load_csv_from_gcs_folder(\"los_scores_2023a_d1.csv\")\n",
    "df_los_2023a_d2 = load_csv_from_gcs_folder(\"los_scores_2023a_d2.csv\")\n",
    "df_los_2023a_d3 = load_csv_from_gcs_folder(\"los_scores_2023a_d3.csv\")\n",
    "df_los_2023a_d4 = load_csv_from_gcs_folder(\"los_scores_2023a_d4.csv\")\n",
    "df_los_2023a_d5 = load_csv_from_gcs_folder(\"los_scores_2023a_d5.csv\")\n",
    "df_los_2023a_d6 = load_csv_from_gcs_folder(\"los_scores_2023a_d6.csv\")\n",
    "df_los_2023a_d7 = load_csv_from_gcs_folder(\"los_scores_2023a_d7.csv\")\n",
    "df_los_2023a_d8 = load_csv_from_gcs_folder(\"los_scores_2023a_d8.csv\")\n",
    "df_los_2023a_d9 = load_csv_from_gcs_folder(\"los_scores_2023a_d9.csv\")\n",
    "df_los_2023a_d10 = load_csv_from_gcs_folder(\"los_scores_2023a_d10.csv\")\n",
    "df_los_2023a_d11 = load_csv_from_gcs_folder(\"los_scores_2023a_d11.csv\")\n",
    "df_los_2023a_d12 = load_csv_from_gcs_folder(\"los_scores_2023a_d12.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import LOS scores (raw) as CSV datasets\n",
    "df_los_all_d1 = load_csv_from_gcs_folder(\"los_scores_raw_d1.csv\")\n",
    "df_los_all_d2 = load_csv_from_gcs_folder(\"los_scores_raw_d2.csv\")\n",
    "df_los_all_d3 = load_csv_from_gcs_folder(\"los_scores_raw_d3.csv\")\n",
    "df_los_all_d4 = load_csv_from_gcs_folder(\"los_scores_raw_d4.csv\")\n",
    "df_los_all_d5 = load_csv_from_gcs_folder(\"los_scores_raw_d5.csv\")\n",
    "df_los_all_d6 = load_csv_from_gcs_folder(\"los_scores_raw_d6.csv\")\n",
    "df_los_all_d7 = load_csv_from_gcs_folder(\"los_scores_raw_d7.csv\")\n",
    "df_los_all_d8 = load_csv_from_gcs_folder(\"los_scores_raw_d8.csv\")\n",
    "df_los_all_d9 = load_csv_from_gcs_folder(\"los_scores_raw_d9.csv\")\n",
    "df_los_all_d10 = load_csv_from_gcs_folder(\"los_scores_raw_d10.csv\")\n",
    "df_los_all_d11 = load_csv_from_gcs_folder(\"los_scores_raw_d11.csv\")\n",
    "df_los_all_d12 = load_csv_from_gcs_folder(\"los_scores_raw_d12.csv\")\n",
    "\n",
    "\n",
    "# import los scores as csv datasets\n",
    "data_profile(df_los_all_d1, \"Data Profile: LOS - d1\")\n",
    "data_profile(df_los_all_d2, \"Data Profile: LOS - d2\")\n",
    "data_profile(df_los_all_d3, \"Data Profile: LOS - d3\")\n",
    "data_profile(df_los_all_d4, \"Data Profile: LOS - d4\")\n",
    "data_profile(df_los_all_d5, \"Data Profile: LOS - d5\")\n",
    "data_profile(df_los_all_d6, \"Data Profile: LOS - d6\")\n",
    "data_profile(df_los_all_d7, \"Data Profile: LOS - d7\")\n",
    "data_profile(df_los_all_d8, \"Data Profile: LOS - d8\")\n",
    "data_profile(df_los_all_d9, \"Data Profile: LOS - d9\")\n",
    "data_profile(df_los_all_d10, \"Data Profile: LOS - d10\")\n",
    "data_profile(df_los_all_d11, \"Data Profile: LOS - d11\")\n",
    "data_profile(df_los_all_d12, \"Data Profile: LOS - d12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd90c72-b672-4af2-97ab-7ef90fd591cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8f0c9-88b0-4125-bfae-d14c0c8dc97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530956b-4eb9-4966-8cd2-3b63f26c9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# clean data - los_2023a_d1\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d1) ***\", \"\\n\")\n",
    "print(df_los_2023a_d1.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d1 = df_los_2023a_d1[~df_los_2023a_d1[\"CO\"].isnull()]\n",
    "df_los_2023a_d1 = df_los_2023a_d1[~df_los_2023a_d1[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d1) ***', '\\n')\n",
    "# print(df_los_2023a_d1.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d2\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d2) ***\", \"\\n\")\n",
    "print(df_los_2023a_d2.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d2 = df_los_2023a_d2[~df_los_2023a_d2[\"CO\"].isnull()]\n",
    "df_los_2023a_d2 = df_los_2023a_d2[~df_los_2023a_d2[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d2) ***', '\\n')\n",
    "# print(df_los_2023a_d2.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d3\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d3) ***\", \"\\n\")\n",
    "print(df_los_2023a_d3.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d3 = df_los_2023a_d3[~df_los_2023a_d3[\"CO\"].isnull()]\n",
    "df_los_2023a_d3 = df_los_2023a_d3[~df_los_2023a_d3[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d3) ***', '\\n')\n",
    "# print(df_los_2023a_d3.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d4\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d4) ***\", \"\\n\")\n",
    "print(df_los_2023a_d4.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d4 = df_los_2023a_d4[~df_los_2023a_d4[\"CO\"].isnull()]\n",
    "df_los_2023a_d4 = df_los_2023a_d4[~df_los_2023a_d4[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d4) ***', '\\n')\n",
    "# print(df_los_2023a_d4.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d5\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d5) ***\", \"\\n\")\n",
    "print(df_los_2023a_d5.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d5 = df_los_2023a_d5[~df_los_2023a_d5[\"CO\"].isnull()]\n",
    "df_los_2023a_d5 = df_los_2023a_d5[~df_los_2023a_d5[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d5) ***', '\\n')\n",
    "# print(df_los_2023a_d5.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d6\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d6) ***\", \"\\n\")\n",
    "print(df_los_2023a_d6.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d6 = df_los_2023a_d6[~df_los_2023a_d6[\"CO\"].isnull()]\n",
    "df_los_2023a_d6 = df_los_2023a_d6[~df_los_2023a_d6[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d6) ***', '\\n')\n",
    "# print(df_los_2023a_d6.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d7\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d7) ***\", \"\\n\")\n",
    "print(df_los_2023a_d7.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d7 = df_los_2023a_d7[~df_los_2023a_d7[\"CO\"].isnull()]\n",
    "df_los_2023a_d7 = df_los_2023a_d7[~df_los_2023a_d7[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d7) ***', '\\n')\n",
    "# print(df_los_2023a_d7.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d8\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d8) ***\", \"\\n\")\n",
    "print(df_los_2023a_d8.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d8 = df_los_2023a_d8[~df_los_2023a_d8[\"CO\"].isnull()]\n",
    "df_los_2023a_d8 = df_los_2023a_d8[~df_los_2023a_d8[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d8) ***', '\\n')\n",
    "# print(df_los_2023a_d8.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d9\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d9) ***\", \"\\n\")\n",
    "print(df_los_2023a_d9.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d9 = df_los_2023a_d9[~df_los_2023a_d9[\"CO\"].isnull()]\n",
    "df_los_2023a_d9 = df_los_2023a_d9[~df_los_2023a_d9[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d9) ***', '\\n')\n",
    "# print(df_los_2023a_d9.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d10\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d10) ***\", \"\\n\")\n",
    "print(df_los_2023a_d10.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d10 = df_los_2023a_d10[~df_los_2023a_d10[\"CO\"].isnull()]\n",
    "df_los_2023a_d10 = df_los_2023a_d10[~df_los_2023a_d10[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d10) ***', '\\n')\n",
    "# print(df_los_2023a_d10.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d11\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d11) ***\", \"\\n\")\n",
    "print(df_los_2023a_d11.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d11 = df_los_2023a_d11[~df_los_2023a_d11[\"CO\"].isnull()]\n",
    "df_los_2023a_d11 = df_los_2023a_d11[~df_los_2023a_d11[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d11) ***', '\\n')\n",
    "# print(df_los_2023a_d11.shape , '\\n')\n",
    "\n",
    "# clean data - los_2023a_d12\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_2023a_d12) ***\", \"\\n\")\n",
    "print(df_los_2023a_d12.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_2023a_d12 = df_los_2023a_d12[~df_los_2023a_d12[\"CO\"].isnull()]\n",
    "df_los_2023a_d12 = df_los_2023a_d12[~df_los_2023a_d12[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove null dist/co/rte (los_2023a_d12) ***', '\\n')\n",
    "# print(df_los_2023a_d12.shape , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbd488-2a5c-4532-b1cb-829790f2b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# export final csv file\n",
    "write_scd_data_csv(df_los_2023a_d1, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d1.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d2, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d2.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d3, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d3.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d4, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d4.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d5, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d5.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d6, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d6.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d7, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d7.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d8, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d8.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d9, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d9.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d10, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d10.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d11, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d11.csv\")\n",
    "write_scd_data_csv(df_los_2023a_d12, f\"{gcs_output_folder}/05.01.03_data_clean_los_2023a_d12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a876c3-ad08-44ef-917c-f9bae2d446db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data - los_all_d1\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d1) ***\", \"\\n\")\n",
    "print(df_los_all_d1.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d1 = df_los_all_d1[~df_los_all_d1[\"CO\"].isnull()]\n",
    "df_los_all_d1 = df_los_all_d1[~df_los_all_d1[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d1) ***\", \"\\n\")\n",
    "print(df_los_all_d1.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d2\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d2) ***\", \"\\n\")\n",
    "print(df_los_all_d2.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d2 = df_los_all_d2[~df_los_all_d2[\"CO\"].isnull()]\n",
    "df_los_all_d2 = df_los_all_d2[~df_los_all_d2[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d2) ***\", \"\\n\")\n",
    "print(df_los_all_d2.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d3\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d3) ***\", \"\\n\")\n",
    "print(df_los_all_d3.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d3 = df_los_all_d3[~df_los_all_d3[\"CO\"].isnull()]\n",
    "df_los_all_d3 = df_los_all_d3[~df_los_all_d3[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d3) ***\", \"\\n\")\n",
    "print(df_los_all_d3.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d4\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d4) ***\", \"\\n\")\n",
    "print(df_los_all_d4.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d4 = df_los_all_d4[~df_los_all_d4[\"CO\"].isnull()]\n",
    "df_los_all_d4 = df_los_all_d4[~df_los_all_d4[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d4) ***\", \"\\n\")\n",
    "print(df_los_all_d4.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d5\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d5) ***\", \"\\n\")\n",
    "print(df_los_all_d5.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d5 = df_los_all_d5[~df_los_all_d5[\"CO\"].isnull()]\n",
    "df_los_all_d5 = df_los_all_d5[~df_los_all_d5[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d5) ***\", \"\\n\")\n",
    "print(df_los_all_d5.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d6\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d6) ***\", \"\\n\")\n",
    "print(df_los_all_d6.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d6 = df_los_all_d6[~df_los_all_d6[\"CO\"].isnull()]\n",
    "df_los_all_d6 = df_los_all_d6[~df_los_all_d6[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d6) ***\", \"\\n\")\n",
    "print(df_los_all_d6.shape, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This caused an error:\n",
    "\n",
    "# # clean data - los_all_d7\n",
    "# # check table dim\n",
    "# print(\"*** Table Dimensions: Original (los_all_d7) ***\", \"\\n\")\n",
    "# print(df_los_all_d7.shape, \"\\n\")\n",
    "# # remove null values from given column\n",
    "# # https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_los_all_d7 = df_los_all_d7[~df_los_all_d7[\"CO\"].isnull()]\n",
    "# df_los_all_d7 = df_los_all_d7[~df_los_all_d7[\"RTE\"].isnull()]\n",
    "# # check table dim\n",
    "# print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d7) ***\", \"\\n\")\n",
    "# print(df_los_all_d7.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# this is my workaround eda\n",
    "# the error is saying that there isn't a dataframe, so the issue may be at a different spot in the script\n",
    "# running the script with the script that remove nulls commented out\n",
    "\n",
    "# clean data - los_all_d7\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d7) ***\", \"\\n\")\n",
    "print(df_los_all_d7.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "# df_los_all_d7 = df_los_all_d7[~df_los_all_d7[\"CO\"].isnull()]\n",
    "# df_los_all_d7 = df_los_all_d7[~df_los_all_d7[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d7) ***\", \"\\n\")\n",
    "print(df_los_all_d7.shape, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clean data - los_all_d8\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d8) ***\", \"\\n\")\n",
    "print(df_los_all_d8.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d8 = df_los_all_d8[~df_los_all_d8[\"CO\"].isnull()]\n",
    "df_los_all_d8 = df_los_all_d8[~df_los_all_d8[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d8) ***\", \"\\n\")\n",
    "print(df_los_all_d8.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d9\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d9) ***\", \"\\n\")\n",
    "print(df_los_all_d9.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d9 = df_los_all_d9[~df_los_all_d9[\"CO\"].isnull()]\n",
    "df_los_all_d9 = df_los_all_d9[~df_los_all_d9[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d9) ***\", \"\\n\")\n",
    "print(df_los_all_d9.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d10\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d10) ***\", \"\\n\")\n",
    "print(df_los_all_d10.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d10 = df_los_all_d10[~df_los_all_d10[\"CO\"].isnull()]\n",
    "df_los_all_d10 = df_los_all_d10[~df_los_all_d10[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d10) ***\", \"\\n\")\n",
    "print(df_los_all_d10.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d11\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d11) ***\", \"\\n\")\n",
    "print(df_los_all_d11.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d11 = df_los_all_d11[~df_los_all_d11[\"CO\"].isnull()]\n",
    "df_los_all_d11 = df_los_all_d11[~df_los_all_d11[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d11) ***\", \"\\n\")\n",
    "print(df_los_all_d11.shape, \"\\n\")\n",
    "\n",
    "# clean data - los_all_d12\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Original (los_all_d12) ***\", \"\\n\")\n",
    "print(df_los_all_d12.shape, \"\\n\")\n",
    "# remove null values from given column\n",
    "# https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n",
    "df_los_all_d12 = df_los_all_d12[~df_los_all_d12[\"CO\"].isnull()]\n",
    "df_los_all_d12 = df_los_all_d12[~df_los_all_d12[\"RTE\"].isnull()]\n",
    "# check table dim\n",
    "print(\"*** Table Dimensions: Remove null dist/co/rte (los_all_d12) ***\", \"\\n\")\n",
    "print(df_los_all_d12.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# export final csv file\n",
    "write_scd_data_csv(df_los_all_d1, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d1.csv\")\n",
    "write_scd_data_csv(df_los_all_d2, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d2.csv\")\n",
    "write_scd_data_csv(df_los_all_d3, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d3.csv\")\n",
    "write_scd_data_csv(df_los_all_d4, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d4.csv\")\n",
    "write_scd_data_csv(df_los_all_d5, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d5.csv\")\n",
    "write_scd_data_csv(df_los_all_d6, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d6.csv\")\n",
    "write_scd_data_csv(df_los_all_d7, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d7.csv\")\n",
    "write_scd_data_csv(df_los_all_d8, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d8.csv\")\n",
    "write_scd_data_csv(df_los_all_d9, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d9.csv\")\n",
    "write_scd_data_csv(df_los_all_d10, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d10.csv\")\n",
    "write_scd_data_csv(df_los_all_d11, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d11.csv\")\n",
    "write_scd_data_csv(df_los_all_d12, f\"{gcs_output_folder}/05.01.03_data_clean_los_all_d12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de73b1-f5a7-45e7-8628-b7b879bfc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.01 - data analysis (imms)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The replacement\n",
    "def filter_by_uom_and_district(df, district_number):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame for rows where 'UOM' contains 'CUYD' and 'Resp. District' equals the specified district_number.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    district_number (int): The district number to filter by.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure 'Resp. District' is of integer type for accurate comparison\n",
    "    df[\"Resp. District\"] = pd.to_numeric(df[\"Resp. District\"], errors=\"coerce\")\n",
    "\n",
    "    # Filter rows where 'UOM' contains 'CUYD' and 'Resp. District' matches the specified number\n",
    "    filtered_df = df[\n",
    "        df[\"UOM\"].str.contains(\"CUYD\", na=False)\n",
    "        & (df[\"Resp. District\"] == district_number)\n",
    "    ]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Apply the function to create various dataframes\n",
    "df_imms_2023a_bar_d1 = filter_by_uom_and_district(df_imms_2023a, 1)\n",
    "df_imms_2023a_bar_d2 = filter_by_uom_and_district(df_imms_2023a, 2)\n",
    "df_imms_2023a_bar_d3 = filter_by_uom_and_district(df_imms_2023a, 3)\n",
    "df_imms_2023a_bar_d4 = filter_by_uom_and_district(df_imms_2023a, 4)\n",
    "df_imms_2023a_bar_d5 = filter_by_uom_and_district(df_imms_2023a, 5)\n",
    "df_imms_2023a_bar_d6 = filter_by_uom_and_district(df_imms_2023a, 6)\n",
    "df_imms_2023a_bar_d7 = filter_by_uom_and_district(df_imms_2023a, 7)\n",
    "df_imms_2023a_bar_d8 = filter_by_uom_and_district(df_imms_2023a, 8)\n",
    "df_imms_2023a_bar_d9 = filter_by_uom_and_district(df_imms_2023a, 9)\n",
    "df_imms_2023a_bar_d10 = filter_by_uom_and_district(df_imms_2023a, 10)\n",
    "df_imms_2023a_bar_d11 = filter_by_uom_and_district(df_imms_2023a, 11)\n",
    "df_imms_2023a_bar_d12 = filter_by_uom_and_district(df_imms_2023a, 12)\n",
    "\n",
    "\n",
    "# check table dim\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D1) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d1.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D2) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d2.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D3) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d3.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D4) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d4.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D5) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d5.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D6) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d6.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D7) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d7.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D8) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d8.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D9) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d9.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D10) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d10.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D11) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d11.shape , '\\n')\n",
    "# print('*** Table Dimensions: Remove sweeping CY values (D12) ***', '\\n')\n",
    "# print(df_imms_2023a_bar_d12.shape , '\\n')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac005 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac005 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac005 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac005 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac005 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac005 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"03-SAC-005\")\n",
    "]\n",
    "df_imms_2024b_hotspot_03sac005 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"03-SAC-005\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_03sac005 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"03-SAC-005\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac005, 'Data Profile: IMMS 2021b - 03sac005')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac005, 'Data Profile: IMMS 2022a - 03sac005')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac005, 'Data Profile: IMMS 2022b - 03sac005')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac005, 'Data Profile: IMMS 2023a - 03sac005')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac005, 'Data Profile: IMMS 2023b - 03sac005')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac005, 'Data Profile: IMMS 2024a - 03sac005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac005 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_03sac005,\n",
    "        df_imms_2022a_hotspot_03sac005,\n",
    "        df_imms_2022b_hotspot_03sac005,\n",
    "        df_imms_2023a_hotspot_03sac005,\n",
    "        df_imms_2023b_hotspot_03sac005,\n",
    "        df_imms_2024a_hotspot_03sac005,\n",
    "        df_imms_2024b_hotspot_03sac005, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_03sac005, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_03sac005, 'Data Profile: IMMS Litter Hotspot - 03sac005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac050 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac050 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac050 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac050 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac050 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac050 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"03-SAC-050\")\n",
    "]\n",
    "df_imms_2024b_hotspot_03sac050 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"03-SAC-050\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_03sac050 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"03-SAC-050\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac050, 'Data Profile: IMMS 2021b - 03sac050')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac050, 'Data Profile: IMMS 2022a - 03sac050')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac050, 'Data Profile: IMMS 2022b - 03sac050')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac050, 'Data Profile: IMMS 2023a - 03sac050')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac050, 'Data Profile: IMMS 2023b - 03sac050')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac050, 'Data Profile: IMMS 2024a - 03sac050')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac050 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_03sac050,\n",
    "        df_imms_2022a_hotspot_03sac050,\n",
    "        df_imms_2022b_hotspot_03sac050,\n",
    "        df_imms_2023a_hotspot_03sac050,\n",
    "        df_imms_2023b_hotspot_03sac050,\n",
    "        df_imms_2024a_hotspot_03sac050,\n",
    "        df_imms_2024b_hotspot_03sac050, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_03sac050, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_03sac050, 'Data Profile: IMMS Litter Hotspot - 03sac050')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_03sac080 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2022a_hotspot_03sac080 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2022b_hotspot_03sac080 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2023a_hotspot_03sac080 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2023b_hotspot_03sac080 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2024a_hotspot_03sac080 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"03-SAC-080\")\n",
    "]\n",
    "df_imms_2024b_hotspot_03sac080 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"03-SAC-080\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_03sac080 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"03-SAC-080\") # Added by NS 6/17/2025\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_03sac080, 'Data Profile: IMMS 2021b - 03sac080')\n",
    "# data_profile(df_imms_2022a_hotspot_03sac080, 'Data Profile: IMMS 2022a - 03sac080')\n",
    "# data_profile(df_imms_2022b_hotspot_03sac080, 'Data Profile: IMMS 2022b - 03sac080')\n",
    "# data_profile(df_imms_2023a_hotspot_03sac080, 'Data Profile: IMMS 2023a - 03sac080')\n",
    "# data_profile(df_imms_2023b_hotspot_03sac080, 'Data Profile: IMMS 2023b - 03sac080')\n",
    "# data_profile(df_imms_2024a_hotspot_03sac080, 'Data Profile: IMMS 2024a - 03sac080')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_03sac080 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_03sac080,\n",
    "        df_imms_2022a_hotspot_03sac080,\n",
    "        df_imms_2022b_hotspot_03sac080,\n",
    "        df_imms_2023a_hotspot_03sac080,\n",
    "        df_imms_2023b_hotspot_03sac080,\n",
    "        df_imms_2024a_hotspot_03sac080,\n",
    "        df_imms_2024b_hotspot_03sac080, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_03sac080, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_03sac080, 'Data Profile: IMMS Litter Hotspot - 03sac080')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala580b = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala580b = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala580b = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala580b = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala580b = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala580b = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-ALA-580B\")\n",
    "]\n",
    "df_imms_2024b_hotspot_04ala580b = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"04-ALA-580B\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_04ala580b = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"04-ALA-580B\") # Added by NS 6/17/2025\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala580b, 'Data Profile: IMMS 2021b - 04ala580b')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala580b, 'Data Profile: IMMS 2022a - 04ala580b')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala580b, 'Data Profile: IMMS 2022b - 04ala580b')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala580b, 'Data Profile: IMMS 2023a - 04ala580b')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala580b, 'Data Profile: IMMS 2023b - 04ala580b')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala580b, 'Data Profile: IMMS 2024a - 04ala580b')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala580b = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04ala580b,\n",
    "        df_imms_2022a_hotspot_04ala580b,\n",
    "        df_imms_2022b_hotspot_04ala580b,\n",
    "        df_imms_2023a_hotspot_04ala580b,\n",
    "        df_imms_2023b_hotspot_04ala580b,\n",
    "        df_imms_2024a_hotspot_04ala580b,\n",
    "        df_imms_2024b_hotspot_04ala580b, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_04ala580b, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04ala580b, 'Data Profile: IMMS Litter Hotspot - 04ala580b')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala680 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala680 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala680 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala680 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala680 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala680 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-ALA-680\")\n",
    "]\n",
    "df_imms_2024b_hotspot_04ala680 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"04-ALA-680\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_04ala680 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"04-ALA-680\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala680, 'Data Profile: IMMS 2021b - 04ala680')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala680, 'Data Profile: IMMS 2022a - 04ala680')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala680, 'Data Profile: IMMS 2022b - 04ala680')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala680, 'Data Profile: IMMS 2023a - 04ala680')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala680, 'Data Profile: IMMS 2023b - 04ala680')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala680, 'Data Profile: IMMS 2024a - 04ala680')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala680 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04ala680,\n",
    "        df_imms_2022a_hotspot_04ala680,\n",
    "        df_imms_2022b_hotspot_04ala680,\n",
    "        df_imms_2023a_hotspot_04ala680,\n",
    "        df_imms_2023b_hotspot_04ala680,\n",
    "        df_imms_2024a_hotspot_04ala680,\n",
    "        df_imms_2024b_hotspot_04ala680, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_04ala680, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04ala680, 'Data Profile: IMMS Litter Hotspot - 04ala680')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04ala880 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04ala880 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04ala880 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04ala880 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04ala880 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04ala880 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-ALA-880\")\n",
    "]\n",
    "df_imms_2024b_hotspot_04ala880 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"04-ALA-880\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_04ala880 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"04-ALA-880\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04ala880, 'Data Profile: IMMS 2021b - 04ala880')\n",
    "# data_profile(df_imms_2022a_hotspot_04ala880, 'Data Profile: IMMS 2022a - 04ala880')\n",
    "# data_profile(df_imms_2022b_hotspot_04ala880, 'Data Profile: IMMS 2022b - 04ala880')\n",
    "# data_profile(df_imms_2023a_hotspot_04ala880, 'Data Profile: IMMS 2023a - 04ala880')\n",
    "# data_profile(df_imms_2023b_hotspot_04ala880, 'Data Profile: IMMS 2023b - 04ala880')\n",
    "# data_profile(df_imms_2024a_hotspot_04ala880, 'Data Profile: IMMS 2024a - 04ala880')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04ala880 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04ala880,\n",
    "        df_imms_2022a_hotspot_04ala880,\n",
    "        df_imms_2022b_hotspot_04ala880,\n",
    "        df_imms_2023a_hotspot_04ala880,\n",
    "        df_imms_2023b_hotspot_04ala880,\n",
    "        df_imms_2024a_hotspot_04ala880,\n",
    "        df_imms_2024b_hotspot_04ala880, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_04ala880, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04ala880, 'Data Profile: IMMS Litter Hotspot - 04ala880')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04cc004a = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04cc004a = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04cc004a = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04cc004a = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04cc004a = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04cc004a = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-CC-004A\")\n",
    "]\n",
    "df_imms_2024b_hotspot_04cc004a = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"04-CC-004A\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_04cc004a = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"04-CC-004A\") # Added by NS 6/17/2025\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04cc004a, 'Data Profile: IMMS 2021b - 04cc004a')\n",
    "# data_profile(df_imms_2022a_hotspot_04cc004a, 'Data Profile: IMMS 2022a - 04cc004a')\n",
    "# data_profile(df_imms_2022b_hotspot_04cc004a, 'Data Profile: IMMS 2022b - 04cc004a')\n",
    "# data_profile(df_imms_2023a_hotspot_04cc004a, 'Data Profile: IMMS 2023a - 04cc004a')\n",
    "# data_profile(df_imms_2023b_hotspot_04cc004a, 'Data Profile: IMMS 2023b - 04cc004a')\n",
    "# data_profile(df_imms_2024a_hotspot_04cc004a, 'Data Profile: IMMS 2024a - 04cc004a')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04cc004a = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04cc004a,\n",
    "        df_imms_2022a_hotspot_04cc004a,\n",
    "        df_imms_2022b_hotspot_04cc004a,\n",
    "        df_imms_2023a_hotspot_04cc004a,\n",
    "        df_imms_2023b_hotspot_04cc004a,\n",
    "        df_imms_2024a_hotspot_04cc004a,\n",
    "        df_imms_2024b_hotspot_04cc004a, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_04cc004a, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04cc004a, 'Data Profile: IMMS Litter Hotspot - 04cc004a')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_04cc680 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2022a_hotspot_04cc680 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2022b_hotspot_04cc680 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2023a_hotspot_04cc680 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2023b_hotspot_04cc680 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2024a_hotspot_04cc680 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"04-CC-680\")\n",
    "]\n",
    "df_imms_2024b_hotspot_04cc680 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"04-CC-680\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_04cc680 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"04-CC-680\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_04cc680, 'Data Profile: IMMS 2021b - 04cc680')\n",
    "# data_profile(df_imms_2022a_hotspot_04cc680, 'Data Profile: IMMS 2022a - 04cc680')\n",
    "# data_profile(df_imms_2022b_hotspot_04cc680, 'Data Profile: IMMS 2022b - 04cc680')\n",
    "# data_profile(df_imms_2023a_hotspot_04cc680, 'Data Profile: IMMS 2023a - 04cc680')\n",
    "# data_profile(df_imms_2023b_hotspot_04cc680, 'Data Profile: IMMS 2023b - 04cc680')\n",
    "# data_profile(df_imms_2024a_hotspot_04cc680, 'Data Profile: IMMS 2024a - 04cc680')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_04cc680 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_04cc680,\n",
    "        df_imms_2022a_hotspot_04cc680,\n",
    "        df_imms_2022b_hotspot_04cc680,\n",
    "        df_imms_2023a_hotspot_04cc680,\n",
    "        df_imms_2023b_hotspot_04cc680,\n",
    "        df_imms_2024a_hotspot_04cc680,\n",
    "        df_imms_2024b_hotspot_04cc680, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_04cc680, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_04cc680, 'Data Profile: IMMS Litter Hotspot - 04cc680')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_06fre099 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2022a_hotspot_06fre099 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2022b_hotspot_06fre099 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2023a_hotspot_06fre099 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2023b_hotspot_06fre099 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2024a_hotspot_06fre099 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"06-FRE-099\")\n",
    "]\n",
    "df_imms_2024b_hotspot_06fre099 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"06-FRE-099\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_06fre099 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"06-FRE-099\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_06fre099, 'Data Profile: IMMS 2021b - 06fre099')\n",
    "# data_profile(df_imms_2022a_hotspot_06fre099, 'Data Profile: IMMS 2022a - 06fre099')\n",
    "# data_profile(df_imms_2022b_hotspot_06fre099, 'Data Profile: IMMS 2022b - 06fre099')\n",
    "# data_profile(df_imms_2023a_hotspot_06fre099, 'Data Profile: IMMS 2023a - 06fre099')\n",
    "# data_profile(df_imms_2023b_hotspot_06fre099, 'Data Profile: IMMS 2023b - 06fre099')\n",
    "# data_profile(df_imms_2024a_hotspot_06fre099, 'Data Profile: IMMS 2024a - 06fre099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_06fre099 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_06fre099,\n",
    "        df_imms_2022a_hotspot_06fre099,\n",
    "        df_imms_2022b_hotspot_06fre099,\n",
    "        df_imms_2023a_hotspot_06fre099,\n",
    "        df_imms_2023b_hotspot_06fre099,\n",
    "        df_imms_2024a_hotspot_06fre099,\n",
    "        df_imms_2024b_hotspot_06fre099, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_06fre099, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_06fre099, 'Data Profile: IMMS Litter Hotspot - 06fre099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_06ker099 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2022a_hotspot_06ker099 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2022b_hotspot_06ker099 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2023a_hotspot_06ker099 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2023b_hotspot_06ker099 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2024a_hotspot_06ker099 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"06-KER-099\")\n",
    "]\n",
    "df_imms_2024b_hotspot_06ker099 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"06-KER-099\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_06ker099 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"06-KER-099\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_06ker099, 'Data Profile: IMMS 2021b - 06ker099')\n",
    "# data_profile(df_imms_2022a_hotspot_06ker099, 'Data Profile: IMMS 2022a - 06ker099')\n",
    "# data_profile(df_imms_2022b_hotspot_06ker099, 'Data Profile: IMMS 2022b - 06ker099')\n",
    "# data_profile(df_imms_2023a_hotspot_06ker099, 'Data Profile: IMMS 2023a - 06ker099')\n",
    "# data_profile(df_imms_2023b_hotspot_06ker099, 'Data Profile: IMMS 2023b - 06ker099')\n",
    "# data_profile(df_imms_2024a_hotspot_06ker099, 'Data Profile: IMMS 2024a - 06ker099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_06ker099 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_06ker099,\n",
    "        df_imms_2022a_hotspot_06ker099,\n",
    "        df_imms_2022b_hotspot_06ker099,\n",
    "        df_imms_2023a_hotspot_06ker099,\n",
    "        df_imms_2023b_hotspot_06ker099,\n",
    "        df_imms_2024a_hotspot_06ker099,\n",
    "        df_imms_2024b_hotspot_06ker099, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_06ker099, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_06ker099, 'Data Profile: IMMS Litter Hotspot - 06ker099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la005a = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la005a = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la005a = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la005a = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la005a = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la005a = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-005A\")\n",
    "]\n",
    "df_imms_2024b_hotspot_07la005a = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"07-LA-005A\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_07la005a = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"07-LA-005A\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la005a, 'Data Profile: IMMS 2021b - 07la005a')\n",
    "# data_profile(df_imms_2022a_hotspot_07la005a, 'Data Profile: IMMS 2022a - 07la005a')\n",
    "# data_profile(df_imms_2022b_hotspot_07la005a, 'Data Profile: IMMS 2022b - 07la005a')\n",
    "# data_profile(df_imms_2023a_hotspot_07la005a, 'Data Profile: IMMS 2023a - 07la005a')\n",
    "# data_profile(df_imms_2023b_hotspot_07la005a, 'Data Profile: IMMS 2023b - 07la005a')\n",
    "# data_profile(df_imms_2024a_hotspot_07la005a, 'Data Profile: IMMS 2024a - 07la005a')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la005a = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la005a,\n",
    "        df_imms_2022a_hotspot_07la005a,\n",
    "        df_imms_2022b_hotspot_07la005a,\n",
    "        df_imms_2023a_hotspot_07la005a,\n",
    "        df_imms_2023b_hotspot_07la005a,\n",
    "        df_imms_2024a_hotspot_07la005a,\n",
    "        df_imms_2024b_hotspot_07la005a, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_07la005a, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la005a, 'Data Profile: IMMS Litter Hotspot - 07la005a')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la010 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la010 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la010 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la010 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la010 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la010 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-010\")\n",
    "]\n",
    "df_imms_2024b_hotspot_07la010 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"07-LA-010\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_07la010 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"07-LA-010\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la010, 'Data Profile: IMMS 2021b - 07la010')\n",
    "# data_profile(df_imms_2022a_hotspot_07la010, 'Data Profile: IMMS 2022a - 07la010')\n",
    "# data_profile(df_imms_2022b_hotspot_07la010, 'Data Profile: IMMS 2022b - 07la010')\n",
    "# data_profile(df_imms_2023a_hotspot_07la010, 'Data Profile: IMMS 2023a - 07la010')\n",
    "# data_profile(df_imms_2023b_hotspot_07la010, 'Data Profile: IMMS 2023b - 07la010')\n",
    "# data_profile(df_imms_2024a_hotspot_07la010, 'Data Profile: IMMS 2024a - 07la010')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la010 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la010,\n",
    "        df_imms_2022a_hotspot_07la010,\n",
    "        df_imms_2022b_hotspot_07la010,\n",
    "        df_imms_2023a_hotspot_07la010,\n",
    "        df_imms_2023b_hotspot_07la010,\n",
    "        df_imms_2024a_hotspot_07la010,\n",
    "        df_imms_2024b_hotspot_07la010, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_07la010, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la010, 'Data Profile: IMMS Litter Hotspot - 07la010')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la101 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la101 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la101 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la101 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la101 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la101 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-101\")\n",
    "]\n",
    "df_imms_2024b_hotspot_07la101 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"07-LA-101\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_07la101 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"07-LA-101\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la101, 'Data Profile: IMMS 2021b - 07la101')\n",
    "# data_profile(df_imms_2022a_hotspot_07la101, 'Data Profile: IMMS 2022a - 07la101')\n",
    "# data_profile(df_imms_2022b_hotspot_07la101, 'Data Profile: IMMS 2022b - 07la101')\n",
    "# data_profile(df_imms_2023a_hotspot_07la101, 'Data Profile: IMMS 2023a - 07la101')\n",
    "# data_profile(df_imms_2023b_hotspot_07la101, 'Data Profile: IMMS 2023b - 07la101')\n",
    "# data_profile(df_imms_2024a_hotspot_07la101, 'Data Profile: IMMS 2024a - 07la101')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la101 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la101,\n",
    "        df_imms_2022a_hotspot_07la101,\n",
    "        df_imms_2022b_hotspot_07la101,\n",
    "        df_imms_2023a_hotspot_07la101,\n",
    "        df_imms_2023b_hotspot_07la101,\n",
    "        df_imms_2024a_hotspot_07la101,\n",
    "        df_imms_2024b_hotspot_07la101, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_07la101, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la101, 'Data Profile: IMMS Litter Hotspot - 07la101')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la110 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la110 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la110 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la110 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la110 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la110 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-110\")\n",
    "]\n",
    "df_imms_2024b_hotspot_07la110 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"07-LA-110\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_07la110 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"07-LA-110\") # Added by NS 6/17/2025\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la110, 'Data Profile: IMMS 2021b - 07la110')\n",
    "# data_profile(df_imms_2022a_hotspot_07la110, 'Data Profile: IMMS 2022a - 07la110')\n",
    "# data_profile(df_imms_2022b_hotspot_07la110, 'Data Profile: IMMS 2022b - 07la110')\n",
    "# data_profile(df_imms_2023a_hotspot_07la110, 'Data Profile: IMMS 2023a - 07la110')\n",
    "# data_profile(df_imms_2023b_hotspot_07la110, 'Data Profile: IMMS 2023b - 07la110')\n",
    "# data_profile(df_imms_2024a_hotspot_07la110, 'Data Profile: IMMS 2024a - 07la110')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la110 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la110,\n",
    "        df_imms_2022a_hotspot_07la110,\n",
    "        df_imms_2022b_hotspot_07la110,\n",
    "        df_imms_2023a_hotspot_07la110,\n",
    "        df_imms_2023b_hotspot_07la110,\n",
    "        df_imms_2024a_hotspot_07la110,\n",
    "        df_imms_2024b_hotspot_07la110, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_07la110, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la110, 'Data Profile: IMMS Litter Hotspot - 07la110')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_07la405 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2022a_hotspot_07la405 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2022b_hotspot_07la405 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2023a_hotspot_07la405 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2023b_hotspot_07la405 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2024a_hotspot_07la405 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"07-LA-405\")\n",
    "]\n",
    "df_imms_2024b_hotspot_07la405 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"07-LA-405\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_07la405 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"07-LA-405\") # Added by NS 6/17/2025\n",
    "]\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_07la405, 'Data Profile: IMMS 2021b - 07la405')\n",
    "# data_profile(df_imms_2022a_hotspot_07la405, 'Data Profile: IMMS 2022a - 07la405')\n",
    "# data_profile(df_imms_2022b_hotspot_07la405, 'Data Profile: IMMS 2022b - 07la405')\n",
    "# data_profile(df_imms_2023a_hotspot_07la405, 'Data Profile: IMMS 2023a - 07la405')\n",
    "# data_profile(df_imms_2023b_hotspot_07la405, 'Data Profile: IMMS 2023b - 07la405')\n",
    "# data_profile(df_imms_2024a_hotspot_07la405, 'Data Profile: IMMS 2024a - 07la405')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_07la405 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_07la405,\n",
    "        df_imms_2022a_hotspot_07la405,\n",
    "        df_imms_2022b_hotspot_07la405,\n",
    "        df_imms_2023a_hotspot_07la405,\n",
    "        df_imms_2023b_hotspot_07la405,\n",
    "        df_imms_2024a_hotspot_07la405,\n",
    "        df_imms_2024b_hotspot_07la405, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_07la405, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_07la405, 'Data Profile: IMMS Litter Hotspot - 07la405')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_08riv010 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2022a_hotspot_08riv010 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2022b_hotspot_08riv010 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2023a_hotspot_08riv010 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2023b_hotspot_08riv010 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2024a_hotspot_08riv010 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"08-RIV-010\")\n",
    "]\n",
    "df_imms_2024b_hotspot_08riv010 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"08-RIV-010\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_08riv010 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"08-RIV-010\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_08riv010, 'Data Profile: IMMS 2021b - 08riv010')\n",
    "# data_profile(df_imms_2022a_hotspot_08riv010, 'Data Profile: IMMS 2022a - 08riv010')\n",
    "# data_profile(df_imms_2022b_hotspot_08riv010, 'Data Profile: IMMS 2022b - 08riv010')\n",
    "# data_profile(df_imms_2023a_hotspot_08riv010, 'Data Profile: IMMS 2023a - 08riv010')\n",
    "# data_profile(df_imms_2023b_hotspot_08riv010, 'Data Profile: IMMS 2023b - 08riv010')\n",
    "# data_profile(df_imms_2024a_hotspot_08riv010, 'Data Profile: IMMS 2024a - 08riv010')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_08riv010 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_08riv010,\n",
    "        df_imms_2022a_hotspot_08riv010,\n",
    "        df_imms_2022b_hotspot_08riv010,\n",
    "        df_imms_2023a_hotspot_08riv010,\n",
    "        df_imms_2023b_hotspot_08riv010,\n",
    "        df_imms_2024a_hotspot_08riv010,\n",
    "        df_imms_2024b_hotspot_08riv010, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_08riv010, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_08riv010, 'Data Profile: IMMS Litter Hotspot - 08riv010')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_08riv060 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2022a_hotspot_08riv060 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2022b_hotspot_08riv060 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2023a_hotspot_08riv060 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2023b_hotspot_08riv060 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2024a_hotspot_08riv060 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"08-RIV-060\")\n",
    "]\n",
    "df_imms_2024b_hotspot_08riv060 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"08-RIV-060\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_08riv060 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"08-RIV-060\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_08riv060, 'Data Profile: IMMS 2021b - 08riv060')\n",
    "# data_profile(df_imms_2022a_hotspot_08riv060, 'Data Profile: IMMS 2022a - 08riv060')\n",
    "# data_profile(df_imms_2022b_hotspot_08riv060, 'Data Profile: IMMS 2022b - 08riv060')\n",
    "# data_profile(df_imms_2023a_hotspot_08riv060, 'Data Profile: IMMS 2023a - 08riv060')\n",
    "# data_profile(df_imms_2023b_hotspot_08riv060, 'Data Profile: IMMS 2023b - 08riv060')\n",
    "# data_profile(df_imms_2024a_hotspot_08riv060, 'Data Profile: IMMS 2024a - 08riv060')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_08riv060 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_08riv060,\n",
    "        df_imms_2022a_hotspot_08riv060,\n",
    "        df_imms_2022b_hotspot_08riv060,\n",
    "        df_imms_2023a_hotspot_08riv060,\n",
    "        df_imms_2023b_hotspot_08riv060,\n",
    "        df_imms_2024a_hotspot_08riv060,\n",
    "        df_imms_2024b_hotspot_08riv060, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_08riv060, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_08riv060, 'Data Profile: IMMS Litter Hotspot - 08riv060')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_10sj005 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2022a_hotspot_10sj005 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2022b_hotspot_10sj005 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2023a_hotspot_10sj005 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2023b_hotspot_10sj005 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2024a_hotspot_10sj005 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"10-SJ-005\")\n",
    "]\n",
    "df_imms_2024b_hotspot_10sj005 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"10-SJ-005\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_10sj005 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"10-SJ-005\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_10sj005, 'Data Profile: IMMS 2021b - 10sj005')\n",
    "# data_profile(df_imms_2022a_hotspot_10sj005, 'Data Profile: IMMS 2022a - 10sj005')\n",
    "# data_profile(df_imms_2022b_hotspot_10sj005, 'Data Profile: IMMS 2022b - 10sj005')\n",
    "# data_profile(df_imms_2023a_hotspot_10sj005, 'Data Profile: IMMS 2023a - 10sj005')\n",
    "# data_profile(df_imms_2023b_hotspot_10sj005, 'Data Profile: IMMS 2023b - 10sj005')\n",
    "# data_profile(df_imms_2024a_hotspot_10sj005, 'Data Profile: IMMS 2024a - 10sj005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_10sj005 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_10sj005,\n",
    "        df_imms_2022a_hotspot_10sj005,\n",
    "        df_imms_2022b_hotspot_10sj005,\n",
    "        df_imms_2023a_hotspot_10sj005,\n",
    "        df_imms_2023b_hotspot_10sj005,\n",
    "        df_imms_2024a_hotspot_10sj005,\n",
    "        df_imms_2024b_hotspot_10sj005, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_10sj005, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_10sj005, 'Data Profile: IMMS Litter Hotspot - 10sj005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_10sj099 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2022a_hotspot_10sj099 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2022b_hotspot_10sj099 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2023a_hotspot_10sj099 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2023b_hotspot_10sj099 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2024a_hotspot_10sj099 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"10-SJ-099\")\n",
    "]\n",
    "df_imms_2024b_hotspot_10sj099 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"10-SJ-099\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_10sj099 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"10-SJ-099\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_10sj099, 'Data Profile: IMMS 2021b - 10sj099')\n",
    "# data_profile(df_imms_2022a_hotspot_10sj099, 'Data Profile: IMMS 2022a - 10sj099')\n",
    "# data_profile(df_imms_2022b_hotspot_10sj099, 'Data Profile: IMMS 2022b - 10sj099')\n",
    "# data_profile(df_imms_2023a_hotspot_10sj099, 'Data Profile: IMMS 2023a - 10sj099')\n",
    "# data_profile(df_imms_2023b_hotspot_10sj099, 'Data Profile: IMMS 2023b - 10sj099')\n",
    "# data_profile(df_imms_2024a_hotspot_10sj099, 'Data Profile: IMMS 2024a - 10sj099')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_10sj099 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_10sj099,\n",
    "        df_imms_2022a_hotspot_10sj099,\n",
    "        df_imms_2022b_hotspot_10sj099,\n",
    "        df_imms_2023a_hotspot_10sj099,\n",
    "        df_imms_2023b_hotspot_10sj099,\n",
    "        df_imms_2024a_hotspot_10sj099,\n",
    "        df_imms_2024b_hotspot_10sj099, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_10sj099, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_10sj099, 'Data Profile: IMMS Litter Hotspot - 10sj099')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_11sd005 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2022a_hotspot_11sd005 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2022b_hotspot_11sd005 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2023a_hotspot_11sd005 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2023b_hotspot_11sd005 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2024a_hotspot_11sd005 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"11-SD-005\")\n",
    "]\n",
    "df_imms_2024b_hotspot_11sd005 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"11-SD-005\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_11sd005 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"11-SD-005\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_11sd005, 'Data Profile: IMMS 2021b - 11sd005')\n",
    "# data_profile(df_imms_2022a_hotspot_11sd005, 'Data Profile: IMMS 2022a - 11sd005')\n",
    "# data_profile(df_imms_2022b_hotspot_11sd005, 'Data Profile: IMMS 2022b - 11sd005')\n",
    "# data_profile(df_imms_2023a_hotspot_11sd005, 'Data Profile: IMMS 2023a - 11sd005')\n",
    "# data_profile(df_imms_2023b_hotspot_11sd005, 'Data Profile: IMMS 2023b - 11sd005')\n",
    "# data_profile(df_imms_2024a_hotspot_11sd005, 'Data Profile: IMMS 2024a - 11sd005')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_11sd005 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_11sd005,\n",
    "        df_imms_2022a_hotspot_11sd005,\n",
    "        df_imms_2022b_hotspot_11sd005,\n",
    "        df_imms_2023a_hotspot_11sd005,\n",
    "        df_imms_2023b_hotspot_11sd005,\n",
    "        df_imms_2024a_hotspot_11sd005,\n",
    "        df_imms_2024b_hotspot_11sd005, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_11sd005, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_11sd005, 'Data Profile: IMMS Litter Hotspot - 11sd005')\n",
    "\n",
    "# filter litter hotspot corridors based on litter/los/csr data\n",
    "# https://www.geeksforgeeks.org/filter-pandas-dataframe-with-multiple-conditions/\n",
    "df_imms_2021b_hotspot_11sd805 = df_imms_2021b[\n",
    "    (df_imms_2021b[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2022a_hotspot_11sd805 = df_imms_2022a[\n",
    "    (df_imms_2022a[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2022b_hotspot_11sd805 = df_imms_2022b[\n",
    "    (df_imms_2022b[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2023a_hotspot_11sd805 = df_imms_2023a[\n",
    "    (df_imms_2023a[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2023b_hotspot_11sd805 = df_imms_2023b[\n",
    "    (df_imms_2023b[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2024a_hotspot_11sd805 = df_imms_2024a[\n",
    "    (df_imms_2024a[\"IMMS Unit ID\"] == \"11-SD-805\")\n",
    "]\n",
    "df_imms_2024b_hotspot_11sd805 = df_imms_2024b[\n",
    "    (df_imms_2024b[\"IMMS Unit ID\"] == \"11-SD-805\") # Added by NS 6/17/2025\n",
    "]\n",
    "df_imms_2025a_hotspot_11sd805 = df_imms_2025a[\n",
    "    (df_imms_2025a[\"IMMS Unit ID\"] == \"11-SD-805\") # Added by NS 6/17/2025\n",
    "]\n",
    "\n",
    "# check filter results\n",
    "# data_profile(df_imms_2021b_hotspot_11sd805, 'Data Profile: IMMS 2021b - 11sd805')\n",
    "# data_profile(df_imms_2022a_hotspot_11sd805, 'Data Profile: IMMS 2022a - 11sd805')\n",
    "# data_profile(df_imms_2022b_hotspot_11sd805, 'Data Profile: IMMS 2022b - 11sd805')\n",
    "# data_profile(df_imms_2023a_hotspot_11sd805, 'Data Profile: IMMS 2023a - 11sd805')\n",
    "# data_profile(df_imms_2023b_hotspot_11sd805, 'Data Profile: IMMS 2023b - 11sd805')\n",
    "# data_profile(df_imms_2024a_hotspot_11sd805, 'Data Profile: IMMS 2024a - 11sd805')\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_11sd805 = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b_hotspot_11sd805,\n",
    "        df_imms_2022a_hotspot_11sd805,\n",
    "        df_imms_2022b_hotspot_11sd805,\n",
    "        df_imms_2023a_hotspot_11sd805,\n",
    "        df_imms_2023b_hotspot_11sd805,\n",
    "        df_imms_2024a_hotspot_11sd805,\n",
    "        df_imms_2024b_hotspot_11sd805, # Added by NS 6/17/2025\n",
    "        df_imms_2025a_hotspot_11sd805, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_11sd805, 'Data Profile: IMMS Litter Hotspot - 11sd805')\n",
    "\n",
    "# create dataframe with all hotspots for analysis\n",
    "# join dataframes together with vertical concat\n",
    "# https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "df_imms_hotspot_all = pd.concat(\n",
    "    [\n",
    "        df_imms_hotspot_03sac005,\n",
    "        df_imms_hotspot_03sac050,\n",
    "        df_imms_hotspot_03sac080,\n",
    "        df_imms_hotspot_04ala580b,\n",
    "        df_imms_hotspot_04ala680,\n",
    "        df_imms_hotspot_04ala880,\n",
    "        df_imms_hotspot_04cc004a,\n",
    "        df_imms_hotspot_04cc680,\n",
    "        df_imms_hotspot_06fre099,\n",
    "        df_imms_hotspot_06ker099,\n",
    "        df_imms_hotspot_07la005a,\n",
    "        df_imms_hotspot_07la010,\n",
    "        df_imms_hotspot_07la101,\n",
    "        df_imms_hotspot_07la110,\n",
    "        df_imms_hotspot_07la405,\n",
    "        df_imms_hotspot_08riv010,\n",
    "        df_imms_hotspot_08riv060,\n",
    "        df_imms_hotspot_11sd005,\n",
    "        df_imms_hotspot_11sd805,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(df_imms_hotspot_all, 'Data Profile: IMMS Litter Hotspot - Total')\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_count = (\n",
    "    df_imms_hotspot_all.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_count,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Activity Count'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_sum = df_imms_hotspot_all[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_sum = (\n",
    "    df_imms_hotspot_all_activity_sum.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_sum,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Activity Sum'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_cost = df_imms_hotspot_all[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_cost = (\n",
    "    df_imms_hotspot_all_activity_cost.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_cost,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Total Cost'\n",
    "# )\n",
    "\n",
    "# aggregate hotspots based on dist/county/route and work activity (total labor)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_hotspot_all_activity_labor = df_imms_hotspot_all[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"P.Y.s\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_hotspot_all_activity_labor = (\n",
    "    df_imms_hotspot_all_activity_labor.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "# preview results\n",
    "# data_profile(\n",
    "#     df_imms_hotspot_all_activity_labor,\n",
    "#     'Data Profile: IMMS Litter Hotspot - Total Labor'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6d372-0911-4f25-a295-e36a8e22205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.02.02 - data analysis for stacked charts (imms)\n",
    "\n",
    "# concatenate all time periods to analyze frequency/CY by district\n",
    "df_imms_all_periods = pd.concat(\n",
    "    [\n",
    "        df_imms_2021b,\n",
    "        df_imms_2022a,\n",
    "        df_imms_2022b,\n",
    "        df_imms_2023a,\n",
    "        df_imms_2023b,\n",
    "        df_imms_2024a,\n",
    "        df_imms_2024b, # Added by NS 6/17/2025\n",
    "        df_imms_2025a, # Added by NS 6/17/2025\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "# data_profile(\n",
    "#     df_imms_all_periods,\n",
    "#     'Data Profile: IMMS Litter Collection - All Periods'\n",
    "# )\n",
    "# subset dataframe by district\n",
    "df_imms_all_periods_d1 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 1)\n",
    "]\n",
    "# data_profile(\n",
    "#     df_imms_all_periods_d1,\n",
    "#     'Data Profile: IMMS Litter Collection - All Periods (D1)'\n",
    "# )\n",
    "df_imms_all_periods_d2 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 2)\n",
    "]\n",
    "df_imms_all_periods_d3 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 3)\n",
    "]\n",
    "df_imms_all_periods_d4 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 4)\n",
    "]\n",
    "df_imms_all_periods_d5 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 5)\n",
    "]\n",
    "df_imms_all_periods_d6 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 6)\n",
    "]\n",
    "df_imms_all_periods_d7 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 7)\n",
    "]\n",
    "df_imms_all_periods_d8 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 8)\n",
    "]\n",
    "df_imms_all_periods_d9 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 9)\n",
    "]\n",
    "df_imms_all_periods_d10 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 10)\n",
    "]\n",
    "df_imms_all_periods_d11 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 11)\n",
    "]\n",
    "df_imms_all_periods_d12 = df_imms_all_periods[\n",
    "    (df_imms_all_periods[\"Resp. District\"] == 12)\n",
    "]\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d1 = (\n",
    "    df_imms_all_periods_d1.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d2 = (\n",
    "    df_imms_all_periods_d2.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d3 = (\n",
    "    df_imms_all_periods_d3.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d4 = (\n",
    "    df_imms_all_periods_d4.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d5 = (\n",
    "    df_imms_all_periods_d5.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d6 = (\n",
    "    df_imms_all_periods_d6.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d7 = (\n",
    "    df_imms_all_periods_d7.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d8 = (\n",
    "    df_imms_all_periods_d8.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d9 = (\n",
    "    df_imms_all_periods_d9.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d10 = (\n",
    "    df_imms_all_periods_d10.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d11 = (\n",
    "    df_imms_all_periods_d11.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate districts based on dist/county/route and work activity (frequency)\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_count_d12 = (\n",
    "    df_imms_all_periods_d12.groupby([\"IMMS Unit ID\", \"Activity Description\"])\n",
    "    .size()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d1 = df_imms_all_periods_d1[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d1 = (\n",
    "    df_imms_all_periods_activity_sum_d1.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d2 = df_imms_all_periods_d2[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d2 = (\n",
    "    df_imms_all_periods_activity_sum_d2.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d3 = df_imms_all_periods_d3[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d3 = (\n",
    "    df_imms_all_periods_activity_sum_d3.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d4 = df_imms_all_periods_d4[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d4 = (\n",
    "    df_imms_all_periods_activity_sum_d4.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d5 = df_imms_all_periods_d5[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d5 = (\n",
    "    df_imms_all_periods_activity_sum_d5.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d6 = df_imms_all_periods_d6[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d6 = (\n",
    "    df_imms_all_periods_activity_sum_d6.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d7 = df_imms_all_periods_d7[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d7 = (\n",
    "    df_imms_all_periods_activity_sum_d7.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d8 = df_imms_all_periods_d8[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d8 = (\n",
    "    df_imms_all_periods_activity_sum_d8.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d9 = df_imms_all_periods_d9[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d9 = (\n",
    "    df_imms_all_periods_activity_sum_d9.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d10 = df_imms_all_periods_d10[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d10 = (\n",
    "    df_imms_all_periods_activity_sum_d10.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d11 = df_imms_all_periods_d11[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d11 = (\n",
    "    df_imms_all_periods_activity_sum_d11.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (litter totals)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_sum_d12 = df_imms_all_periods_d12[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Production Quantity\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_sum_d12 = (\n",
    "    df_imms_all_periods_activity_sum_d12.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d1 = df_imms_all_periods_d1[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d1 = (\n",
    "    df_imms_all_periods_activity_cost_d1.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d2 = df_imms_all_periods_d2[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d2 = (\n",
    "    df_imms_all_periods_activity_cost_d2.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d3 = df_imms_all_periods_d3[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d3 = (\n",
    "    df_imms_all_periods_activity_cost_d3.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d4 = df_imms_all_periods_d4[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d4 = (\n",
    "    df_imms_all_periods_activity_cost_d4.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d5 = df_imms_all_periods_d5[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d5 = (\n",
    "    df_imms_all_periods_activity_cost_d5.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d6 = df_imms_all_periods_d6[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d6 = (\n",
    "    df_imms_all_periods_activity_cost_d6.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d7 = df_imms_all_periods_d7[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d7 = (\n",
    "    df_imms_all_periods_activity_cost_d7.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d8 = df_imms_all_periods_d8[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d8 = (\n",
    "    df_imms_all_periods_activity_cost_d8.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d9 = df_imms_all_periods_d9[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d9 = (\n",
    "    df_imms_all_periods_activity_cost_d9.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d10 = df_imms_all_periods_d10[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d10 = (\n",
    "    df_imms_all_periods_activity_cost_d10.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d11 = df_imms_all_periods_d11[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d11 = (\n",
    "    df_imms_all_periods_activity_cost_d11.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# aggregate district based on dist/county/route and work activity (total cost)\n",
    "# subset dataframe before aggregation/sum\n",
    "df_imms_all_periods_activity_cost_d12 = df_imms_all_periods_d12[\n",
    "    [\"IMMS Unit ID\", \"Activity Description\", \"Total Cost\"]\n",
    "]\n",
    "# https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "df_imms_all_periods_activity_cost_d12 = (\n",
    "    df_imms_all_periods_activity_cost_d12.groupby(\n",
    "        [\"IMMS Unit ID\", \"Activity Description\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .unstack(\"Activity Description\")\n",
    ")\n",
    "\n",
    "# preview results\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d1,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D1)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d2,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D2)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d3,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D3)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d4,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D4)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d5,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D5)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d6,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D6)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d7,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D7)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d8,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D8)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d9,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D9)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d10,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D10)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d11,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D11)\",\n",
    ")\n",
    "data_profile(\n",
    "    df_imms_all_periods_activity_cost_d12,\n",
    "    \"Data Profile: IMMS Litter Collection - Activity Sum (D12)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73f0f5-0366-42f0-8aa7-9202556cca27",
   "metadata": {},
   "source": [
    "# Do I need to update this section? (CSRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad22598-be7e-4570-8db3-04c4ea3b7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 05.02.03 - data analysis (csr)\n",
    "\n",
    "# # format data for plotting\n",
    "\n",
    "\n",
    "\n",
    "# # NS, this next section was used to replace the previous section to get past an error\n",
    "# df_csr_2023a_bar_d1 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 1\n",
    "# ]\n",
    "# df_csr_2023a_bar_d2 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 2\n",
    "# ]\n",
    "# df_csr_2023a_bar_d3 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 3\n",
    "# ]\n",
    "# df_csr_2023a_bar_d4 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 4\n",
    "# ]\n",
    "# df_csr_2023a_bar_d5 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 5\n",
    "# ]\n",
    "# df_csr_2023a_bar_d6 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 6\n",
    "# ]\n",
    "# df_csr_2023a_bar_d7 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 7\n",
    "# ]\n",
    "# df_csr_2023a_bar_d8 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 8\n",
    "# ]\n",
    "# df_csr_2023a_bar_d9 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 9\n",
    "# ]\n",
    "# df_csr_2023a_bar_d10 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 10\n",
    "# ]\n",
    "# df_csr_2023a_bar_d11 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 11\n",
    "# ]\n",
    "# df_csr_2023a_bar_d12 = df_csr_2023a[\n",
    "#     df_csr_2023a[\"Responsible District\"].astype(int) == 12\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # concatenate all time periods for analysis\n",
    "# df_csr_all_periods = pd.concat(\n",
    "#     [\n",
    "#         df_csr_2021b,\n",
    "#         df_csr_2022a,\n",
    "#         df_csr_2022b,\n",
    "#         df_csr_2023a,\n",
    "#         df_csr_2023b,\n",
    "#         df_csr_2024a,\n",
    "#     ],\n",
    "#     axis=0,\n",
    "# )\n",
    "# data_profile(df_csr_all_periods, \"Data Profile: CSR - All Periods\")\n",
    "\n",
    "# # subset all periods by district\n",
    "# df_csr_all_periods_d1 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 1)\n",
    "# ]\n",
    "# df_csr_all_periods_d2 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 2)\n",
    "# ]\n",
    "# df_csr_all_periods_d3 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 3)\n",
    "# ]\n",
    "# df_csr_all_periods_d4 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 4)\n",
    "# ]\n",
    "# df_csr_all_periods_d5 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 5)\n",
    "# ]\n",
    "# df_csr_all_periods_d6 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 6)\n",
    "# ]\n",
    "# df_csr_all_periods_d7 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 7)\n",
    "# ]\n",
    "# df_csr_all_periods_d8 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 8)\n",
    "# ]\n",
    "# df_csr_all_periods_d9 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 9)\n",
    "# ]\n",
    "# df_csr_all_periods_d10 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 10)\n",
    "# ]\n",
    "# df_csr_all_periods_d11 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 11)\n",
    "# ]\n",
    "# df_csr_all_periods_d12 = df_csr_all_periods[\n",
    "#     (df_csr_all_periods[\"Responsible District\"] == 12)\n",
    "# ]\n",
    "\n",
    "# # aggregate total count based on dist/county/route\n",
    "# # https://stackoverflow.com/questions/19384532/get-statistics-for-each-group-such-as-count-mean-etc-using-pandas-groupby\n",
    "# df_csr_all_periods_route_count_d1 = (\n",
    "#     df_csr_all_periods_d1.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d2 = (\n",
    "#     df_csr_all_periods_d2.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d3 = (\n",
    "#     df_csr_all_periods_d3.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d4 = (\n",
    "#     df_csr_all_periods_d4.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d5 = (\n",
    "#     df_csr_all_periods_d5.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d6 = (\n",
    "#     df_csr_all_periods_d6.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d7 = (\n",
    "#     df_csr_all_periods_d7.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d8 = (\n",
    "#     df_csr_all_periods_d8.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d9 = (\n",
    "#     df_csr_all_periods_d9.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d10 = (\n",
    "#     df_csr_all_periods_d10.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d11 = (\n",
    "#     df_csr_all_periods_d11.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "# df_csr_all_periods_route_count_d12 = (\n",
    "#     df_csr_all_periods_d12.groupby([\"County\", \"Route\"]).size().unstack(\"Route\")\n",
    "# )\n",
    "\n",
    "# # preview results\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d1, \"Data Profile: CSR - Count by Route (D1)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d2, \"Data Profile: CSR - Count by Route (D2)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d3, \"Data Profile: CSR - Count by Route (D3)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d4, \"Data Profile: CSR - Count by Route (D4)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d5, \"Data Profile: CSR - Count by Route (D5)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d6, \"Data Profile: CSR - Count by Route (D6)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d7, \"Data Profile: CSR - Count by Route (D7)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d8, \"Data Profile: CSR - Count by Route (D8)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d9, \"Data Profile: CSR - Count by Route (D9)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d10, \"Data Profile: CSR - Count by Route (D10)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d11, \"Data Profile: CSR - Count by Route (D11)\"\n",
    "# )\n",
    "# data_profile(\n",
    "#     df_csr_all_periods_route_count_d12, \"Data Profile: CSR - Count by Route (D12)\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121b7a8-a96d-434d-adfc-9bff1dd82f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 05.07.01 - plot work activty counts by hotspot corridors\n",
    "\n",
    "# # note: dim convention = x, y\n",
    "# sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# # create stacked bar chart based on work activity count\n",
    "# # https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "# df_imms_hotspot_all_activity_count.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e78e6-d718-44de-972f-0257a2948d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 05.07.13 - plot work activity counts by litter hotspot\n",
    "\n",
    "# # note: dim convention = x, y\n",
    "# sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# # create stacked bar chart based on work activity count\n",
    "# # https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "# df_imms_hotspot_all_activity_count.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581b54e-4c67-4ffb-9f46-096568e499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.08.13 - plot work activity totals by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity sum\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_sum.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14634303-cc73-4bf6-9834-bee40ae42469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.13 - plot work activity cost by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_cost.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c97f1-9d3b-4d18-9905-7d7b445ef1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05.09.14 - plot work total labor by hotspot corridors\n",
    "\n",
    "# note: dim convention = x, y\n",
    "sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "# create stacked bar chart based on work activity cost\n",
    "# https://stackoverflow.com/questions/67805611/stacked-bar-plot-in-seaborn-with-groups\n",
    "df_imms_hotspot_all_activity_labor.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a10162-c302-484c-bcb6-969b21704f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualizations_to_pdf(df1, df2, df3, filename=\"work_activity_visuals.pdf\"):\n",
    "    \"\"\"\n",
    "    Create three stacked bar plots from input DataFrames and save them into a single PDF.\n",
    "\n",
    "    Parameters:\n",
    "        df1 (pd.DataFrame): Data for total work activity\n",
    "        df2 (pd.DataFrame): Data for labor totals\n",
    "        df3 (pd.DataFrame): Data for cost breakdown\n",
    "        filename (str): Output PDF filename\n",
    "    \"\"\"\n",
    "    sns.set_theme(rc={\"figure.figsize\": (20, 10)})\n",
    "\n",
    "    with PdfPages(filename) as pdf:\n",
    "        # Visualization 1\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        df1.plot.bar(stacked=True, ax=ax1)\n",
    "        ax1.set_title(\"Total Work Activity by Hotspot Corridors\")\n",
    "        ax1.set_ylabel(\"Work Activity Total\")\n",
    "        ax1.set_xlabel(\"Hotspot Corridors\")\n",
    "        pdf.savefig(fig1)\n",
    "        plt.close(fig1)\n",
    "\n",
    "        # Visualization 2\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        df2.plot.bar(stacked=True, ax=ax2)\n",
    "        ax2.set_title(\"Labor Totals by Hotspot Corridors\")\n",
    "        ax2.set_ylabel(\"Total Labor Cost\")\n",
    "        ax2.set_xlabel(\"Hotspot Corridors\")\n",
    "        pdf.savefig(fig2)\n",
    "        plt.close(fig2)\n",
    "\n",
    "        # Visualization 3\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        df3.plot.bar(stacked=True, ax=ax3)\n",
    "        ax3.set_title(\"Work Activity Cost by Hotspot Corridors\")\n",
    "        ax3.set_ylabel(\"Activity Cost\")\n",
    "        ax3.set_xlabel(\"Hotspot Corridors\")\n",
    "        pdf.savefig(fig3)\n",
    "        plt.close(fig3)\n",
    "\n",
    "    print(f\"PDF saved successfully as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81844ad7-c4ba-469e-b01d-6e4b37a97258",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_visualizations_to_pdf(\n",
    "    df_imms_hotspot_all_activity_sum,\n",
    "    df_imms_hotspot_all_activity_labor,\n",
    "    df_imms_hotspot_all_activity_cost,\n",
    "    filename=\"hotspot_work_summary.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae2cc4-538b-404c-9753-9345ec88e68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4685b-8a0d-4fdd-ba40-6fdcd9d8e10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
