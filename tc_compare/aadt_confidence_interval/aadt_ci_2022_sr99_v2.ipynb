{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35c3b37-f7e4-41e8-abf2-083155ea8641",
   "metadata": {},
   "source": [
    "# AADT Confidence Interval - Interstate 99\n",
    "\n",
    "## FHWA Links\n",
    "* Guidelines for Obtaining AADT Estimates from Non-Traditional Sources:\n",
    "    * https://www.fhwa.dot.gov/policyinformation/travel_monitoring/pubs/aadtnt/Guidelines_for_AADT_Estimates_Final.pdf\n",
    "  \n",
    "  \n",
    "## AADT Analysis Locations\n",
    "* 10 locations were used in the analysis\n",
    "* Locations were determined based on the location on installed & recording Traffic Operations cameras\n",
    "    * for additional information contact Zhenyu Zhu with Traffic Operations\n",
    "\n",
    "## Traffic Census Data\n",
    "* https://dot.ca.gov/programs/traffic-operations/census/traffic-volumes\n",
    "* Back AADT, Peak Month, and Peak Hour usually represents traffic South or West of the count location.  \n",
    "* Ahead AADT, Peak Month, and Peak Hour usually represents traffic North or East of the count location. Listing of routes with their designated  \n",
    "\n",
    "* Because the Back & Ahead counts are included at each location in the Traffic Census Data, (e.g., \"IRWINDALE, ARROW HIGHWAY\") only one [OBJECTID*] per location was pulled; for this analysis the North Bound Nodes were used for the analysis. \n",
    "    * for more information see the diagram: https://traffic.onramp.dot.ca.gov/downloads/traffic/files/performance/census/Back_and_Ahead_Leg_Traffic_Count_Diagram.pdf\n",
    "\n",
    "## StreetLight Analysis Data\n",
    "* StreetLight Locations on Interstate 99 are one-direction, each location will contain two points: northbound and southbound\n",
    "    * Analysis Type == Network Performance\n",
    "    * Segment Metrics\n",
    "    * 2022 was used to match currently available Traffic Census Data (as of 8/27/2025)\n",
    "    * pulled a variety of Day Types, but plan to just look at \"\"\"All Day Types\"\"\"\n",
    "    * pulled a variety of Day Parts, but plan to just look at \"\"\"All Day Parts\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171fa2b0-9b02-4947-a4d1-dd18ef86de42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5394f0e-d012-42ad-9286-c95948da43aa",
   "metadata": {},
   "source": [
    "### Pull in the Location Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6bce3a-11a1-4f2a-a7d9-eb7904946817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '{' on line 912 (sr99_tc_locations_utils.py, line 916)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\n\u001b[0;31m    from sr99_tc_locations_utils import sr_99_d3_tc_aadt_locations\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/big-data-geoanalytics/tc_compare/aadt_confidence_interval/sr99_tc_locations_utils.py:916\u001b[0;36m\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '{' on line 912\n"
     ]
    }
   ],
   "source": [
    "# pull in the coordinates from the utils docs\n",
    "#from osow_frp_o_d_utils_v3 import origin_intersections, destination_intersections\n",
    "from sr99_tc_locations_utils import sr_99_d3_tc_aadt_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0a612-d979-43d3-87f3-e8d69df16d42",
   "metadata": {},
   "source": [
    "### Identify the Google Cloud Storage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4826a9-4c1c-46e4-95c5-20c820351b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the GCS path to the data\n",
    "gcs_path = \"gs://calitp-analytics-data/data-analyses/big_data/compare_traffic_counts/sr99_d3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628fa29-7fdc-46d2-bc5a-84c271f150d9",
   "metadata": {},
   "source": [
    "### Pull in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c01657-5051-44da-b79f-594359c06427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will pull in the data and clean the column headers in a way that will make them easier to work with\n",
    "def getdata_and_cleanheaders(path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Clean column headers: remove spaces, convert to lowercase, and strip trailing asterisks\n",
    "    cleaned_columns = []\n",
    "    for column in df.columns:\n",
    "        cleaned_column = column.replace(\" \", \"\").lower().rstrip(\"*\")\n",
    "        cleaned_columns.append(cleaned_column)\n",
    "\n",
    "    df.columns = cleaned_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ea444-0d68-415c-beda-7ecdfe887062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pull in the data & create dataframes\n",
    "df_tc = getdata_and_cleanheaders(f\"{gcs_path}caltrans_traffic_census_2022.csv\")  # Traffic Census\n",
    "df_stl = getdata_and_cleanheaders(f\"{gcs_path}streetlight_sr99_d3_all_vehicles_2022_np.csv\")  # StreetLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b9a53-0066-4643-b8b7-ec90ceec2f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comparing\n",
    "df_tc.to_csv(\"df_tc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59259345-ec3c-47e8-bd2d-cf5059babf9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comparing\n",
    "df_stl.to_csv(\"df_stl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d877c99-b5fa-4b51-ac98-08b535e4d7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb279d3-f89a-43a1-9f9f-5a0d2ffb237c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eda593-1284-4445-8b5b-29c62f5ef789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1) Normalize your locations\n",
    "# ----------------------------\n",
    "def _ensure_list(x):\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return list(x)\n",
    "    return [x]\n",
    "\n",
    "def _gather_objectids(node_dict):\n",
    "    \"\"\"\n",
    "    Accepts a nodes[<direction>] dict and returns a list of objectids (as strings).\n",
    "    Handles 'objectid' and 'objectids' keys.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    if not isinstance(node_dict, dict):\n",
    "        return ids\n",
    "    if \"objectid\" in node_dict:\n",
    "        ids.extend(_ensure_list(node_dict[\"objectid\"]))\n",
    "    if \"objectids\" in node_dict:\n",
    "        ids.extend(_ensure_list(node_dict[\"objectids\"]))\n",
    "    return [str(i) for i in ids if i is not None and str(i).strip() != \"\"]\n",
    "\n",
    "def _gather_zones(node_dict):\n",
    "    \"\"\"\n",
    "    Returns (ahead_zones, behind_zones) lists from a nodes[<direction>] dict.\n",
    "    \"\"\"\n",
    "    ahead = _ensure_list(node_dict.get(\"zonename_ahead\", []))\n",
    "    behind = _ensure_list(node_dict.get(\"zonename_behind\", []))\n",
    "    return ahead, behind\n",
    "\n",
    "def _iter_locations(aadt_locations):\n",
    "    \"\"\"\n",
    "    Yields normalized location records:\n",
    "    {\n",
    "      'name': <location name>,\n",
    "      'daytype': <daytype string>,\n",
    "      'objectids': [list of str],\n",
    "      'ahead_zones': [list of str],\n",
    "      'behind_zones': [list of str]\n",
    "    }\n",
    "    Works whether aadt_locations is:\n",
    "      - a list with a single dict keyed by location names, or\n",
    "      - a list of location dicts, or\n",
    "      - a dict keyed by location names.\n",
    "    \"\"\"\n",
    "    if isinstance(aadt_locations, dict):\n",
    "        # dict keyed by location name\n",
    "        for name, loc in aadt_locations.items():\n",
    "            yield _normalize_one_location(name, loc)\n",
    "    elif isinstance(aadt_locations, list):\n",
    "        for item in aadt_locations:\n",
    "            if isinstance(item, dict) and \"nodes\" in item:\n",
    "                # this is a single location dict (not keyed by name)\n",
    "                name = item.get(\"location_description\") or item.get(\"name\") or \"UNKNOWN\"\n",
    "                yield _normalize_one_location(name, item)\n",
    "            elif isinstance(item, dict):\n",
    "                # dict keyed by location names\n",
    "                for name, loc in item.items():\n",
    "                    yield _normalize_one_location(name, loc)\n",
    "\n",
    "def _normalize_one_location(name, loc):\n",
    "    daytype = loc.get(\"daytype\", \"0: All Days (M-Su)\")\n",
    "    nodes = loc.get(\"nodes\", {}) or {}\n",
    "    all_ids, ahead, behind = [], [], []\n",
    "    for _, node in nodes.items():\n",
    "        all_ids.extend(_gather_objectids(node))\n",
    "        a, b = _gather_zones(node)\n",
    "        ahead.extend([z for z in a if z])\n",
    "        behind.extend([z for z in b if z])\n",
    "    # De-dup while preserving order\n",
    "    def _dedup(seq):\n",
    "        seen = set(); out = []\n",
    "        for x in seq:\n",
    "            if x not in seen:\n",
    "                out.append(x); seen.add(x)\n",
    "        return out\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"daytype\": daytype,\n",
    "        \"objectids\": _dedup(all_ids),\n",
    "        \"ahead_zones\": _dedup(ahead),\n",
    "        \"behind_zones\": _dedup(behind),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a0ab6-0c34-4195-8a53-a7fa226793ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 2) Traditional (Traffic Census) AADT for a location\n",
    "# ------------------------------------------------------\n",
    "def _traditional_aadt_for_ids(df_tc, obj_ids):\n",
    "    \"\"\"\n",
    "    Given df_tc and a list of objectids (strings), compute:\n",
    "      mean_ahead, mean_back, overall = (mean_ahead + mean_back) / 2\n",
    "    Returns (overall, mean_ahead, mean_back, count_used)\n",
    "    \"\"\"\n",
    "    if not obj_ids:\n",
    "        return np.nan, np.nan, np.nan, 0\n",
    "    sub = df_tc[df_tc[\"objectid\"].astype(str).isin(obj_ids)]\n",
    "    if sub.empty:\n",
    "        return np.nan, np.nan, np.nan, 0\n",
    "\n",
    "    # Expect columns 'ahead_aadt' and 'back_aadt'\n",
    "    ahead_vals = pd.to_numeric(sub.get(\"ahead_aadt\"), errors=\"coerce\").dropna()\n",
    "    back_vals  = pd.to_numeric(sub.get(\"back_aadt\"),  errors=\"coerce\").dropna()\n",
    "\n",
    "    mean_ahead = ahead_vals.mean() if not ahead_vals.empty else np.nan\n",
    "    mean_back  = back_vals.mean()  if not back_vals.empty  else np.nan\n",
    "\n",
    "    overall = np.nanmean([mean_ahead, mean_back])  # average of the two means\n",
    "    count_used = len(sub)\n",
    "    return overall, mean_ahead, mean_back, count_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8671e59-3d56-43aa-bada-8abb357e6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 3) StreetLight (Non-Traditional) AADT for a location\n",
    "# ------------------------------------------------------\n",
    "def _stl_aadt_for_zones(\n",
    "    df_stl, ahead_zones, behind_zones,\n",
    "    daytype=\"0: All Days (M-Su)\",\n",
    "    daypart=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel=None,\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute non-traditional AADT for a location as:\n",
    "       (mean(ahead_zones) + mean(behind_zones)) / 2\n",
    "    after filtering by daytype/daypart/(optional) modeoftravel.\n",
    "    Returns (overall, mean_ahead, mean_behind, ahead_n, behind_n, missing_ahead, missing_behind)\n",
    "    \"\"\"\n",
    "    filt = (df_stl[\"daytype\"] == daytype) & (df_stl[\"daypart\"] == daypart)\n",
    "    if modeoftravel:\n",
    "        filt = filt & (df_stl[\"modeoftravel\"] == modeoftravel)\n",
    "    stl = df_stl.loc[filt]\n",
    "\n",
    "    def mean_for(zones):\n",
    "        if not zones:\n",
    "            return np.nan, 0, []\n",
    "        sub = stl[stl[zonename_col].isin(zones)]\n",
    "        present = set(sub[zonename_col].unique())\n",
    "        missing = [z for z in zones if z not in present]\n",
    "        vals = pd.to_numeric(sub[stl_volume_col], errors=\"coerce\").dropna()\n",
    "        return (vals.mean() if not vals.empty else np.nan, len(sub), missing)\n",
    "\n",
    "    mean_ahead, ahead_n, miss_a = mean_for(ahead_zones)\n",
    "    mean_behind, behind_n, miss_b = mean_for(behind_zones)\n",
    "    overall = np.nanmean([mean_ahead, mean_behind])\n",
    "\n",
    "    return overall, mean_ahead, mean_behind, ahead_n, behind_n, miss_a, miss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b263629-b116-4601-be1f-7afc14afe711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 4) Build the per-location comparison DataFrame\n",
    "# ------------------------------------------------------\n",
    "def build_aadt_comparison_df(\n",
    "    aadt_locations,\n",
    "    df_tc,\n",
    "    df_stl,\n",
    "    daytype_filter=\"0: All Days (M-Su)\",\n",
    "    daypart_filter=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel_filter=None,\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a tidy DataFrame with one row per (location), including:\n",
    "      • objectids, ahead_zones, behind_zones\n",
    "      • traditional_aadt, traditional_ahead_mean, traditional_behind_mean\n",
    "      • non_trad_aadt, non_trad_ahead_mean, non_trad_behind_mean\n",
    "      • TCE (%)\n",
    "      • counts & missing info for debugging\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for loc in _iter_locations(aadt_locations):\n",
    "        # traditional\n",
    "        trad_overall, trad_ahead, trad_behind, n_ids = _traditional_aadt_for_ids(\n",
    "            df_tc, loc[\"objectids\"]\n",
    "        )\n",
    "\n",
    "        # non-traditional\n",
    "        stl_overall, stl_ahead, stl_behind, ahead_n, behind_n, miss_a, miss_b = _stl_aadt_for_zones(\n",
    "            df_stl,\n",
    "            loc[\"ahead_zones\"],\n",
    "            loc[\"behind_zones\"],\n",
    "            daytype=daytype_filter,\n",
    "            daypart=daypart_filter,\n",
    "            modeoftravel=modeoftravel_filter,\n",
    "            zonename_col=zonename_col,\n",
    "            stl_volume_col=stl_volume_col\n",
    "        )\n",
    "\n",
    "        # TCE\n",
    "        tce = np.nan\n",
    "        if pd.notna(trad_overall) and trad_overall != 0 and pd.notna(stl_overall):\n",
    "            tce = 100.0 * (stl_overall - trad_overall) / trad_overall\n",
    "\n",
    "        records.append({\n",
    "            \"location\": loc[\"name\"],\n",
    "            \"daytype_expected\": loc[\"daytype\"],\n",
    "            \"daytype_used\": daytype_filter,\n",
    "            \"daypart_used\": daypart_filter,\n",
    "            \"objectids\": \",\".join(loc[\"objectids\"]),\n",
    "            \"n_objectids\": len(loc[\"objectids\"]),\n",
    "            \"ahead_zones\": \",\".join(loc[\"ahead_zones\"]),\n",
    "            \"behind_zones\": \",\".join(loc[\"behind_zones\"]),\n",
    "\n",
    "            \"traditional_aadt\": trad_overall,\n",
    "            \"traditional_ahead_mean\": trad_ahead,\n",
    "            \"traditional_behind_mean\": trad_behind,\n",
    "\n",
    "            \"non_trad_aadt\": stl_overall,\n",
    "            \"non_trad_ahead_mean\": stl_ahead,\n",
    "            \"non_trad_behind_mean\": stl_behind,\n",
    "\n",
    "            \"tce_percent\": tce,\n",
    "\n",
    "            \"stl_ahead_rows\": ahead_n,\n",
    "            \"stl_behind_rows\": behind_n,\n",
    "            \"missing_ahead_zones\": \",\".join(miss_a) if miss_a else \"\",\n",
    "            \"missing_behind_zones\": \",\".join(miss_b) if miss_b else \"\",\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    # Optional: keep a stable, readable column order\n",
    "    preferred_cols = [\n",
    "        \"location\", \"objectids\", \"n_objectids\",\n",
    "        \"ahead_zones\", \"behind_zones\",\n",
    "        \"traditional_ahead_mean\", \"traditional_behind_mean\", \"traditional_aadt\",\n",
    "        \"non_trad_ahead_mean\", \"non_trad_behind_mean\", \"non_trad_aadt\",\n",
    "        \"tce_percent\",\n",
    "        \"daytype_expected\", \"daytype_used\", \"daypart_used\",\n",
    "        \"stl_ahead_rows\", \"stl_behind_rows\",\n",
    "        \"missing_ahead_zones\", \"missing_behind_zones\",\n",
    "    ]\n",
    "    df = df[[c for c in preferred_cols if c in df.columns]]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cad911-7b47-42bc-ad6d-1c20e49bc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 5) Confidence interval over TCE\n",
    "# ------------------------------------------------------\n",
    "def tce_confidence_interval(detail_df, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Computes mean TCE, CI, t-critical, and t-test statistic over the rows in detail_df.\n",
    "    Expects a 'tce_percent' column.\n",
    "    \"\"\"\n",
    "    tces = pd.to_numeric(detail_df[\"tce_percent\"], errors=\"coerce\").dropna().values\n",
    "    n = len(tces)\n",
    "    if n == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    mean_tce = float(np.mean(tces))\n",
    "    std_tce = float(np.std(tces, ddof=1)) if n > 1 else 0.0\n",
    "    se = std_tce / np.sqrt(n) if n > 1 else 0.0\n",
    "\n",
    "    if n > 1 and se > 0:\n",
    "        dfree = n - 1\n",
    "        tcrit = float(stats.t.ppf((1 + confidence) / 2, dfree))\n",
    "        ci_lo = mean_tce - tcrit * se\n",
    "        ci_hi = mean_tce + tcrit * se\n",
    "        t_stat = mean_tce / se\n",
    "    else:\n",
    "        tcrit = None\n",
    "        ci_lo = None\n",
    "        ci_hi = None\n",
    "        t_stat = None\n",
    "\n",
    "    return mean_tce, ci_lo, ci_hi, tcrit, t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eff893-f371-4148-82bb-ef109ddff859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build the per-location comparison table\n",
    "detail = build_aadt_comparison_df(\n",
    "    aadt_locations=sr_99_d3_tc_aadt_locations,\n",
    "    df_tc=df_tc,\n",
    "    df_stl=df_stl,\n",
    "    daytype_filter=\"0: All Days (M-Su)\",\n",
    "    daypart_filter=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel_filter=\"All Vehicles - StL All Vehicles Volume\",  # or None if not needed\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\"\n",
    ")\n",
    "\n",
    "# e.g., export for inspection\n",
    "# detail.to_csv(\"sr99_d3_aadt_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5b362-db66-4bd8-ad23-a430e2647278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Compute the CI across locations\n",
    "mean_tce, ci_lo, ci_hi, tcrit, t_stat = tce_confidence_interval(detail, confidence=0.95)\n",
    "print(mean_tce, ci_lo, ci_hi, tcrit, t_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b070076-a1af-44a4-92b1-0997264ffd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c085da-99c2-4620-be00-d50274c7f610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f8fac-8009-461f-88af-d65aed2a8e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd707ff-c6d1-425f-b258-e5cac0738abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22b73a-6681-4d67-87b0-bad3321ca9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ece7a389-e31e-43a2-9cf4-ccb7e7eec747",
   "metadata": {},
   "source": [
    "### Mean TCE: -3.62\n",
    "Traffic Census Error (TCE)\n",
    "* \n",
    "\n",
    "### 95% Confidence Interval (-10.78%, 3.54%)\n",
    "* \n",
    "\n",
    "### T-Test Statistic  \n",
    "* \n",
    "### Summary\n",
    "* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71be92d-e371-47d8-9cf8-5c3da056db6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee5909-ec3c-4c6b-ab29-e93293f9f224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
