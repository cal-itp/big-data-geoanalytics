{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35c3b37-f7e4-41e8-abf2-083155ea8641",
   "metadata": {},
   "source": [
    "# AADT Confidence Interval - Interstate 99\n",
    "\n",
    "## FHWA Links\n",
    "* Guidelines for Obtaining AADT Estimates from Non-Traditional Sources:\n",
    "    * https://www.fhwa.dot.gov/policyinformation/travel_monitoring/pubs/aadtnt/Guidelines_for_AADT_Estimates_Final.pdf\n",
    "  \n",
    "  \n",
    "## AADT Analysis Locations\n",
    "* 10 locations were used in the analysis\n",
    "* Locations were determined based on the location on installed & recording Traffic Operations cameras\n",
    "    * for additional information contact Zhenyu Zhu with Traffic Operations\n",
    "\n",
    "## Traffic Census Data\n",
    "* https://dot.ca.gov/programs/traffic-operations/census/traffic-volumes\n",
    "* Back AADT, Peak Month, and Peak Hour usually represents traffic South or West of the count location.  \n",
    "* Ahead AADT, Peak Month, and Peak Hour usually represents traffic North or East of the count location. Listing of routes with their designated  \n",
    "\n",
    "* Because the Back & Ahead counts are included at each location in the Traffic Census Data, (e.g., \"IRWINDALE, ARROW HIGHWAY\") only one [OBJECTID*] per location was pulled; for this analysis the North Bound Nodes were used for the analysis. \n",
    "    * for more information see the diagram: https://traffic.onramp.dot.ca.gov/downloads/traffic/files/performance/census/Back_and_Ahead_Leg_Traffic_Count_Diagram.pdf\n",
    "\n",
    "## StreetLight Analysis Data\n",
    "* StreetLight Locations on Interstate 99 are one-direction, each location will contain two points: northbound and southbound\n",
    "    * Analysis Type == Network Performance\n",
    "    * Segment Metrics\n",
    "    * 2022 was used to match currently available Traffic Census Data (as of 8/27/2025)\n",
    "    * pulled a variety of Day Types, but plan to just look at \"\"\"All Day Types\"\"\"\n",
    "    * pulled a variety of Day Parts, but plan to just look at \"\"\"All Day Parts\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171fa2b0-9b02-4947-a4d1-dd18ef86de42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5394f0e-d012-42ad-9286-c95948da43aa",
   "metadata": {},
   "source": [
    "### Pull in the Location Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6bce3a-11a1-4f2a-a7d9-eb7904946817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pull in the coordinates from the utils docs\n",
    "#from osow_frp_o_d_utils_v3 import origin_intersections, destination_intersections\n",
    "from sr99_tc_locations_utils import sr_99_d3_tc_aadt_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0a612-d979-43d3-87f3-e8d69df16d42",
   "metadata": {},
   "source": [
    "### Identify the Google Cloud Storage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4826a9-4c1c-46e4-95c5-20c820351b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the GCS path to the data\n",
    "gcs_path = \"gs://calitp-analytics-data/data-analyses/big_data/compare_traffic_counts/sr99_d3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628fa29-7fdc-46d2-bc5a-84c271f150d9",
   "metadata": {},
   "source": [
    "### Pull in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c01657-5051-44da-b79f-594359c06427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will pull in the data and clean the column headers in a way that will make them easier to work with\n",
    "def getdata_and_cleanheaders(path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Clean column headers: remove spaces, convert to lowercase, and strip trailing asterisks\n",
    "    cleaned_columns = []\n",
    "    for column in df.columns:\n",
    "        cleaned_column = column.replace(\" \", \"\").lower().rstrip(\"*\")\n",
    "        cleaned_columns.append(cleaned_column)\n",
    "\n",
    "    df.columns = cleaned_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686ea444-0d68-415c-beda-7ecdfe887062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pull in the data & create dataframes\n",
    "df_tc = getdata_and_cleanheaders(f\"{gcs_path}caltrans_traffic_census_2022.csv\")  # Traffic Census\n",
    "df_stl = getdata_and_cleanheaders(f\"{gcs_path}streetlight_sr99_d3_all_vehicles_2022_np.csv\")  # StreetLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b73b9a53-0066-4643-b8b7-ec90ceec2f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comparing\n",
    "df_tc.to_csv(\"df_tc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59259345-ec3c-47e8-bd2d-cf5059babf9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comparing\n",
    "df_stl.to_csv(\"df_stl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d877c99-b5fa-4b51-ac98-08b535e4d7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316ff939-7384-4f6d-86bc-109a2a6a54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_aadt_by_location(aadt_locations, df_tc, as_df=True):\n",
    "    \"\"\"\n",
    "    Build a per-location summary of *traditional* (Traffic Census) AADT.\n",
    "\n",
    "    Input:\n",
    "      - aadt_locations: raw structure (dict or list) OR the normalized list/DF\n",
    "        with columns/keys: name, daytype, objectids\n",
    "      - df_tc: Traffic Census DataFrame (columns: objectid, ahead_aadt, back_aadt)\n",
    "      - as_df: return a DataFrame (True) or list[dict] (False)\n",
    "\n",
    "    Output columns:\n",
    "      location, daytype, objectids, n_objectids, n_found_in_tc, missing_objectids,\n",
    "      traditional_ahead_mean, traditional_behind_mean, traditional_aadt\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- tiny helpers kept INSIDE this function -----\n",
    "    def _ensure_list(x):\n",
    "        if x is None: return []\n",
    "        if isinstance(x, (list, tuple, set)): return list(x)\n",
    "        return [x]\n",
    "\n",
    "    def _gather_objectids(node_dict):\n",
    "        ids = []\n",
    "        if not isinstance(node_dict, dict): return ids\n",
    "        if \"objectid\" in node_dict:  ids.extend(_ensure_list(node_dict[\"objectid\"]))\n",
    "        if \"objectids\" in node_dict: ids.extend(_ensure_list(node_dict[\"objectids\"]))\n",
    "        return [str(i) for i in ids if i is not None and str(i).strip() != \"\"]\n",
    "\n",
    "    def _dedup(seq):\n",
    "        seen=set(); out=[]\n",
    "        for x in seq:\n",
    "            if x not in seen:\n",
    "                out.append(x); seen.add(x)\n",
    "        return out\n",
    "\n",
    "    def _normalize_one_location(name, loc):\n",
    "        nodes = loc.get(\"nodes\", {}) or {}\n",
    "        all_ids=[]\n",
    "        for _, node in nodes.items():\n",
    "            all_ids.extend(_gather_objectids(node))\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"daytype\": loc.get(\"daytype\", \"0: All Days (M-Su)\"),\n",
    "            \"objectids\": _dedup(all_ids),\n",
    "        }\n",
    "\n",
    "    def _normalize_input(aadt_locs):\n",
    "        # Already normalized DataFrame?\n",
    "        if isinstance(aadt_locs, pd.DataFrame) and \\\n",
    "           {\"name\",\"daytype\",\"objectids\"}.issubset(aadt_locs.columns):\n",
    "            return aadt_locs.to_dict(orient=\"records\")\n",
    "        # Already normalized list[dict]?\n",
    "        if isinstance(aadt_locs, list) and aadt_locs and isinstance(aadt_locs[0], dict) and \\\n",
    "           {\"name\",\"daytype\",\"objectids\"}.issubset(aadt_locs[0].keys()):\n",
    "            return aadt_locs\n",
    "\n",
    "        recs = []\n",
    "        if isinstance(aadt_locs, dict):\n",
    "            for nm, loc in aadt_locs.items():\n",
    "                recs.append(_normalize_one_location(nm, loc))\n",
    "        elif isinstance(aadt_locs, list):\n",
    "            for item in aadt_locs:\n",
    "                if isinstance(item, dict) and \"nodes\" in item:  # single location dict\n",
    "                    nm = item.get(\"location_description\") or item.get(\"name\") or \"UNKNOWN\"\n",
    "                    recs.append(_normalize_one_location(nm, item))\n",
    "                elif isinstance(item, dict):  # dict keyed by name\n",
    "                    for nm, loc in item.items():\n",
    "                        recs.append(_normalize_one_location(nm, loc))\n",
    "        return recs\n",
    "\n",
    "    def _traditional_aadt_for_ids(df_tc_in, obj_ids):\n",
    "        if not obj_ids:\n",
    "            return np.nan, np.nan, np.nan, 0\n",
    "        sub = df_tc_in[df_tc_in[\"objectid\"].astype(str).isin(obj_ids)]\n",
    "        if sub.empty:\n",
    "            return np.nan, np.nan, np.nan, 0\n",
    "        ahead_vals = pd.to_numeric(sub.get(\"ahead_aadt\"), errors=\"coerce\").dropna()\n",
    "        back_vals  = pd.to_numeric(sub.get(\"back_aadt\"),  errors=\"coerce\").dropna()\n",
    "        mean_ahead = ahead_vals.mean() if not ahead_vals.empty else np.nan\n",
    "        mean_back  = back_vals.mean()  if not back_vals.empty  else np.nan\n",
    "        overall = np.nanmean([mean_ahead, mean_back])  # average of the two means\n",
    "        count_used = len(sub)\n",
    "        return overall, mean_ahead, mean_back, count_used\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    norm = _normalize_input(aadt_locations)\n",
    "    tc_ids_all = set(df_tc[\"objectid\"].astype(str).unique())\n",
    "\n",
    "    rows = []\n",
    "    for loc in norm:\n",
    "        obj_ids = [str(x) for x in (loc.get(\"objectids\") or [])]\n",
    "        overall, mean_ahead, mean_back, n_found = _traditional_aadt_for_ids(df_tc, obj_ids)\n",
    "        missing = [x for x in obj_ids if x not in tc_ids_all]\n",
    "        rows.append({\n",
    "            \"location\": loc.get(\"name\"),\n",
    "            \"daytype\":  loc.get(\"daytype\"),\n",
    "            \"objectids\": \",\".join(obj_ids),\n",
    "            \"n_objectids\": len(obj_ids),\n",
    "            \"n_found_in_tc\": int(n_found),\n",
    "            \"missing_objectids\": \",\".join(missing) if missing else \"\",\n",
    "            \"traditional_ahead_mean\": mean_ahead,\n",
    "            \"traditional_behind_mean\": mean_back,\n",
    "            \"traditional_aadt\": overall,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows) if as_df else rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db115308-4010-4c5a-a51c-49db69dfaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_df = traditional_aadt_by_location(sr_99_d3_tc_aadt_locations, df_tc, as_df=True)\n",
    "trad_df.head()\n",
    "trad_df.to_csv(\"traditional_aadt_by_location.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86684d1a-e3b0-4e7b-b218-2c8e09aa8518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e68861-59c8-4426-bf8c-16db1ea1ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_traditional_aadt_by_location(\n",
    "    aadt_locations,\n",
    "    df_stl,\n",
    "    daytype_filter=\"0: All Days (M-Su)\",\n",
    "    daypart_filter=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel_filter=None,\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\",\n",
    "    as_df=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a per-location summary of *non-traditional* (StreetLight) AADT.\n",
    "\n",
    "    Inputs:\n",
    "      - aadt_locations: raw dict/list (your nested structure) OR normalized data\n",
    "        with keys/cols: name, daytype, ahead_zones, behind_zones\n",
    "      - df_stl: StreetLight DataFrame with columns:\n",
    "          zonename, averagedailysegmenttraffic(stlvolume), daytype, daypart\n",
    "        (and optionally modeoftravel if you want to filter by it)\n",
    "      - daytype_filter, daypart_filter, modeoftravel_filter: filters to apply\n",
    "      - zonename_col, stl_volume_col: column names in df_stl\n",
    "      - as_df: return a DataFrame (True) or list[dict] (False)\n",
    "\n",
    "    Output columns (one row per location):\n",
    "      location, daytype_expected, daytype_used, daypart_used, modeoftravel_used,\n",
    "      ahead_zones, behind_zones,\n",
    "      non_trad_ahead_mean, non_trad_behind_mean, non_trad_aadt,\n",
    "      stl_ahead_rows, stl_behind_rows, missing_ahead_zones, missing_behind_zones\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------- tiny helpers kept inside -------------\n",
    "    def _ensure_list(x):\n",
    "        if x is None: return []\n",
    "        if isinstance(x, (list, tuple, set)): return list(x)\n",
    "        return [x]\n",
    "\n",
    "    def _gather_zones(node_dict):\n",
    "        ahead  = _ensure_list(node_dict.get(\"zonename_ahead\", []))\n",
    "        behind = _ensure_list(node_dict.get(\"zonename_behind\", []))\n",
    "        return ahead, behind\n",
    "\n",
    "    def _dedup(seq):\n",
    "        seen=set(); out=[]\n",
    "        for x in seq:\n",
    "            if x not in seen:\n",
    "                out.append(x); seen.add(x)\n",
    "        return out\n",
    "\n",
    "    def _normalize_one_location(name, loc):\n",
    "        nodes = loc.get(\"nodes\", {}) or {}\n",
    "        ahead, behind = [], []\n",
    "        for _, node in nodes.items():\n",
    "            a, b = _gather_zones(node)\n",
    "            ahead.extend([z for z in a if z])\n",
    "            behind.extend([z for z in b if z])\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"daytype\": loc.get(\"daytype\", \"0: All Days (M-Su)\"),\n",
    "            \"ahead_zones\": _dedup(ahead),\n",
    "            \"behind_zones\": _dedup(behind),\n",
    "        }\n",
    "\n",
    "    def _normalize_input(aadt_locs):\n",
    "        # Already normalized DataFrame?\n",
    "        if isinstance(aadt_locs, pd.DataFrame) and \\\n",
    "           {\"name\",\"daytype\",\"ahead_zones\",\"behind_zones\"}.issubset(aadt_locs.columns):\n",
    "            return aadt_locs.to_dict(orient=\"records\")\n",
    "        # Already normalized list[dict]?\n",
    "        if isinstance(aadt_locs, list) and aadt_locs and isinstance(aadt_locs[0], dict) and \\\n",
    "           {\"name\",\"daytype\",\"ahead_zones\",\"behind_zones\"}.issubset(aadt_locs[0].keys()):\n",
    "            return aadt_locs\n",
    "\n",
    "        # Otherwise, normalize from raw structure\n",
    "        recs = []\n",
    "        if isinstance(aadt_locs, dict):\n",
    "            for nm, loc in aadt_locs.items():\n",
    "                recs.append(_normalize_one_location(nm, loc))\n",
    "        elif isinstance(aadt_locs, list):\n",
    "            for item in aadt_locs:\n",
    "                if isinstance(item, dict) and \"nodes\" in item:  # single location dict\n",
    "                    nm = item.get(\"location_description\") or item.get(\"name\") or \"UNKNOWN\"\n",
    "                    recs.append(_normalize_one_location(nm, item))\n",
    "                elif isinstance(item, dict):  # dict keyed by name\n",
    "                    for nm, loc in item.items():\n",
    "                        recs.append(_normalize_one_location(nm, loc))\n",
    "        return recs\n",
    "\n",
    "    def _stl_means_for_zone_lists(stl_df, zones):\n",
    "        \"\"\"Return mean volume, matched row count, and missing list for a set of zonenames.\"\"\"\n",
    "        if not zones:\n",
    "            return np.nan, 0, []\n",
    "        sub = stl_df[stl_df[zonename_col].isin(zones)]\n",
    "        present = set(sub[zonename_col].unique())\n",
    "        missing = [z for z in zones if z not in present]\n",
    "        vals = pd.to_numeric(sub[stl_volume_col], errors=\"coerce\").dropna()\n",
    "        mean_val = vals.mean() if not vals.empty else np.nan\n",
    "        return mean_val, int(len(sub)), missing\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # Filter StreetLight once\n",
    "    filt = (df_stl[\"daytype\"] == daytype_filter) & (df_stl[\"daypart\"] == daypart_filter)\n",
    "    if modeoftravel_filter and (\"modeoftravel\" in df_stl.columns):\n",
    "        filt = filt & (df_stl[\"modeoftravel\"] == modeoftravel_filter)\n",
    "    stl_filtered = df_stl.loc[filt].copy()\n",
    "\n",
    "    norm = _normalize_input(aadt_locations)\n",
    "\n",
    "    rows = []\n",
    "    for loc in norm:\n",
    "        ahead = _ensure_list(loc.get(\"ahead_zones\", []))\n",
    "        behind = _ensure_list(loc.get(\"behind_zones\", []))\n",
    "\n",
    "        mean_ahead, ahead_n, miss_a = _stl_means_for_zone_lists(stl_filtered, ahead)\n",
    "        mean_behind, behind_n, miss_b = _stl_means_for_zone_lists(stl_filtered, behind)\n",
    "        overall = np.nanmean([mean_ahead, mean_behind])\n",
    "\n",
    "        rows.append({\n",
    "            \"location\": loc.get(\"name\"),\n",
    "            \"daytype_expected\": loc.get(\"daytype\"),\n",
    "            \"daytype_used\": daytype_filter,\n",
    "            \"daypart_used\": daypart_filter,\n",
    "            \"modeoftravel_used\": modeoftravel_filter if modeoftravel_filter else \"\",\n",
    "            \"ahead_zones\": \",\".join(ahead),\n",
    "            \"behind_zones\": \",\".join(behind),\n",
    "\n",
    "            \"non_trad_ahead_mean\": mean_ahead,\n",
    "            \"non_trad_behind_mean\": mean_behind,\n",
    "            \"non_trad_aadt\": overall,\n",
    "\n",
    "            \"stl_ahead_rows\": ahead_n,\n",
    "            \"stl_behind_rows\": behind_n,\n",
    "            \"missing_ahead_zones\": \",\".join(miss_a) if miss_a else \"\",\n",
    "            \"missing_behind_zones\": \",\".join(miss_b) if miss_b else \"\",\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows) if as_df else rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bffe53-019a-424d-99bd-6880d47e4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have the raw nested structure:\n",
    "stl_df = non_traditional_aadt_by_location(\n",
    "    sr_99_d3_tc_aadt_locations,\n",
    "    df_stl,\n",
    "    daytype_filter=\"0: All Days (M-Su)\",\n",
    "    daypart_filter=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel_filter=\"All Vehicles - StL All Vehicles Volume\",  # or None\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\",\n",
    "    as_df=True\n",
    ")\n",
    "\n",
    "stl_df.to_csv(\"non_traditional_aadt_by_location.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46d7d7-60e1-4994-b59f-7c5ddfed828f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42362c-a0c1-43ec-9d1a-72fd413b679a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe2fd0-949b-4145-8aac-9001a6e3e292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97013243-bb98-452a-9954-058b6ee91289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec234022-6cff-4b8f-90c7-ed0f67a0bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 4) Build the per-location comparison DataFrame\n",
    "# ------------------------------------------------------\n",
    "def build_aadt_comparison_df(\n",
    "    aadt_locations,\n",
    "    df_tc,\n",
    "    df_stl,\n",
    "    daytype_filter=\"0: All Days (M-Su)\",\n",
    "    daypart_filter=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel_filter=None,\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a tidy DataFrame with one row per (location), including:\n",
    "      • objectids, ahead_zones, behind_zones\n",
    "      • traditional_aadt, traditional_ahead_mean, traditional_behind_mean\n",
    "      • non_trad_aadt, non_trad_ahead_mean, non_trad_behind_mean\n",
    "      • TCE (%)\n",
    "      • counts & missing info for debugging\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for loc in _iter_locations(aadt_locations):\n",
    "        # traditional\n",
    "        trad_overall, trad_ahead, trad_behind, n_ids = _traditional_aadt_for_ids(\n",
    "            df_tc, loc[\"objectids\"]\n",
    "        )\n",
    "\n",
    "        # non-traditional\n",
    "        stl_overall, stl_ahead, stl_behind, ahead_n, behind_n, miss_a, miss_b = _stl_aadt_for_zones(\n",
    "            df_stl,\n",
    "            loc[\"ahead_zones\"],\n",
    "            loc[\"behind_zones\"],\n",
    "            daytype=daytype_filter,\n",
    "            daypart=daypart_filter,\n",
    "            modeoftravel=modeoftravel_filter,\n",
    "            zonename_col=zonename_col,\n",
    "            stl_volume_col=stl_volume_col\n",
    "        )\n",
    "\n",
    "        # TCE\n",
    "        tce = np.nan\n",
    "        if pd.notna(trad_overall) and trad_overall != 0 and pd.notna(stl_overall):\n",
    "            tce = 100.0 * (stl_overall - trad_overall) / trad_overall\n",
    "\n",
    "        records.append({\n",
    "            \"location\": loc[\"name\"],\n",
    "            \"daytype_expected\": loc[\"daytype\"],\n",
    "            \"daytype_used\": daytype_filter,\n",
    "            \"daypart_used\": daypart_filter,\n",
    "            \"objectids\": \",\".join(loc[\"objectids\"]),\n",
    "            \"n_objectids\": len(loc[\"objectids\"]),\n",
    "            \"ahead_zones\": \",\".join(loc[\"ahead_zones\"]),\n",
    "            \"behind_zones\": \",\".join(loc[\"behind_zones\"]),\n",
    "\n",
    "            \"traditional_aadt\": trad_overall,\n",
    "            \"traditional_ahead_mean\": trad_ahead,\n",
    "            \"traditional_behind_mean\": trad_behind,\n",
    "\n",
    "            \"non_trad_aadt\": stl_overall,\n",
    "            \"non_trad_ahead_mean\": stl_ahead,\n",
    "            \"non_trad_behind_mean\": stl_behind,\n",
    "\n",
    "            \"tce_percent\": tce,\n",
    "\n",
    "            \"stl_ahead_rows\": ahead_n,\n",
    "            \"stl_behind_rows\": behind_n,\n",
    "            \"missing_ahead_zones\": \",\".join(miss_a) if miss_a else \"\",\n",
    "            \"missing_behind_zones\": \",\".join(miss_b) if miss_b else \"\",\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    # Optional: keep a stable, readable column order\n",
    "    preferred_cols = [\n",
    "        \"location\", \"objectids\", \"n_objectids\",\n",
    "        \"ahead_zones\", \"behind_zones\",\n",
    "        \"traditional_ahead_mean\", \"traditional_behind_mean\", \"traditional_aadt\",\n",
    "        \"non_trad_ahead_mean\", \"non_trad_behind_mean\", \"non_trad_aadt\",\n",
    "        \"tce_percent\",\n",
    "        \"daytype_expected\", \"daytype_used\", \"daypart_used\",\n",
    "        \"stl_ahead_rows\", \"stl_behind_rows\",\n",
    "        \"missing_ahead_zones\", \"missing_behind_zones\",\n",
    "    ]\n",
    "    df = df[[c for c in preferred_cols if c in df.columns]]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183dac9-4407-491a-8e88-76339267e208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c453dbb8-0d46-4847-b296-00aee2b97787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# 5) Confidence interval over TCE\n",
    "# ------------------------------------------------------\n",
    "def tce_confidence_interval(detail_df, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Computes mean TCE, CI, t-critical, and t-test statistic over the rows in detail_df.\n",
    "    Expects a 'tce_percent' column.\n",
    "    \"\"\"\n",
    "    tces = pd.to_numeric(detail_df[\"tce_percent\"], errors=\"coerce\").dropna().values\n",
    "    n = len(tces)\n",
    "    if n == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    mean_tce = float(np.mean(tces))\n",
    "    std_tce = float(np.std(tces, ddof=1)) if n > 1 else 0.0\n",
    "    se = std_tce / np.sqrt(n) if n > 1 else 0.0\n",
    "\n",
    "    if n > 1 and se > 0:\n",
    "        dfree = n - 1\n",
    "        tcrit = float(stats.t.ppf((1 + confidence) / 2, dfree))\n",
    "        ci_lo = mean_tce - tcrit * se\n",
    "        ci_hi = mean_tce + tcrit * se\n",
    "        t_stat = mean_tce / se\n",
    "    else:\n",
    "        tcrit = None\n",
    "        ci_lo = None\n",
    "        ci_hi = None\n",
    "        t_stat = None\n",
    "\n",
    "    return mean_tce, ci_lo, ci_hi, tcrit, t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b070076-a1af-44a4-92b1-0997264ffd06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_iter_locations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1) Build the per-location comparison table\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m detail \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_aadt_comparison_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43maadt_locations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr_99_d3_tc_aadt_locations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_tc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_tc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_stl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_stl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdaytype_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0: All Days (M-Su)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdaypart_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0: All Day (12am-12am)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodeoftravel_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAll Vehicles - StL All Vehicles Volume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or None if not needed\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzonename_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzonename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstl_volume_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maveragedailysegmenttraffic(stlvolume)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# e.g., export for inspection\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# detail.to_csv(\"sr99_d3_aadt_comparison.csv\", index=False)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 2) Compute the CI across locations\u001b[39;00m\n\u001b[1;32m     17\u001b[0m mean_tce, ci_lo, ci_hi, tcrit, t_stat \u001b[38;5;241m=\u001b[39m tce_confidence_interval(detail, confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m, in \u001b[0;36mbuild_aadt_comparison_df\u001b[0;34m(aadt_locations, df_tc, df_stl, daytype_filter, daypart_filter, modeoftravel_filter, zonename_col, stl_volume_col)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mReturns a tidy DataFrame with one row per (location), including:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m  • objectids, ahead_zones, behind_zones\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m  • counts & missing info for debugging\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m records \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_iter_locations\u001b[49m(aadt_locations):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# traditional\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     trad_overall, trad_ahead, trad_behind, n_ids \u001b[38;5;241m=\u001b[39m _traditional_aadt_for_ids(\n\u001b[1;32m     27\u001b[0m         df_tc, loc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjectids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# non-traditional\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_iter_locations' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Build the per-location comparison table\n",
    "detail = build_aadt_comparison_df(\n",
    "    aadt_locations=sr_99_d3_tc_aadt_locations,\n",
    "    df_tc=df_tc,\n",
    "    df_stl=df_stl,\n",
    "    daytype_filter=\"0: All Days (M-Su)\",\n",
    "    daypart_filter=\"0: All Day (12am-12am)\",\n",
    "    modeoftravel_filter=\"All Vehicles - StL All Vehicles Volume\",  # or None if not needed\n",
    "    zonename_col=\"zonename\",\n",
    "    stl_volume_col=\"averagedailysegmenttraffic(stlvolume)\"\n",
    ")\n",
    "\n",
    "# e.g., export for inspection\n",
    "# detail.to_csv(\"sr99_d3_aadt_comparison.csv\", index=False)\n",
    "\n",
    "# 2) Compute the CI across locations\n",
    "mean_tce, ci_lo, ci_hi, tcrit, t_stat = tce_confidence_interval(detail, confidence=0.95)\n",
    "print(mean_tce, ci_lo, ci_hi, tcrit, t_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c085da-99c2-4620-be00-d50274c7f610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f8fac-8009-461f-88af-d65aed2a8e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd707ff-c6d1-425f-b258-e5cac0738abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22b73a-6681-4d67-87b0-bad3321ca9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ece7a389-e31e-43a2-9cf4-ccb7e7eec747",
   "metadata": {},
   "source": [
    "### Mean TCE: -3.62\n",
    "Traffic Census Error (TCE)\n",
    "* \n",
    "\n",
    "### 95% Confidence Interval (-10.78%, 3.54%)\n",
    "* \n",
    "\n",
    "### T-Test Statistic  \n",
    "* \n",
    "### Summary\n",
    "* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71be92d-e371-47d8-9cf8-5c3da056db6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee5909-ec3c-4c6b-ab29-e93293f9f224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
